{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CrossValidation-TkC.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6AvICftLwNH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "34c766e6-9c30-443d-a4e0-eca8c67bd12c"
      },
      "source": [
        "!wget -c http://gemeos.org/henrique/health_fasttext_300v1.tar.gz -O health_fasttext_300v1.tar.gz #0.86\n",
        "!tar -zxvf health_fasttext_300v1.tar.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-12 16:57:28--  http://gemeos.org/henrique/health_fasttext_300v1.tar.gz\n",
            "Resolving gemeos.org (gemeos.org)... 187.45.195.133\n",
            "Connecting to gemeos.org (gemeos.org)|187.45.195.133|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2255702828 (2.1G) [application/x-gzip]\n",
            "Saving to: ‘health_fasttext_300v1.tar.gz’\n",
            "\n",
            "health_fasttext_300 100%[===================>]   2.10G  24.3MB/s    in 90s     \n",
            "\n",
            "2020-02-12 16:58:58 (23.9 MB/s) - ‘health_fasttext_300v1.tar.gz’ saved [2255702828/2255702828]\n",
            "\n",
            "health_fasttext_300.model\n",
            "health_fasttext_300.model.trainables.syn1neg.npy\n",
            "health_fasttext_300.model.trainables.vectors_ngrams_lockf.npy\n",
            "health_fasttext_300.model.trainables.vectors_vocab_lockf.npy\n",
            "health_fasttext_300.model.wv.vectors_ngrams.npy\n",
            "health_fasttext_300.model.wv.vectors.npy\n",
            "health_fasttext_300.model.wv.vectors_vocab.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Vx4OY69Lx6b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5107a9ea-be4e-4311-f2b2-28c2c867e65b"
      },
      "source": [
        "!pip install flair==0.4.3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: flair==0.4.3 in /usr/local/lib/python3.6/dist-packages (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.3) (4.28.1)\n",
            "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.3) (3.1.3)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.20 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.3) (1.24.3)\n",
            "Requirement already satisfied: pytest>=3.6.4 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.3) (3.6.4)\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.6/dist-packages (from flair==0.4.3) (1.0.7)\n",
            "Requirement already satisfied: pytorch-transformers>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.3) (1.2.0)\n",
            "Requirement already satisfied: bpemb>=0.2.9 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.3) (0.3.0)\n",
            "Requirement already satisfied: ipython-genutils==0.2.0 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.3) (0.2.0)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (from flair==0.4.3) (0.0)\n",
            "Requirement already satisfied: gensim>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.3) (3.6.0)\n",
            "Requirement already satisfied: deprecated>=1.2.4 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.3) (1.2.7)\n",
            "Requirement already satisfied: ipython==7.6.1 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.3) (7.6.1)\n",
            "Requirement already satisfied: hyperopt>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.3) (0.1.2)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.3) (1.4.0)\n",
            "Requirement already satisfied: sqlitedict>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.3) (1.6.0)\n",
            "Requirement already satisfied: mpld3==0.3 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.3) (0.3)\n",
            "Requirement already satisfied: segtok>=1.5.7 in /usr/local/lib/python3.6/dist-packages (from flair==0.4.3) (1.5.7)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from flair==0.4.3) (0.8.6)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from flair==0.4.3) (2019.12.20)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair==0.4.3) (0.10.0)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair==0.4.3) (1.17.5)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair==0.4.3) (2.4.6)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair==0.4.3) (2.6.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair==0.4.3) (1.1.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair==0.4.3) (8.2.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair==0.4.3) (0.7.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair==0.4.3) (1.12.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair==0.4.3) (19.3.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair==0.4.3) (1.8.1)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair==0.4.3) (1.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair==0.4.3) (45.1.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers>=1.1.0->flair==0.4.3) (0.0.38)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers>=1.1.0->flair==0.4.3) (1.11.14)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers>=1.1.0->flair==0.4.3) (0.1.85)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers>=1.1.0->flair==0.4.3) (2.21.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn->flair==0.4.3) (0.22.1)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair==0.4.3) (1.9.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair==0.4.3) (1.4.1)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.6/dist-packages (from deprecated>=1.2.4->flair==0.4.3) (1.11.2)\n",
            "Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.6/dist-packages (from ipython==7.6.1->flair==0.4.3) (0.16.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from ipython==7.6.1->flair==0.4.3) (2.0.10)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython==7.6.1->flair==0.4.3) (4.4.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython==7.6.1->flair==0.4.3) (0.7.5)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython==7.6.1->flair==0.4.3) (4.8.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.6/dist-packages (from ipython==7.6.1->flair==0.4.3) (0.1.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython==7.6.1->flair==0.4.3) (2.1.3)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython==7.6.1->flair==0.4.3) (4.3.3)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair==0.4.3) (3.10.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair==0.4.3) (2.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair==0.4.3) (0.16.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers>=1.1.0->flair==0.4.3) (0.14.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers>=1.1.0->flair==0.4.3) (7.0)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers>=1.1.0->flair==0.4.3) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers>=1.1.0->flair==0.4.3) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.14 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers>=1.1.0->flair==0.4.3) (1.14.14)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers>=1.1.0->flair==0.4.3) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers>=1.1.0->flair==0.4.3) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers>=1.1.0->flair==0.4.3) (2019.11.28)\n",
            "Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim>=3.4.0->flair==0.4.3) (2.49.0)\n",
            "Requirement already satisfied: parso>=0.5.2 in /usr/local/lib/python3.6/dist-packages (from jedi>=0.10->ipython==7.6.1->flair==0.4.3) (0.6.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython==7.6.1->flair==0.4.3) (0.1.8)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython==7.6.1->flair==0.4.3) (0.6.0)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.14->boto3->pytorch-transformers>=1.1.0->flair==0.4.3) (0.15.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Toofg1Z6MA7M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from flair.data import Corpus\n",
        "from flair.datasets import ColumnCorpus\n",
        "from flair.datasets import CSVClassificationCorpus\n",
        "from flair.embeddings import TokenEmbeddings, WordEmbeddings, StackedEmbeddings, FlairEmbeddings\n",
        "from flair.embeddings import DocumentRNNEmbeddings\n",
        "from flair.models import TextClassifier\n",
        "from flair.models import SequenceTagger\n",
        "from flair.trainers import ModelTrainer\n",
        "from flair.optim import SGDW\n",
        "from flair.data import Sentence\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from typing import List\n",
        "import pandas as pd\n",
        "import torch\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbgvC8KPLhRl",
        "colab_type": "text"
      },
      "source": [
        "## FOLD 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNgebH95KoB-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "127f8131-9b60-4654-a8f6-3a31b06f1f41"
      },
      "source": [
        "pathCorpus : str = '/content/Fall-Recognition/Data/FOLDER_1/'\n",
        "train_file : str = 'Train-SPLIT-1.txt'\n",
        "test_file : str = 'Test-SPLIT-1.txt'\n",
        "dev_file : str = 'CoNLL-dev.txt'\n",
        "pathCheckpoint: str = '/content/Fall-Recognition/Data/FOLDER_1/TRN-FD1'\n",
        "pathWordEmbeddings : str = 'health_fasttext_300.model'\n",
        "pathFlairEmbeddingsForward : str = None\n",
        "pathFlairEmbeddingsBackward : str =  None\n",
        "\n",
        "print('--------------------------START TRAINING (TOKEN)------------------------------')\n",
        "\n",
        "columns = {0:'token', 1:'label'}\n",
        "\n",
        "corpus: Corpus = ColumnCorpus(pathCorpus, columns,\n",
        "\ttrain_file = train_file,\n",
        "\ttest_file = test_file,\n",
        "\tdev_file = dev_file)\n",
        "\n",
        "print(\" \")\n",
        "print(\"Train len: \", len(corpus.train))\n",
        "print(\"Test len: \", len(corpus.test))\n",
        "print(\"Dev len: \", len(corpus.dev))\n",
        "\n",
        "tag_type = 'label'\n",
        "tag_dictionary = corpus.make_tag_dictionary(tag_type=tag_type)\n",
        "\n",
        "print(tag_dictionary.idx2item)\n",
        "print(\"len: \", len(tag_dictionary.idx2item))\n",
        "\n",
        "health_embedding = WordEmbeddings(pathWordEmbeddings)\n",
        "#flair_forward_embedding = FlairEmbeddings(pathFlairEmbeddingsForward)\n",
        "#flair_backward_embedding = FlairEmbeddings(pathFlairEmbeddingsBackward)\n",
        "\n",
        "embedding_types: List[TokenEmbeddings] = [\n",
        "\thealth_embedding,\n",
        "]\n",
        "  \n",
        "embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)\n",
        "\t\n",
        "tagger: SequenceTagger = SequenceTagger(hidden_size=256,\n",
        "\t\t\t\t\t\t\t\t\t\tembeddings=embeddings,\n",
        "\t\t\t\t\t\t\t\t\t\ttag_dictionary=tag_dictionary,\n",
        "\t\t\t\t\t\t\t\t\t\ttag_type=tag_type,\n",
        "\t\t\t\t\t\t\t\t\t\tuse_crf=True)\n",
        "\n",
        "trainer: ModelTrainer = ModelTrainer(tagger, corpus, optimizer=SGDW)\n",
        "\n",
        "trainer.train(pathCheckpoint,\n",
        "\t\t\t  learning_rate=0.1,\n",
        "\t\t\t  mini_batch_size=32,\n",
        "\t\t\t  max_epochs=150,\n",
        "\t\t\t  checkpoint=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------------START TRAINING (TOKEN)------------------------------\n",
            "2020-02-12 12:03:31,277 Reading data from /content/drive/My Drive/Colab Notebooks/Fall-Recognition/Data/FOLDER_1\n",
            "2020-02-12 12:03:31,280 Train: /content/drive/My Drive/Colab Notebooks/Fall-Recognition/Data/FOLDER_1/Train-SPLIT-1.txt\n",
            "2020-02-12 12:03:31,281 Dev: /content/drive/My Drive/Colab Notebooks/Fall-Recognition/Data/FOLDER_1/CoNLL-dev.txt\n",
            "2020-02-12 12:03:31,283 Test: /content/drive/My Drive/Colab Notebooks/Fall-Recognition/Data/FOLDER_1/Test-SPLIT-1.txt\n",
            " \n",
            "Train len:  888\n",
            "Test len:  444\n",
            "Dev len:  70\n",
            "[b'<unk>', b'O', b'B-QUEDA', b'I-QUEDA', b'<START>', b'<STOP>']\n",
            "len:  6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-02-12 12:03:49,736 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 12:03:49,737 Model: \"SequenceTagger(\n",
            "  (embeddings): StackedEmbeddings(\n",
            "    (list_embedding_0): WordEmbeddings('health_fasttext_300.model')\n",
            "  )\n",
            "  (word_dropout): WordDropout(p=0.05)\n",
            "  (locked_dropout): LockedDropout(p=0.5)\n",
            "  (embedding2nn): Linear(in_features=300, out_features=300, bias=True)\n",
            "  (rnn): LSTM(300, 256, bidirectional=True)\n",
            "  (linear): Linear(in_features=512, out_features=6, bias=True)\n",
            ")\"\n",
            "2020-02-12 12:03:49,739 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 12:03:49,740 Corpus: \"Corpus: 888 train + 70 dev + 444 test sentences\"\n",
            "2020-02-12 12:03:49,742 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 12:03:49,744 Parameters:\n",
            "2020-02-12 12:03:49,745  - learning_rate: \"0.1\"\n",
            "2020-02-12 12:03:49,746  - mini_batch_size: \"32\"\n",
            "2020-02-12 12:03:49,748  - patience: \"3\"\n",
            "2020-02-12 12:03:49,749  - anneal_factor: \"0.5\"\n",
            "2020-02-12 12:03:49,750  - max_epochs: \"150\"\n",
            "2020-02-12 12:03:49,751  - shuffle: \"True\"\n",
            "2020-02-12 12:03:49,752  - train_with_dev: \"False\"\n",
            "2020-02-12 12:03:49,753 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 12:03:49,754 Model training base path: \"/content/drive/My Drive/Colab Notebooks/Fall-Recognition/Data/FOLDER_1/TRN-FD1\"\n",
            "2020-02-12 12:03:49,755 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 12:03:49,756 Device: cuda:0\n",
            "2020-02-12 12:03:49,757 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 12:03:49,759 Embeddings storage mode: cpu\n",
            "2020-02-12 12:03:50,468 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 12:03:52,639 epoch 1 - iter 0/28 - loss 363.06848145 - samples/sec: 30.14\n",
            "2020-02-12 12:03:56,709 epoch 1 - iter 2/28 - loss 236.64652507 - samples/sec: 16.77\n",
            "2020-02-12 12:04:00,560 epoch 1 - iter 4/28 - loss 157.00783081 - samples/sec: 17.86\n",
            "2020-02-12 12:04:04,123 epoch 1 - iter 6/28 - loss 115.40488284 - samples/sec: 19.58\n",
            "2020-02-12 12:04:08,005 epoch 1 - iter 8/28 - loss 91.18485594 - samples/sec: 17.75\n",
            "2020-02-12 12:04:12,061 epoch 1 - iter 10/28 - loss 75.69319443 - samples/sec: 16.84\n",
            "2020-02-12 12:04:17,081 epoch 1 - iter 12/28 - loss 64.85265662 - samples/sec: 13.49\n",
            "2020-02-12 12:04:20,026 epoch 1 - iter 14/28 - loss 56.86725238 - samples/sec: 23.61\n",
            "2020-02-12 12:04:24,188 epoch 1 - iter 16/28 - loss 50.54316243 - samples/sec: 16.49\n",
            "2020-02-12 12:04:28,134 epoch 1 - iter 18/28 - loss 45.62690714 - samples/sec: 17.33\n",
            "2020-02-12 12:04:31,995 epoch 1 - iter 20/28 - loss 41.67512134 - samples/sec: 17.99\n",
            "2020-02-12 12:04:34,886 epoch 1 - iter 22/28 - loss 38.35536495 - samples/sec: 24.53\n",
            "2020-02-12 12:04:39,769 epoch 1 - iter 24/28 - loss 35.54435790 - samples/sec: 13.79\n",
            "2020-02-12 12:04:43,647 epoch 1 - iter 26/28 - loss 33.03787645 - samples/sec: 17.86\n",
            "2020-02-12 12:04:45,268 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 12:04:45,270 EPOCH 1 done: loss 31.9451 - lr 0.1000\n",
            "2020-02-12 12:04:52,616 DEV : loss 1.8937400579452515 - score 0.4913\n",
            "2020-02-12 12:04:52,642 BAD EPOCHS (no improvement): 0\n",
            "2020-02-12 12:07:50,341 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 12:07:51,705 epoch 2 - iter 0/28 - loss 3.77889013 - samples/sec: 47.02\n",
            "2020-02-12 12:08:02,773 epoch 2 - iter 2/28 - loss 2.91773526 - samples/sec: 22.76\n",
            "2020-02-12 12:08:08,889 epoch 2 - iter 4/28 - loss 3.15346832 - samples/sec: 24.38\n",
            "2020-02-12 12:08:16,538 epoch 2 - iter 6/28 - loss 3.21161706 - samples/sec: 18.45\n",
            "2020-02-12 12:08:23,138 epoch 2 - iter 8/28 - loss 3.10929807 - samples/sec: 26.85\n",
            "2020-02-12 12:08:29,678 epoch 2 - iter 10/28 - loss 3.17321660 - samples/sec: 26.46\n",
            "2020-02-12 12:08:35,384 epoch 2 - iter 12/28 - loss 3.08920303 - samples/sec: 27.57\n",
            "2020-02-12 12:08:41,931 epoch 2 - iter 14/28 - loss 3.06614838 - samples/sec: 29.46\n",
            "2020-02-12 12:08:48,990 epoch 2 - iter 16/28 - loss 3.01602115 - samples/sec: 28.65\n",
            "2020-02-12 12:08:56,065 epoch 2 - iter 18/28 - loss 2.96537815 - samples/sec: 25.59\n",
            "2020-02-12 12:09:02,031 epoch 2 - iter 20/28 - loss 2.90416064 - samples/sec: 26.93\n",
            "2020-02-12 12:09:08,922 epoch 2 - iter 22/28 - loss 2.87081895 - samples/sec: 36.32\n",
            "2020-02-12 12:09:17,329 epoch 2 - iter 24/28 - loss 2.80632483 - samples/sec: 23.97\n",
            "2020-02-12 12:09:23,694 epoch 2 - iter 26/28 - loss 2.83425574 - samples/sec: 26.29\n",
            "2020-02-12 12:09:30,270 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 12:09:30,273 EPOCH 2 done: loss 2.8074 - lr 0.1000\n",
            "2020-02-12 12:09:36,371 DEV : loss 1.2908084392547607 - score 0.6046\n",
            "2020-02-12 12:09:36,399 BAD EPOCHS (no improvement): 0\n",
            "2020-02-12 12:12:38,402 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 12:12:39,913 epoch 3 - iter 0/28 - loss 1.92600775 - samples/sec: 48.88\n",
            "2020-02-12 12:12:44,561 epoch 3 - iter 2/28 - loss 2.22497114 - samples/sec: 31.14\n",
            "2020-02-12 12:12:49,616 epoch 3 - iter 4/28 - loss 2.50949926 - samples/sec: 20.59\n",
            "2020-02-12 12:12:56,724 epoch 3 - iter 6/28 - loss 2.45741544 - samples/sec: 24.75\n",
            "2020-02-12 12:13:04,149 epoch 3 - iter 8/28 - loss 2.31739775 - samples/sec: 26.58\n",
            "2020-02-12 12:13:11,330 epoch 3 - iter 10/28 - loss 2.13717205 - samples/sec: 27.97\n",
            "2020-02-12 12:13:17,453 epoch 3 - iter 12/28 - loss 2.06319879 - samples/sec: 35.20\n",
            "2020-02-12 12:13:24,037 epoch 3 - iter 14/28 - loss 2.03108431 - samples/sec: 27.79\n",
            "2020-02-12 12:13:30,430 epoch 3 - iter 16/28 - loss 2.10665512 - samples/sec: 32.07\n",
            "2020-02-12 12:13:36,691 epoch 3 - iter 18/28 - loss 2.14260134 - samples/sec: 26.16\n",
            "2020-02-12 12:13:44,648 epoch 3 - iter 20/28 - loss 2.15844488 - samples/sec: 18.79\n",
            "2020-02-12 12:13:53,588 epoch 3 - iter 22/28 - loss 2.23021302 - samples/sec: 15.44\n",
            "2020-02-12 12:14:00,937 epoch 3 - iter 24/28 - loss 2.18886986 - samples/sec: 21.31\n",
            "2020-02-12 12:14:08,726 epoch 3 - iter 26/28 - loss 2.28996282 - samples/sec: 20.06\n",
            "2020-02-12 12:14:13,689 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 12:14:13,691 EPOCH 3 done: loss 2.3257 - lr 0.1000\n",
            "2020-02-12 12:14:20,046 DEV : loss 1.534300684928894 - score 0.5417\n",
            "2020-02-12 12:14:20,075 BAD EPOCHS (no improvement): 1\n",
            "2020-02-12 12:15:40,408 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 12:15:42,054 epoch 4 - iter 0/28 - loss 2.12833834 - samples/sec: 41.20\n",
            "2020-02-12 12:15:49,027 epoch 4 - iter 2/28 - loss 1.71242007 - samples/sec: 29.87\n",
            "2020-02-12 12:15:57,000 epoch 4 - iter 4/28 - loss 1.71863942 - samples/sec: 22.62\n",
            "2020-02-12 12:16:03,666 epoch 4 - iter 6/28 - loss 1.57027466 - samples/sec: 29.20\n",
            "2020-02-12 12:16:09,819 epoch 4 - iter 8/28 - loss 1.56866082 - samples/sec: 16.68\n",
            "2020-02-12 12:16:14,390 epoch 4 - iter 10/28 - loss 1.70500692 - samples/sec: 23.58\n",
            "2020-02-12 12:16:18,109 epoch 4 - iter 12/28 - loss 1.88885780 - samples/sec: 33.19\n",
            "2020-02-12 12:16:22,743 epoch 4 - iter 14/28 - loss 1.97950309 - samples/sec: 28.30\n",
            "2020-02-12 12:16:27,350 epoch 4 - iter 16/28 - loss 1.99805369 - samples/sec: 23.84\n",
            "2020-02-12 12:16:32,285 epoch 4 - iter 18/28 - loss 2.01416166 - samples/sec: 27.72\n",
            "2020-02-12 12:16:36,649 epoch 4 - iter 20/28 - loss 1.96886925 - samples/sec: 23.97\n",
            "2020-02-12 12:16:41,288 epoch 4 - iter 22/28 - loss 1.94386967 - samples/sec: 23.60\n",
            "2020-02-12 12:16:45,636 epoch 4 - iter 24/28 - loss 2.01089058 - samples/sec: 29.60\n",
            "2020-02-12 12:16:50,480 epoch 4 - iter 26/28 - loss 2.03674000 - samples/sec: 21.98\n",
            "2020-02-12 12:16:53,678 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 12:16:53,683 EPOCH 4 done: loss 2.0448 - lr 0.1000\n",
            "2020-02-12 12:16:59,814 DEV : loss 1.0905680656433105 - score 0.5957\n",
            "2020-02-12 12:16:59,847 BAD EPOCHS (no improvement): 2\n",
            "2020-02-12 12:18:19,745 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 12:18:21,203 epoch 5 - iter 0/28 - loss 1.83213806 - samples/sec: 44.04\n",
            "2020-02-12 12:18:25,667 epoch 5 - iter 2/28 - loss 2.46401278 - samples/sec: 31.74\n",
            "2020-02-12 12:18:30,723 epoch 5 - iter 4/28 - loss 2.37616806 - samples/sec: 24.84\n",
            "2020-02-12 12:18:34,851 epoch 5 - iter 6/28 - loss 2.20601307 - samples/sec: 30.39\n",
            "2020-02-12 12:18:39,878 epoch 5 - iter 8/28 - loss 2.27543767 - samples/sec: 21.87\n",
            "2020-02-12 12:18:44,738 epoch 5 - iter 10/28 - loss 2.18069996 - samples/sec: 21.39\n",
            "2020-02-12 12:18:49,496 epoch 5 - iter 12/28 - loss 2.16997101 - samples/sec: 21.79\n",
            "2020-02-12 12:18:52,398 epoch 5 - iter 14/28 - loss 2.05889443 - samples/sec: 24.80\n",
            "2020-02-12 12:18:55,301 epoch 5 - iter 16/28 - loss 2.01053868 - samples/sec: 24.70\n",
            "2020-02-12 12:18:58,009 epoch 5 - iter 18/28 - loss 1.99154082 - samples/sec: 26.60\n",
            "2020-02-12 12:19:00,501 epoch 5 - iter 20/28 - loss 1.94677325 - samples/sec: 29.85\n",
            "2020-02-12 12:19:03,748 epoch 5 - iter 22/28 - loss 1.94607653 - samples/sec: 21.79\n",
            "2020-02-12 12:19:06,498 epoch 5 - iter 24/28 - loss 1.88899700 - samples/sec: 26.40\n",
            "2020-02-12 12:19:11,183 epoch 5 - iter 26/28 - loss 1.86095928 - samples/sec: 14.70\n",
            "2020-02-12 12:19:12,857 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 12:19:12,858 EPOCH 5 done: loss 1.8834 - lr 0.1000\n",
            "2020-02-12 12:19:19,344 DEV : loss 1.1063761711120605 - score 0.6383\n",
            "2020-02-12 12:19:19,376 BAD EPOCHS (no improvement): 0\n",
            "2020-02-12 12:22:20,881 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 12:22:22,160 epoch 6 - iter 0/28 - loss 2.48485756 - samples/sec: 50.26\n",
            "2020-02-12 12:22:27,457 epoch 6 - iter 2/28 - loss 2.16098897 - samples/sec: 23.79\n",
            "2020-02-12 12:22:32,443 epoch 6 - iter 4/28 - loss 1.90390806 - samples/sec: 19.52\n",
            "2020-02-12 12:22:40,089 epoch 6 - iter 6/28 - loss 1.78448364 - samples/sec: 28.79\n",
            "2020-02-12 12:22:47,095 epoch 6 - iter 8/28 - loss 2.01308351 - samples/sec: 30.07\n",
            "2020-02-12 12:22:54,666 epoch 6 - iter 10/28 - loss 1.90748215 - samples/sec: 26.67\n",
            "2020-02-12 12:23:01,803 epoch 6 - iter 12/28 - loss 1.72352321 - samples/sec: 21.85\n",
            "2020-02-12 12:23:09,529 epoch 6 - iter 14/28 - loss 1.73974069 - samples/sec: 32.63\n",
            "2020-02-12 12:23:16,352 epoch 6 - iter 16/28 - loss 1.74971827 - samples/sec: 23.94\n",
            "2020-02-12 12:23:23,183 epoch 6 - iter 18/28 - loss 1.70225407 - samples/sec: 27.64\n",
            "2020-02-12 12:23:32,180 epoch 6 - iter 20/28 - loss 1.68987896 - samples/sec: 16.81\n",
            "2020-02-12 12:23:38,919 epoch 6 - iter 22/28 - loss 1.70564554 - samples/sec: 34.65\n",
            "2020-02-12 12:23:46,644 epoch 6 - iter 24/28 - loss 1.65587355 - samples/sec: 23.14\n",
            "2020-02-12 12:23:56,848 epoch 6 - iter 26/28 - loss 1.69565686 - samples/sec: 22.22\n",
            "2020-02-12 12:24:02,085 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 12:24:02,089 EPOCH 6 done: loss 1.6828 - lr 0.1000\n",
            "2020-02-12 12:24:08,309 DEV : loss 1.0710418224334717 - score 0.6364\n",
            "2020-02-12 12:24:08,336 BAD EPOCHS (no improvement): 1\n",
            "2020-02-12 12:25:29,452 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 12:25:31,050 epoch 7 - iter 0/28 - loss 1.06117010 - samples/sec: 40.15\n",
            "2020-02-12 12:25:37,259 epoch 7 - iter 2/28 - loss 1.35824919 - samples/sec: 21.69\n",
            "2020-02-12 12:25:43,676 epoch 7 - iter 4/28 - loss 1.33312855 - samples/sec: 17.03\n",
            "2020-02-12 12:25:48,659 epoch 7 - iter 6/28 - loss 1.35068171 - samples/sec: 28.45\n",
            "2020-02-12 12:25:53,731 epoch 7 - iter 8/28 - loss 1.50454378 - samples/sec: 21.29\n",
            "2020-02-12 12:25:57,818 epoch 7 - iter 10/28 - loss 1.52668272 - samples/sec: 35.50\n",
            "2020-02-12 12:26:02,432 epoch 7 - iter 12/28 - loss 1.56274231 - samples/sec: 26.37\n",
            "2020-02-12 12:26:07,936 epoch 7 - iter 14/28 - loss 1.56219708 - samples/sec: 23.45\n",
            "2020-02-12 12:26:12,120 epoch 7 - iter 16/28 - loss 1.55364368 - samples/sec: 27.83\n",
            "2020-02-12 12:26:17,272 epoch 7 - iter 18/28 - loss 1.57180204 - samples/sec: 24.04\n",
            "2020-02-12 12:26:21,542 epoch 7 - iter 20/28 - loss 1.55294868 - samples/sec: 30.03\n",
            "2020-02-12 12:26:26,384 epoch 7 - iter 22/28 - loss 1.55320671 - samples/sec: 27.01\n",
            "2020-02-12 12:26:31,195 epoch 7 - iter 24/28 - loss 1.51487972 - samples/sec: 32.32\n",
            "2020-02-12 12:26:36,764 epoch 7 - iter 26/28 - loss 1.54829726 - samples/sec: 23.18\n",
            "2020-02-12 12:26:39,725 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 12:26:39,729 EPOCH 7 done: loss 1.5696 - lr 0.1000\n",
            "2020-02-12 12:26:46,613 DEV : loss 1.1379661560058594 - score 0.5957\n",
            "2020-02-12 12:26:46,644 BAD EPOCHS (no improvement): 2\n",
            "2020-02-12 12:28:03,814 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 12:28:04,905 epoch 8 - iter 0/28 - loss 0.76823282 - samples/sec: 58.75\n",
            "2020-02-12 12:28:09,529 epoch 8 - iter 2/28 - loss 1.45540571 - samples/sec: 25.13\n",
            "2020-02-12 12:28:12,250 epoch 8 - iter 4/28 - loss 1.80818586 - samples/sec: 26.52\n",
            "2020-02-12 12:28:15,312 epoch 8 - iter 6/28 - loss 1.59915767 - samples/sec: 23.39\n",
            "2020-02-12 12:28:19,010 epoch 8 - iter 8/28 - loss 1.56147411 - samples/sec: 38.43\n",
            "2020-02-12 12:28:23,769 epoch 8 - iter 10/28 - loss 1.60899535 - samples/sec: 24.41\n",
            "2020-02-12 12:28:27,877 epoch 8 - iter 12/28 - loss 1.58325491 - samples/sec: 30.15\n",
            "2020-02-12 12:28:32,272 epoch 8 - iter 14/28 - loss 1.54535556 - samples/sec: 31.78\n",
            "2020-02-12 12:28:37,688 epoch 8 - iter 16/28 - loss 1.55616215 - samples/sec: 21.15\n",
            "2020-02-12 12:28:42,289 epoch 8 - iter 18/28 - loss 1.49666549 - samples/sec: 26.24\n",
            "2020-02-12 12:28:46,190 epoch 8 - iter 20/28 - loss 1.54102635 - samples/sec: 30.82\n",
            "2020-02-12 12:28:49,063 epoch 8 - iter 22/28 - loss 1.49762291 - samples/sec: 24.79\n",
            "2020-02-12 12:28:52,078 epoch 8 - iter 24/28 - loss 1.51030446 - samples/sec: 23.79\n",
            "2020-02-12 12:28:55,916 epoch 8 - iter 26/28 - loss 1.46532411 - samples/sec: 18.40\n",
            "2020-02-12 12:28:57,349 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 12:28:57,351 EPOCH 8 done: loss 1.4505 - lr 0.1000\n",
            "2020-02-12 12:29:03,950 DEV : loss 1.093630075454712 - score 0.5652\n",
            "2020-02-12 12:29:03,979 BAD EPOCHS (no improvement): 3\n",
            "2020-02-12 12:30:16,742 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 12:30:17,757 epoch 9 - iter 0/28 - loss 2.48275328 - samples/sec: 63.40\n",
            "2020-02-12 12:30:30,312 epoch 9 - iter 2/28 - loss 1.73766629 - samples/sec: 22.50\n",
            "2020-02-12 12:30:35,418 epoch 9 - iter 4/28 - loss 1.49119329 - samples/sec: 23.13\n",
            "2020-02-12 12:30:40,465 epoch 9 - iter 6/28 - loss 1.22499820 - samples/sec: 19.39\n",
            "2020-02-12 12:30:45,671 epoch 9 - iter 8/28 - loss 1.12809430 - samples/sec: 30.11\n",
            "2020-02-12 12:30:49,427 epoch 9 - iter 10/28 - loss 1.16548373 - samples/sec: 30.86\n",
            "2020-02-12 12:30:53,355 epoch 9 - iter 12/28 - loss 1.14518888 - samples/sec: 27.51\n",
            "2020-02-12 12:30:56,255 epoch 9 - iter 14/28 - loss 1.22543777 - samples/sec: 24.96\n",
            "2020-02-12 12:30:58,068 epoch 9 - iter 16/28 - loss 1.25575147 - samples/sec: 43.04\n",
            "2020-02-12 12:31:01,133 epoch 9 - iter 18/28 - loss 1.34285703 - samples/sec: 23.90\n",
            "2020-02-12 12:31:04,918 epoch 9 - iter 20/28 - loss 1.34857997 - samples/sec: 18.43\n",
            "2020-02-12 12:31:07,382 epoch 9 - iter 22/28 - loss 1.41921228 - samples/sec: 29.63\n",
            "2020-02-12 12:31:10,200 epoch 9 - iter 24/28 - loss 1.44192804 - samples/sec: 25.30\n",
            "2020-02-12 12:31:13,404 epoch 9 - iter 26/28 - loss 1.41356763 - samples/sec: 22.23\n",
            "2020-02-12 12:31:15,082 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 12:31:15,083 EPOCH 9 done: loss 1.3878 - lr 0.1000\n",
            "2020-02-12 12:31:21,460 DEV : loss 1.2034833431243896 - score 0.6364\n",
            "Epoch     9: reducing learning rate of group 0 to 5.0000e-02.\n",
            "2020-02-12 12:31:21,498 BAD EPOCHS (no improvement): 4\n",
            "2020-02-12 12:32:38,234 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 12:32:42,533 epoch 10 - iter 0/28 - loss 1.43430710 - samples/sec: 49.72\n",
            "2020-02-12 12:32:44,980 epoch 10 - iter 2/28 - loss 1.54480775 - samples/sec: 30.51\n",
            "2020-02-12 12:32:47,829 epoch 10 - iter 4/28 - loss 1.38448057 - samples/sec: 24.80\n",
            "2020-02-12 12:32:52,622 epoch 10 - iter 6/28 - loss 1.42438419 - samples/sec: 25.28\n",
            "2020-02-12 12:32:56,883 epoch 10 - iter 8/28 - loss 1.33343262 - samples/sec: 28.05\n",
            "2020-02-12 12:33:02,046 epoch 10 - iter 10/28 - loss 1.31083558 - samples/sec: 24.15\n",
            "2020-02-12 12:33:06,515 epoch 10 - iter 12/28 - loss 1.28797810 - samples/sec: 31.64\n",
            "2020-02-12 12:33:11,652 epoch 10 - iter 14/28 - loss 1.33476950 - samples/sec: 20.38\n",
            "2020-02-12 12:33:14,952 epoch 10 - iter 16/28 - loss 1.32372811 - samples/sec: 21.46\n",
            "2020-02-12 12:33:18,209 epoch 10 - iter 18/28 - loss 1.32935991 - samples/sec: 21.88\n",
            "2020-02-12 12:33:21,875 epoch 10 - iter 20/28 - loss 1.31417633 - samples/sec: 19.30\n",
            "2020-02-12 12:33:24,785 epoch 10 - iter 22/28 - loss 1.30643869 - samples/sec: 24.56\n",
            "2020-02-12 12:33:27,938 epoch 10 - iter 24/28 - loss 1.29513466 - samples/sec: 22.84\n",
            "2020-02-12 12:33:31,078 epoch 10 - iter 26/28 - loss 1.27227910 - samples/sec: 23.10\n",
            "2020-02-12 12:33:32,466 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 12:33:32,468 EPOCH 10 done: loss 1.2995 - lr 0.0500\n",
            "2020-02-12 12:33:38,762 DEV : loss 0.9159637689590454 - score 0.6087\n",
            "2020-02-12 12:33:38,790 BAD EPOCHS (no improvement): 1\n",
            "2020-02-12 12:34:52,774 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 12:34:53,751 epoch 11 - iter 0/28 - loss 0.84301233 - samples/sec: 65.77\n",
            "2020-02-12 12:35:02,875 epoch 11 - iter 2/28 - loss 1.04364204 - samples/sec: 21.91\n",
            "2020-02-12 12:35:07,231 epoch 11 - iter 4/28 - loss 1.21690102 - samples/sec: 29.95\n",
            "2020-02-12 12:35:12,368 epoch 11 - iter 6/28 - loss 1.27109909 - samples/sec: 25.79\n",
            "2020-02-12 12:35:16,863 epoch 11 - iter 8/28 - loss 1.21778822 - samples/sec: 34.12\n",
            "2020-02-12 12:35:21,698 epoch 11 - iter 10/28 - loss 1.26530045 - samples/sec: 24.64\n",
            "2020-02-12 12:35:26,724 epoch 11 - iter 12/28 - loss 1.29207285 - samples/sec: 21.94\n",
            "2020-02-12 12:35:29,777 epoch 11 - iter 14/28 - loss 1.26419786 - samples/sec: 23.32\n",
            "2020-02-12 12:35:32,196 epoch 11 - iter 16/28 - loss 1.25968546 - samples/sec: 29.95\n",
            "2020-02-12 12:35:34,795 epoch 11 - iter 18/28 - loss 1.24065580 - samples/sec: 27.88\n",
            "2020-02-12 12:35:37,520 epoch 11 - iter 20/28 - loss 1.24221220 - samples/sec: 26.56\n",
            "2020-02-12 12:35:41,506 epoch 11 - iter 22/28 - loss 1.20986302 - samples/sec: 17.50\n",
            "2020-02-12 12:35:44,481 epoch 11 - iter 24/28 - loss 1.19045448 - samples/sec: 24.67\n",
            "2020-02-12 12:35:48,072 epoch 11 - iter 26/28 - loss 1.19763104 - samples/sec: 19.70\n",
            "2020-02-12 12:35:49,829 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 12:35:49,830 EPOCH 11 done: loss 1.2180 - lr 0.0500\n",
            "2020-02-12 12:35:55,701 DEV : loss 0.8447059392929077 - score 0.6667\n",
            "2020-02-12 12:35:55,730 BAD EPOCHS (no improvement): 0\n",
            "2020-02-12 12:38:49,948 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 12:38:51,056 epoch 12 - iter 0/28 - loss 0.96967840 - samples/sec: 58.49\n",
            "2020-02-12 12:39:03,814 epoch 12 - iter 2/28 - loss 1.53477319 - samples/sec: 23.16\n",
            "2020-02-12 12:39:10,541 epoch 12 - iter 4/28 - loss 1.54488087 - samples/sec: 33.90\n",
            "2020-02-12 12:39:19,665 epoch 12 - iter 6/28 - loss 1.64842776 - samples/sec: 15.97\n",
            "2020-02-12 12:39:28,267 epoch 12 - iter 8/28 - loss 1.57184166 - samples/sec: 22.73\n",
            "2020-02-12 12:39:34,062 epoch 12 - iter 10/28 - loss 1.44809901 - samples/sec: 29.02\n",
            "2020-02-12 12:39:41,570 epoch 12 - iter 12/28 - loss 1.33488952 - samples/sec: 25.51\n",
            "2020-02-12 12:39:48,381 epoch 12 - iter 14/28 - loss 1.31016725 - samples/sec: 27.53\n",
            "2020-02-12 12:39:58,088 epoch 12 - iter 16/28 - loss 1.29407995 - samples/sec: 23.43\n",
            "2020-02-12 12:40:04,262 epoch 12 - iter 18/28 - loss 1.25424483 - samples/sec: 35.58\n",
            "2020-02-12 12:40:11,742 epoch 12 - iter 20/28 - loss 1.24601033 - samples/sec: 28.05\n",
            "2020-02-12 12:40:19,311 epoch 12 - iter 22/28 - loss 1.26082534 - samples/sec: 24.12\n",
            "2020-02-12 12:40:26,349 epoch 12 - iter 24/28 - loss 1.27707996 - samples/sec: 22.94\n",
            "2020-02-12 12:40:34,480 epoch 12 - iter 26/28 - loss 1.25604335 - samples/sec: 19.87\n",
            "2020-02-12 12:40:40,663 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 12:40:40,665 EPOCH 12 done: loss 1.2768 - lr 0.0500\n",
            "2020-02-12 12:40:46,873 DEV : loss 0.9329811334609985 - score 0.6087\n",
            "2020-02-12 12:40:46,902 BAD EPOCHS (no improvement): 1\n",
            "2020-02-12 12:42:10,121 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 12:42:11,221 epoch 13 - iter 0/28 - loss 0.64535093 - samples/sec: 58.50\n",
            "2020-02-12 12:42:14,720 epoch 13 - iter 2/28 - loss 1.09217580 - samples/sec: 26.00\n",
            "2020-02-12 12:42:17,986 epoch 13 - iter 4/28 - loss 1.14645262 - samples/sec: 21.33\n",
            "2020-02-12 12:42:20,862 epoch 13 - iter 6/28 - loss 1.07672453 - samples/sec: 24.43\n",
            "2020-02-12 12:42:23,527 epoch 13 - iter 8/28 - loss 1.01562039 - samples/sec: 27.28\n",
            "2020-02-12 12:42:28,864 epoch 13 - iter 10/28 - loss 1.04244119 - samples/sec: 25.27\n",
            "2020-02-12 12:42:34,495 epoch 13 - iter 12/28 - loss 1.11451420 - samples/sec: 22.39\n",
            "2020-02-12 12:42:40,803 epoch 13 - iter 14/28 - loss 1.05752881 - samples/sec: 16.54\n",
            "2020-02-12 12:42:44,892 epoch 13 - iter 16/28 - loss 1.05708063 - samples/sec: 27.28\n",
            "2020-02-12 12:42:49,478 epoch 13 - iter 18/28 - loss 1.06634368 - samples/sec: 24.20\n",
            "2020-02-12 12:42:53,722 epoch 13 - iter 20/28 - loss 1.12339837 - samples/sec: 29.37\n",
            "2020-02-12 12:42:58,879 epoch 13 - iter 22/28 - loss 1.12461828 - samples/sec: 22.50\n",
            "2020-02-12 12:43:05,570 epoch 13 - iter 24/28 - loss 1.16162725 - samples/sec: 20.36\n",
            "2020-02-12 12:43:09,556 epoch 13 - iter 26/28 - loss 1.18977884 - samples/sec: 35.21\n",
            "2020-02-12 12:43:12,695 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 12:43:12,697 EPOCH 13 done: loss 1.1658 - lr 0.0500\n",
            "2020-02-12 12:43:19,099 DEV : loss 0.9097737669944763 - score 0.625\n",
            "2020-02-12 12:43:19,126 BAD EPOCHS (no improvement): 2\n",
            "2020-02-12 12:44:31,888 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 12:44:33,120 epoch 14 - iter 0/28 - loss 0.56250429 - samples/sec: 52.05\n",
            "2020-02-12 12:44:36,118 epoch 14 - iter 2/28 - loss 0.71004629 - samples/sec: 24.38\n",
            "2020-02-12 12:44:39,150 epoch 14 - iter 4/28 - loss 1.02398949 - samples/sec: 23.62\n",
            "2020-02-12 12:44:45,543 epoch 14 - iter 6/28 - loss 1.05657761 - samples/sec: 30.29\n",
            "2020-02-12 12:44:50,168 epoch 14 - iter 8/28 - loss 1.13189936 - samples/sec: 28.68\n",
            "2020-02-12 12:44:54,822 epoch 14 - iter 10/28 - loss 1.14078067 - samples/sec: 26.77\n",
            "2020-02-12 12:44:59,864 epoch 14 - iter 12/28 - loss 1.09481973 - samples/sec: 20.44\n",
            "2020-02-12 12:45:04,842 epoch 14 - iter 14/28 - loss 1.06611293 - samples/sec: 23.55\n",
            "2020-02-12 12:45:10,555 epoch 14 - iter 16/28 - loss 1.04432723 - samples/sec: 15.94\n",
            "2020-02-12 12:45:15,645 epoch 14 - iter 18/28 - loss 1.07989728 - samples/sec: 29.06\n",
            "2020-02-12 12:45:18,407 epoch 14 - iter 20/28 - loss 1.14502664 - samples/sec: 26.38\n",
            "2020-02-12 12:45:21,213 epoch 14 - iter 22/28 - loss 1.13561649 - samples/sec: 25.61\n",
            "2020-02-12 12:45:24,779 epoch 14 - iter 24/28 - loss 1.13372257 - samples/sec: 19.72\n",
            "2020-02-12 12:45:27,116 epoch 14 - iter 26/28 - loss 1.21120040 - samples/sec: 31.40\n",
            "2020-02-12 12:45:28,533 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 12:45:28,534 EPOCH 14 done: loss 1.2322 - lr 0.0500\n",
            "2020-02-12 12:45:34,780 DEV : loss 1.089329481124878 - score 0.6\n",
            "2020-02-12 12:45:34,816 BAD EPOCHS (no improvement): 3\n",
            "2020-02-12 12:46:47,761 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 12:46:48,960 epoch 15 - iter 0/28 - loss 1.09511948 - samples/sec: 53.51\n",
            "2020-02-12 12:46:51,786 epoch 15 - iter 2/28 - loss 1.26086934 - samples/sec: 26.21\n",
            "2020-02-12 12:46:54,217 epoch 15 - iter 4/28 - loss 1.24983120 - samples/sec: 29.49\n",
            "2020-02-12 12:46:56,907 epoch 15 - iter 6/28 - loss 1.20211349 - samples/sec: 26.75\n",
            "2020-02-12 12:47:01,262 epoch 15 - iter 8/28 - loss 1.18865665 - samples/sec: 25.62\n",
            "2020-02-12 12:47:06,878 epoch 15 - iter 10/28 - loss 1.19099396 - samples/sec: 19.96\n",
            "2020-02-12 12:47:11,478 epoch 15 - iter 12/28 - loss 1.10681471 - samples/sec: 26.62\n",
            "2020-02-12 12:47:15,712 epoch 15 - iter 14/28 - loss 1.14392592 - samples/sec: 24.24\n",
            "2020-02-12 12:47:20,156 epoch 15 - iter 16/28 - loss 1.20677087 - samples/sec: 27.86\n",
            "2020-02-12 12:47:25,200 epoch 15 - iter 18/28 - loss 1.21971083 - samples/sec: 21.11\n",
            "2020-02-12 12:47:28,946 epoch 15 - iter 20/28 - loss 1.17810097 - samples/sec: 34.08\n",
            "2020-02-12 12:47:33,528 epoch 15 - iter 22/28 - loss 1.11719409 - samples/sec: 24.99\n",
            "2020-02-12 12:47:38,200 epoch 15 - iter 24/28 - loss 1.19131924 - samples/sec: 19.41\n",
            "2020-02-12 12:47:41,271 epoch 15 - iter 26/28 - loss 1.18058378 - samples/sec: 23.17\n",
            "2020-02-12 12:47:44,119 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 12:47:44,121 EPOCH 15 done: loss 1.2051 - lr 0.0500\n",
            "2020-02-12 12:47:50,739 DEV : loss 0.9606380462646484 - score 0.6522\n",
            "Epoch    15: reducing learning rate of group 0 to 2.5000e-02.\n",
            "2020-02-12 12:47:50,779 BAD EPOCHS (no improvement): 4\n",
            "2020-02-12 12:49:08,988 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 12:49:13,504 epoch 16 - iter 0/28 - loss 1.35292673 - samples/sec: 26.71\n",
            "2020-02-12 12:49:15,841 epoch 16 - iter 2/28 - loss 1.16530132 - samples/sec: 32.01\n",
            "2020-02-12 12:49:18,063 epoch 16 - iter 4/28 - loss 0.89934607 - samples/sec: 33.01\n",
            "2020-02-12 12:49:20,609 epoch 16 - iter 6/28 - loss 0.89481292 - samples/sec: 28.13\n",
            "2020-02-12 12:49:23,459 epoch 16 - iter 8/28 - loss 0.98618741 - samples/sec: 25.05\n",
            "2020-02-12 12:49:26,393 epoch 16 - iter 10/28 - loss 1.04262677 - samples/sec: 24.31\n",
            "2020-02-12 12:49:29,287 epoch 16 - iter 12/28 - loss 1.03209408 - samples/sec: 24.74\n",
            "2020-02-12 12:49:32,274 epoch 16 - iter 14/28 - loss 0.96865622 - samples/sec: 23.96\n",
            "2020-02-12 12:49:35,225 epoch 16 - iter 16/28 - loss 0.99636967 - samples/sec: 24.20\n",
            "2020-02-12 12:49:38,506 epoch 16 - iter 18/28 - loss 0.99595680 - samples/sec: 21.30\n",
            "2020-02-12 12:49:41,042 epoch 16 - iter 20/28 - loss 0.97700782 - samples/sec: 29.08\n",
            "2020-02-12 12:49:44,424 epoch 16 - iter 22/28 - loss 1.00529505 - samples/sec: 20.99\n",
            "2020-02-12 12:49:47,708 epoch 16 - iter 24/28 - loss 1.04819103 - samples/sec: 21.37\n",
            "2020-02-12 12:49:50,123 epoch 16 - iter 26/28 - loss 1.09745949 - samples/sec: 29.98\n",
            "2020-02-12 12:49:51,913 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 12:49:51,916 EPOCH 16 done: loss 1.1651 - lr 0.0250\n",
            "2020-02-12 12:49:58,241 DEV : loss 0.8758012056350708 - score 0.6522\n",
            "2020-02-12 12:49:58,273 BAD EPOCHS (no improvement): 1\n",
            "2020-02-12 12:51:17,648 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 12:51:18,772 epoch 17 - iter 0/28 - loss 1.43294907 - samples/sec: 57.11\n",
            "2020-02-12 12:51:22,707 epoch 17 - iter 2/28 - loss 1.38134114 - samples/sec: 28.27\n",
            "2020-02-12 12:51:25,054 epoch 17 - iter 4/28 - loss 1.20837479 - samples/sec: 31.42\n",
            "2020-02-12 12:51:29,102 epoch 17 - iter 6/28 - loss 1.23246138 - samples/sec: 30.13\n",
            "2020-02-12 12:51:34,049 epoch 17 - iter 8/28 - loss 1.19479354 - samples/sec: 21.52\n",
            "2020-02-12 12:51:38,780 epoch 17 - iter 10/28 - loss 1.15332838 - samples/sec: 22.02\n",
            "2020-02-12 12:51:44,643 epoch 17 - iter 12/28 - loss 1.12687313 - samples/sec: 25.83\n",
            "2020-02-12 12:51:49,395 epoch 17 - iter 14/28 - loss 1.20741282 - samples/sec: 26.31\n",
            "2020-02-12 12:51:54,254 epoch 17 - iter 16/28 - loss 1.19773015 - samples/sec: 24.84\n",
            "2020-02-12 12:51:59,909 epoch 17 - iter 18/28 - loss 1.26621849 - samples/sec: 17.64\n",
            "2020-02-12 12:52:04,736 epoch 17 - iter 20/28 - loss 1.26905655 - samples/sec: 22.36\n",
            "2020-02-12 12:52:06,902 epoch 17 - iter 22/28 - loss 1.22162214 - samples/sec: 34.06\n",
            "2020-02-12 12:52:09,590 epoch 17 - iter 24/28 - loss 1.19931946 - samples/sec: 26.86\n",
            "2020-02-12 12:52:12,626 epoch 17 - iter 26/28 - loss 1.17584758 - samples/sec: 22.96\n",
            "2020-02-12 12:52:13,829 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 12:52:13,831 EPOCH 17 done: loss 1.1442 - lr 0.0250\n",
            "2020-02-12 12:52:19,755 DEV : loss 0.8392883539199829 - score 0.6667\n",
            "2020-02-12 12:52:19,786 BAD EPOCHS (no improvement): 2\n",
            "2020-02-12 12:55:14,003 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 12:55:15,017 epoch 18 - iter 0/28 - loss 1.03678894 - samples/sec: 63.99\n",
            "2020-02-12 12:55:29,483 epoch 18 - iter 2/28 - loss 0.98034763 - samples/sec: 17.41\n",
            "2020-02-12 12:55:36,552 epoch 18 - iter 4/28 - loss 1.02924128 - samples/sec: 25.20\n",
            "2020-02-12 12:55:44,196 epoch 18 - iter 6/28 - loss 1.06091118 - samples/sec: 23.79\n",
            "2020-02-12 12:55:51,219 epoch 18 - iter 8/28 - loss 1.03089147 - samples/sec: 35.36\n",
            "2020-02-12 12:55:58,626 epoch 18 - iter 10/28 - loss 1.03915349 - samples/sec: 27.53\n",
            "2020-02-12 12:56:05,193 epoch 18 - iter 12/28 - loss 1.05231509 - samples/sec: 26.79\n",
            "2020-02-12 12:56:11,886 epoch 18 - iter 14/28 - loss 1.10947059 - samples/sec: 29.36\n",
            "2020-02-12 12:56:18,149 epoch 18 - iter 16/28 - loss 1.07992054 - samples/sec: 31.40\n",
            "2020-02-12 12:56:24,837 epoch 18 - iter 18/28 - loss 1.11332153 - samples/sec: 26.37\n",
            "2020-02-12 12:56:31,918 epoch 18 - iter 20/28 - loss 1.09172083 - samples/sec: 21.98\n",
            "2020-02-12 12:56:40,014 epoch 18 - iter 22/28 - loss 1.05730277 - samples/sec: 20.62\n",
            "2020-02-12 12:56:45,904 epoch 18 - iter 24/28 - loss 1.06214142 - samples/sec: 33.90\n",
            "2020-02-12 12:56:53,074 epoch 18 - iter 26/28 - loss 1.05156747 - samples/sec: 26.98\n",
            "2020-02-12 12:56:58,570 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 12:56:58,572 EPOCH 18 done: loss 1.0473 - lr 0.0250\n",
            "2020-02-12 12:57:04,721 DEV : loss 0.8730940818786621 - score 0.6522\n",
            "2020-02-12 12:57:04,753 BAD EPOCHS (no improvement): 3\n",
            "2020-02-12 12:58:29,899 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 12:58:31,002 epoch 19 - iter 0/28 - loss 1.01241875 - samples/sec: 64.68\n",
            "2020-02-12 12:58:36,794 epoch 19 - iter 2/28 - loss 1.39466397 - samples/sec: 23.73\n",
            "2020-02-12 12:58:41,304 epoch 19 - iter 4/28 - loss 1.26662359 - samples/sec: 18.13\n",
            "2020-02-12 12:58:46,459 epoch 19 - iter 6/28 - loss 1.24155739 - samples/sec: 23.01\n",
            "2020-02-12 12:58:52,627 epoch 19 - iter 8/28 - loss 1.27357075 - samples/sec: 23.32\n",
            "2020-02-12 12:58:57,122 epoch 19 - iter 10/28 - loss 1.16323692 - samples/sec: 27.26\n",
            "2020-02-12 12:59:01,867 epoch 19 - iter 12/28 - loss 1.09258289 - samples/sec: 25.58\n",
            "2020-02-12 12:59:05,914 epoch 19 - iter 14/28 - loss 1.11741190 - samples/sec: 32.96\n",
            "2020-02-12 12:59:10,451 epoch 19 - iter 16/28 - loss 1.10884922 - samples/sec: 28.20\n",
            "2020-02-12 12:59:14,638 epoch 19 - iter 18/28 - loss 1.08953511 - samples/sec: 26.02\n",
            "2020-02-12 12:59:18,849 epoch 19 - iter 20/28 - loss 1.05509111 - samples/sec: 24.77\n",
            "2020-02-12 12:59:24,331 epoch 19 - iter 22/28 - loss 1.04965929 - samples/sec: 29.63\n",
            "2020-02-12 12:59:29,799 epoch 19 - iter 24/28 - loss 1.06750946 - samples/sec: 26.32\n",
            "2020-02-12 12:59:35,294 epoch 19 - iter 26/28 - loss 1.03139476 - samples/sec: 26.49\n",
            "2020-02-12 12:59:38,026 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 12:59:38,028 EPOCH 19 done: loss 1.0296 - lr 0.0250\n",
            "2020-02-12 12:59:44,227 DEV : loss 1.0254590511322021 - score 0.5715\n",
            "Epoch    19: reducing learning rate of group 0 to 1.2500e-02.\n",
            "2020-02-12 12:59:44,274 BAD EPOCHS (no improvement): 4\n",
            "2020-02-12 13:00:58,141 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 13:00:59,041 epoch 20 - iter 0/28 - loss 2.50272989 - samples/sec: 71.36\n",
            "2020-02-12 13:01:01,341 epoch 20 - iter 2/28 - loss 1.47563966 - samples/sec: 33.25\n",
            "2020-02-12 13:01:10,864 epoch 20 - iter 4/28 - loss 1.09569969 - samples/sec: 22.26\n",
            "2020-02-12 13:01:15,339 epoch 20 - iter 6/28 - loss 1.10252544 - samples/sec: 29.62\n",
            "2020-02-12 13:01:19,399 epoch 20 - iter 8/28 - loss 1.08691247 - samples/sec: 29.03\n",
            "2020-02-12 13:01:24,710 epoch 20 - iter 10/28 - loss 1.09488279 - samples/sec: 19.23\n",
            "2020-02-12 13:01:29,302 epoch 20 - iter 12/28 - loss 1.12637623 - samples/sec: 28.87\n",
            "2020-02-12 13:01:33,607 epoch 20 - iter 14/28 - loss 1.13359769 - samples/sec: 27.65\n",
            "2020-02-12 13:01:38,335 epoch 20 - iter 16/28 - loss 1.07052854 - samples/sec: 22.56\n",
            "2020-02-12 13:01:42,644 epoch 20 - iter 18/28 - loss 1.03849434 - samples/sec: 34.40\n",
            "2020-02-12 13:01:48,168 epoch 20 - iter 20/28 - loss 1.03298998 - samples/sec: 20.13\n",
            "2020-02-12 13:01:53,661 epoch 20 - iter 22/28 - loss 1.03597058 - samples/sec: 24.99\n",
            "2020-02-12 13:01:58,298 epoch 20 - iter 24/28 - loss 1.03186903 - samples/sec: 25.50\n",
            "2020-02-12 13:02:03,445 epoch 20 - iter 26/28 - loss 1.01660271 - samples/sec: 21.62\n",
            "2020-02-12 13:02:06,816 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 13:02:06,820 EPOCH 20 done: loss 1.0404 - lr 0.0125\n",
            "2020-02-12 13:02:13,006 DEV : loss 0.8591005802154541 - score 0.6667\n",
            "2020-02-12 13:02:13,034 BAD EPOCHS (no improvement): 1\n",
            "2020-02-12 13:05:08,070 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 13:05:09,205 epoch 21 - iter 0/28 - loss 0.73085690 - samples/sec: 56.68\n",
            "2020-02-12 13:05:20,425 epoch 21 - iter 2/28 - loss 1.13940795 - samples/sec: 24.68\n",
            "2020-02-12 13:05:27,770 epoch 21 - iter 4/28 - loss 1.05519114 - samples/sec: 19.77\n",
            "2020-02-12 13:05:35,414 epoch 21 - iter 6/28 - loss 1.08186919 - samples/sec: 24.75\n",
            "2020-02-12 13:05:42,441 epoch 21 - iter 8/28 - loss 0.98974344 - samples/sec: 23.55\n",
            "2020-02-12 13:05:50,178 epoch 21 - iter 10/28 - loss 1.01832264 - samples/sec: 20.98\n",
            "2020-02-12 13:05:56,306 epoch 21 - iter 12/28 - loss 1.05544941 - samples/sec: 32.47\n",
            "2020-02-12 13:06:04,141 epoch 21 - iter 14/28 - loss 1.04184453 - samples/sec: 31.75\n",
            "2020-02-12 13:06:11,340 epoch 21 - iter 16/28 - loss 0.99831051 - samples/sec: 27.67\n",
            "2020-02-12 13:06:19,628 epoch 21 - iter 18/28 - loss 1.02293948 - samples/sec: 17.32\n",
            "2020-02-12 13:06:26,147 epoch 21 - iter 20/28 - loss 1.03650266 - samples/sec: 28.83\n",
            "2020-02-12 13:06:32,953 epoch 21 - iter 22/28 - loss 1.01576726 - samples/sec: 30.31\n",
            "2020-02-12 13:06:38,802 epoch 21 - iter 24/28 - loss 1.02048857 - samples/sec: 36.10\n",
            "2020-02-12 13:06:46,078 epoch 21 - iter 26/28 - loss 0.99990317 - samples/sec: 32.85\n",
            "2020-02-12 13:06:51,059 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 13:06:51,060 EPOCH 21 done: loss 1.0619 - lr 0.0125\n",
            "2020-02-12 13:06:57,218 DEV : loss 0.925438642501831 - score 0.6383\n",
            "2020-02-12 13:06:57,251 BAD EPOCHS (no improvement): 2\n",
            "2020-02-12 13:08:19,328 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 13:08:20,537 epoch 22 - iter 0/28 - loss 1.04306030 - samples/sec: 53.37\n",
            "2020-02-12 13:08:26,530 epoch 22 - iter 2/28 - loss 0.97592815 - samples/sec: 27.36\n",
            "2020-02-12 13:08:30,800 epoch 22 - iter 4/28 - loss 0.92833462 - samples/sec: 26.51\n",
            "2020-02-12 13:08:34,037 epoch 22 - iter 6/28 - loss 0.95465081 - samples/sec: 41.26\n",
            "2020-02-12 13:08:38,821 epoch 22 - iter 8/28 - loss 0.98396587 - samples/sec: 24.32\n",
            "2020-02-12 13:08:43,429 epoch 22 - iter 10/28 - loss 1.09486918 - samples/sec: 27.27\n",
            "2020-02-12 13:08:47,824 epoch 22 - iter 12/28 - loss 1.10683819 - samples/sec: 24.40\n",
            "2020-02-12 13:08:52,315 epoch 22 - iter 14/28 - loss 1.05248712 - samples/sec: 27.51\n",
            "2020-02-12 13:08:56,505 epoch 22 - iter 16/28 - loss 1.07294851 - samples/sec: 26.42\n",
            "2020-02-12 13:09:01,649 epoch 22 - iter 18/28 - loss 1.06022125 - samples/sec: 19.09\n",
            "2020-02-12 13:09:05,537 epoch 22 - iter 20/28 - loss 1.04123277 - samples/sec: 31.23\n",
            "2020-02-12 13:09:11,347 epoch 22 - iter 22/28 - loss 1.04861529 - samples/sec: 16.63\n",
            "2020-02-12 13:09:15,892 epoch 22 - iter 24/28 - loss 1.03807449 - samples/sec: 37.50\n",
            "2020-02-12 13:09:21,156 epoch 22 - iter 26/28 - loss 1.04211341 - samples/sec: 22.43\n",
            "2020-02-12 13:09:24,147 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 13:09:24,149 EPOCH 22 done: loss 1.0404 - lr 0.0125\n",
            "2020-02-12 13:09:30,896 DEV : loss 0.9465142488479614 - score 0.625\n",
            "2020-02-12 13:09:30,928 BAD EPOCHS (no improvement): 3\n",
            "2020-02-12 13:10:50,053 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 13:10:51,211 epoch 23 - iter 0/28 - loss 0.44516468 - samples/sec: 55.53\n",
            "2020-02-12 13:10:54,112 epoch 23 - iter 2/28 - loss 0.85985565 - samples/sec: 25.53\n",
            "2020-02-12 13:10:56,365 epoch 23 - iter 4/28 - loss 0.77783155 - samples/sec: 32.48\n",
            "2020-02-12 13:10:59,091 epoch 23 - iter 6/28 - loss 0.86412423 - samples/sec: 26.11\n",
            "2020-02-12 13:11:02,452 epoch 23 - iter 8/28 - loss 0.85965421 - samples/sec: 20.48\n",
            "2020-02-12 13:11:07,110 epoch 23 - iter 10/28 - loss 0.83170674 - samples/sec: 28.90\n",
            "2020-02-12 13:11:09,316 epoch 23 - iter 12/28 - loss 0.89075686 - samples/sec: 34.94\n",
            "2020-02-12 13:11:14,446 epoch 23 - iter 14/28 - loss 0.91933861 - samples/sec: 19.07\n",
            "2020-02-12 13:11:18,341 epoch 23 - iter 16/28 - loss 0.95369204 - samples/sec: 29.88\n",
            "2020-02-12 13:11:23,077 epoch 23 - iter 18/28 - loss 1.00938077 - samples/sec: 21.51\n",
            "2020-02-12 13:11:27,011 epoch 23 - iter 20/28 - loss 1.02293001 - samples/sec: 37.06\n",
            "2020-02-12 13:11:31,976 epoch 23 - iter 22/28 - loss 1.06011890 - samples/sec: 24.83\n",
            "2020-02-12 13:11:37,377 epoch 23 - iter 24/28 - loss 1.06429436 - samples/sec: 24.83\n",
            "2020-02-12 13:11:42,165 epoch 23 - iter 26/28 - loss 1.02411904 - samples/sec: 24.91\n",
            "2020-02-12 13:11:45,779 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 13:11:45,781 EPOCH 23 done: loss 1.0138 - lr 0.0125\n",
            "2020-02-12 13:11:52,269 DEV : loss 0.9412230849266052 - score 0.625\n",
            "Epoch    23: reducing learning rate of group 0 to 6.2500e-03.\n",
            "2020-02-12 13:11:52,388 BAD EPOCHS (no improvement): 4\n",
            "2020-02-12 13:13:14,172 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 13:13:15,552 epoch 24 - iter 0/28 - loss 0.63631773 - samples/sec: 46.49\n",
            "2020-02-12 13:13:18,668 epoch 24 - iter 2/28 - loss 1.31545782 - samples/sec: 22.87\n",
            "2020-02-12 13:13:21,672 epoch 24 - iter 4/28 - loss 1.18493385 - samples/sec: 23.08\n",
            "2020-02-12 13:13:26,806 epoch 24 - iter 6/28 - loss 1.34634100 - samples/sec: 26.42\n",
            "2020-02-12 13:13:31,341 epoch 24 - iter 8/28 - loss 1.23205784 - samples/sec: 32.72\n",
            "2020-02-12 13:13:35,778 epoch 24 - iter 10/28 - loss 1.17659686 - samples/sec: 27.91\n",
            "2020-02-12 13:13:40,538 epoch 24 - iter 12/28 - loss 1.11812071 - samples/sec: 32.71\n",
            "2020-02-12 13:13:45,630 epoch 24 - iter 14/28 - loss 1.12491051 - samples/sec: 24.19\n",
            "2020-02-12 13:13:51,202 epoch 24 - iter 16/28 - loss 1.08577047 - samples/sec: 19.35\n",
            "2020-02-12 13:13:55,744 epoch 24 - iter 18/28 - loss 1.07323172 - samples/sec: 24.14\n",
            "2020-02-12 13:13:59,566 epoch 24 - iter 20/28 - loss 1.00429433 - samples/sec: 26.96\n",
            "2020-02-12 13:14:04,456 epoch 24 - iter 22/28 - loss 0.98816337 - samples/sec: 21.57\n",
            "2020-02-12 13:14:08,704 epoch 24 - iter 24/28 - loss 1.00209278 - samples/sec: 25.34\n",
            "2020-02-12 13:14:12,290 epoch 24 - iter 26/28 - loss 1.01809357 - samples/sec: 30.29\n",
            "2020-02-12 13:14:15,105 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 13:14:15,106 EPOCH 24 done: loss 1.0004 - lr 0.0063\n",
            "2020-02-12 13:14:21,329 DEV : loss 0.9350283145904541 - score 0.625\n",
            "2020-02-12 13:14:21,359 BAD EPOCHS (no improvement): 1\n",
            "2020-02-12 13:15:40,997 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 13:15:42,698 epoch 25 - iter 0/28 - loss 0.26884556 - samples/sec: 37.76\n",
            "2020-02-12 13:15:45,811 epoch 25 - iter 2/28 - loss 0.91556994 - samples/sec: 23.11\n",
            "2020-02-12 13:15:48,832 epoch 25 - iter 4/28 - loss 0.91086054 - samples/sec: 23.67\n",
            "2020-02-12 13:15:53,192 epoch 25 - iter 6/28 - loss 0.93866920 - samples/sec: 27.48\n",
            "2020-02-12 13:15:58,052 epoch 25 - iter 8/28 - loss 1.01366064 - samples/sec: 24.75\n",
            "2020-02-12 13:16:02,530 epoch 25 - iter 10/28 - loss 1.14069223 - samples/sec: 29.51\n",
            "2020-02-12 13:16:07,497 epoch 25 - iter 12/28 - loss 1.15994670 - samples/sec: 23.55\n",
            "2020-02-12 13:16:11,602 epoch 25 - iter 14/28 - loss 1.08062283 - samples/sec: 31.46\n",
            "2020-02-12 13:16:17,478 epoch 25 - iter 16/28 - loss 1.09909658 - samples/sec: 17.68\n",
            "2020-02-12 13:16:21,441 epoch 25 - iter 18/28 - loss 1.06017301 - samples/sec: 32.34\n",
            "2020-02-12 13:16:24,840 epoch 25 - iter 20/28 - loss 1.05738642 - samples/sec: 21.04\n",
            "2020-02-12 13:16:27,822 epoch 25 - iter 22/28 - loss 1.02653829 - samples/sec: 24.84\n",
            "2020-02-12 13:16:30,753 epoch 25 - iter 24/28 - loss 1.03285631 - samples/sec: 24.59\n",
            "2020-02-12 13:16:33,481 epoch 25 - iter 26/28 - loss 1.03035141 - samples/sec: 26.72\n",
            "2020-02-12 13:16:35,302 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 13:16:35,306 EPOCH 25 done: loss 1.0241 - lr 0.0063\n",
            "2020-02-12 13:16:41,471 DEV : loss 0.9375410079956055 - score 0.6383\n",
            "2020-02-12 13:16:41,506 BAD EPOCHS (no improvement): 2\n",
            "2020-02-12 13:18:02,025 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 13:18:03,251 epoch 26 - iter 0/28 - loss 1.13865185 - samples/sec: 52.62\n",
            "2020-02-12 13:18:06,216 epoch 26 - iter 2/28 - loss 1.43034951 - samples/sec: 27.33\n",
            "2020-02-12 13:18:09,464 epoch 26 - iter 4/28 - loss 1.20864868 - samples/sec: 21.83\n",
            "2020-02-12 13:18:14,137 epoch 26 - iter 6/28 - loss 1.18492753 - samples/sec: 25.53\n",
            "2020-02-12 13:18:19,262 epoch 26 - iter 8/28 - loss 1.15308343 - samples/sec: 23.52\n",
            "2020-02-12 13:18:23,794 epoch 26 - iter 10/28 - loss 1.14878537 - samples/sec: 25.06\n",
            "2020-02-12 13:18:28,024 epoch 26 - iter 12/28 - loss 1.08551645 - samples/sec: 30.95\n",
            "2020-02-12 13:18:31,937 epoch 26 - iter 14/28 - loss 1.02765090 - samples/sec: 32.20\n",
            "2020-02-12 13:18:37,724 epoch 26 - iter 16/28 - loss 1.05249256 - samples/sec: 17.85\n",
            "2020-02-12 13:18:41,930 epoch 26 - iter 18/28 - loss 1.03737932 - samples/sec: 32.30\n",
            "2020-02-12 13:18:46,572 epoch 26 - iter 20/28 - loss 0.99202397 - samples/sec: 24.45\n",
            "2020-02-12 13:18:50,870 epoch 26 - iter 22/28 - loss 1.00639607 - samples/sec: 30.08\n",
            "2020-02-12 13:18:55,281 epoch 26 - iter 24/28 - loss 1.01639355 - samples/sec: 28.57\n",
            "2020-02-12 13:18:58,795 epoch 26 - iter 26/28 - loss 1.01209321 - samples/sec: 19.80\n",
            "2020-02-12 13:19:00,159 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 13:19:00,161 EPOCH 26 done: loss 1.0288 - lr 0.0063\n",
            "2020-02-12 13:19:06,204 DEV : loss 0.9439736604690552 - score 0.6383\n",
            "2020-02-12 13:19:06,234 BAD EPOCHS (no improvement): 3\n",
            "2020-02-12 13:20:21,007 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 13:20:23,410 epoch 27 - iter 0/28 - loss 0.53447104 - samples/sec: 26.70\n",
            "2020-02-12 13:20:25,979 epoch 27 - iter 2/28 - loss 0.88415019 - samples/sec: 28.91\n",
            "2020-02-12 13:20:28,574 epoch 27 - iter 4/28 - loss 0.85816689 - samples/sec: 27.68\n",
            "2020-02-12 13:20:31,187 epoch 27 - iter 6/28 - loss 0.80954238 - samples/sec: 27.64\n",
            "2020-02-12 13:20:35,686 epoch 27 - iter 8/28 - loss 0.81036875 - samples/sec: 27.37\n",
            "2020-02-12 13:20:40,487 epoch 27 - iter 10/28 - loss 0.92901386 - samples/sec: 22.70\n",
            "2020-02-12 13:20:44,830 epoch 27 - iter 12/28 - loss 1.02190429 - samples/sec: 28.15\n",
            "2020-02-12 13:20:49,281 epoch 27 - iter 14/28 - loss 1.01017230 - samples/sec: 26.38\n",
            "2020-02-12 13:20:53,066 epoch 27 - iter 16/28 - loss 0.94493524 - samples/sec: 39.82\n",
            "2020-02-12 13:20:58,204 epoch 27 - iter 18/28 - loss 1.00171114 - samples/sec: 36.51\n",
            "2020-02-12 13:21:04,261 epoch 27 - iter 20/28 - loss 1.00126235 - samples/sec: 20.06\n",
            "2020-02-12 13:21:09,493 epoch 27 - iter 22/28 - loss 1.00022177 - samples/sec: 24.26\n",
            "2020-02-12 13:21:13,561 epoch 27 - iter 24/28 - loss 0.97467714 - samples/sec: 24.55\n",
            "2020-02-12 13:21:17,898 epoch 27 - iter 26/28 - loss 0.97628486 - samples/sec: 29.83\n",
            "2020-02-12 13:21:21,298 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 13:21:21,302 EPOCH 27 done: loss 0.9907 - lr 0.0063\n",
            "2020-02-12 13:21:29,204 DEV : loss 1.0151925086975098 - score 0.625\n",
            "Epoch    27: reducing learning rate of group 0 to 3.1250e-03.\n",
            "2020-02-12 13:21:29,232 BAD EPOCHS (no improvement): 4\n",
            "2020-02-12 13:22:42,551 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 13:22:43,827 epoch 28 - iter 0/28 - loss 1.08014059 - samples/sec: 50.27\n",
            "2020-02-12 13:22:55,849 epoch 28 - iter 2/28 - loss 0.77142270 - samples/sec: 21.85\n",
            "2020-02-12 13:23:00,474 epoch 28 - iter 4/28 - loss 0.80526237 - samples/sec: 22.48\n",
            "2020-02-12 13:23:04,000 epoch 28 - iter 6/28 - loss 0.82529177 - samples/sec: 42.83\n",
            "2020-02-12 13:23:08,523 epoch 28 - iter 8/28 - loss 0.81566350 - samples/sec: 21.99\n",
            "2020-02-12 13:23:12,621 epoch 28 - iter 10/28 - loss 0.83903729 - samples/sec: 27.91\n",
            "2020-02-12 13:23:17,324 epoch 28 - iter 12/28 - loss 0.83100961 - samples/sec: 25.39\n",
            "2020-02-12 13:23:21,775 epoch 28 - iter 14/28 - loss 0.87334871 - samples/sec: 27.10\n",
            "2020-02-12 13:23:25,384 epoch 28 - iter 16/28 - loss 0.91635766 - samples/sec: 35.94\n",
            "2020-02-12 13:23:30,938 epoch 28 - iter 18/28 - loss 0.89216938 - samples/sec: 27.47\n",
            "2020-02-12 13:23:35,617 epoch 28 - iter 20/28 - loss 0.91817145 - samples/sec: 33.58\n",
            "2020-02-12 13:23:40,527 epoch 28 - iter 22/28 - loss 0.91466479 - samples/sec: 25.48\n",
            "2020-02-12 13:23:44,728 epoch 28 - iter 24/28 - loss 0.92786816 - samples/sec: 25.49\n",
            "2020-02-12 13:23:50,699 epoch 28 - iter 26/28 - loss 0.97312201 - samples/sec: 16.93\n",
            "2020-02-12 13:23:54,395 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 13:23:54,397 EPOCH 28 done: loss 0.9501 - lr 0.0031\n",
            "2020-02-12 13:24:00,701 DEV : loss 0.9612731337547302 - score 0.625\n",
            "2020-02-12 13:24:00,735 BAD EPOCHS (no improvement): 1\n",
            "2020-02-12 13:25:21,792 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 13:25:23,123 epoch 29 - iter 0/28 - loss 1.01019859 - samples/sec: 48.28\n",
            "2020-02-12 13:25:26,295 epoch 29 - iter 2/28 - loss 1.11444235 - samples/sec: 22.79\n",
            "2020-02-12 13:25:28,754 epoch 29 - iter 4/28 - loss 1.01889887 - samples/sec: 28.75\n",
            "2020-02-12 13:25:31,672 epoch 29 - iter 6/28 - loss 1.07552978 - samples/sec: 24.49\n",
            "2020-02-12 13:25:36,374 epoch 29 - iter 8/28 - loss 0.97187127 - samples/sec: 23.65\n",
            "2020-02-12 13:25:40,731 epoch 29 - iter 10/28 - loss 0.96480287 - samples/sec: 25.89\n",
            "2020-02-12 13:25:45,747 epoch 29 - iter 12/28 - loss 0.97452505 - samples/sec: 23.73\n",
            "2020-02-12 13:25:50,299 epoch 29 - iter 14/28 - loss 0.96358665 - samples/sec: 25.14\n",
            "2020-02-12 13:25:55,432 epoch 29 - iter 16/28 - loss 0.97821881 - samples/sec: 26.95\n",
            "2020-02-12 13:26:00,208 epoch 29 - iter 18/28 - loss 1.00762483 - samples/sec: 27.32\n",
            "2020-02-12 13:26:05,001 epoch 29 - iter 20/28 - loss 1.03014149 - samples/sec: 28.48\n",
            "2020-02-12 13:26:08,757 epoch 29 - iter 22/28 - loss 1.05607120 - samples/sec: 26.83\n",
            "2020-02-12 13:26:13,058 epoch 29 - iter 24/28 - loss 1.04217888 - samples/sec: 25.73\n",
            "2020-02-12 13:26:19,285 epoch 29 - iter 26/28 - loss 1.04700534 - samples/sec: 16.73\n",
            "2020-02-12 13:26:22,751 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 13:26:22,755 EPOCH 29 done: loss 1.0286 - lr 0.0031\n",
            "2020-02-12 13:26:28,667 DEV : loss 0.9906498193740845 - score 0.625\n",
            "2020-02-12 13:26:28,699 BAD EPOCHS (no improvement): 2\n",
            "2020-02-12 13:27:43,254 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 13:27:44,678 epoch 30 - iter 0/28 - loss 0.90982580 - samples/sec: 45.06\n",
            "2020-02-12 13:27:48,668 epoch 30 - iter 2/28 - loss 0.78314336 - samples/sec: 17.77\n",
            "2020-02-12 13:27:51,313 epoch 30 - iter 4/28 - loss 0.80829935 - samples/sec: 27.12\n",
            "2020-02-12 13:27:54,093 epoch 30 - iter 6/28 - loss 0.72692517 - samples/sec: 25.72\n",
            "2020-02-12 13:27:59,059 epoch 30 - iter 8/28 - loss 0.79980718 - samples/sec: 23.11\n",
            "2020-02-12 13:28:04,503 epoch 30 - iter 10/28 - loss 0.85678738 - samples/sec: 28.85\n",
            "2020-02-12 13:28:09,095 epoch 30 - iter 12/28 - loss 0.88834656 - samples/sec: 27.91\n",
            "2020-02-12 13:28:13,865 epoch 30 - iter 14/28 - loss 1.03574578 - samples/sec: 26.85\n",
            "2020-02-12 13:28:18,906 epoch 30 - iter 16/28 - loss 1.03347001 - samples/sec: 24.45\n",
            "2020-02-12 13:28:22,860 epoch 30 - iter 18/28 - loss 1.03789997 - samples/sec: 32.59\n",
            "2020-02-12 13:28:27,893 epoch 30 - iter 20/28 - loss 1.04341920 - samples/sec: 25.44\n",
            "2020-02-12 13:28:33,114 epoch 30 - iter 22/28 - loss 1.04809917 - samples/sec: 24.40\n",
            "2020-02-12 13:28:38,278 epoch 30 - iter 24/28 - loss 1.02435488 - samples/sec: 24.71\n",
            "2020-02-12 13:28:42,436 epoch 30 - iter 26/28 - loss 1.00429070 - samples/sec: 27.24\n",
            "2020-02-12 13:28:45,669 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 13:28:45,671 EPOCH 30 done: loss 0.9960 - lr 0.0031\n",
            "2020-02-12 13:28:51,842 DEV : loss 1.0042226314544678 - score 0.625\n",
            "2020-02-12 13:28:51,871 BAD EPOCHS (no improvement): 3\n",
            "2020-02-12 13:30:12,910 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 13:30:13,811 epoch 31 - iter 0/28 - loss 0.58920956 - samples/sec: 71.33\n",
            "2020-02-12 13:30:18,304 epoch 31 - iter 2/28 - loss 1.08108727 - samples/sec: 29.76\n",
            "2020-02-12 13:30:23,023 epoch 31 - iter 4/28 - loss 1.05141010 - samples/sec: 22.24\n",
            "2020-02-12 13:30:27,148 epoch 31 - iter 6/28 - loss 1.03148637 - samples/sec: 30.65\n",
            "2020-02-12 13:30:31,438 epoch 31 - iter 8/28 - loss 0.96137057 - samples/sec: 34.10\n",
            "2020-02-12 13:30:36,481 epoch 31 - iter 10/28 - loss 0.94386829 - samples/sec: 21.88\n",
            "2020-02-12 13:30:40,339 epoch 31 - iter 12/28 - loss 0.92938346 - samples/sec: 35.98\n",
            "2020-02-12 13:30:44,698 epoch 31 - iter 14/28 - loss 0.89839764 - samples/sec: 26.17\n",
            "2020-02-12 13:30:49,740 epoch 31 - iter 16/28 - loss 0.90102084 - samples/sec: 21.49\n",
            "2020-02-12 13:30:55,041 epoch 31 - iter 18/28 - loss 0.91645522 - samples/sec: 23.03\n",
            "2020-02-12 13:31:01,805 epoch 31 - iter 20/28 - loss 0.96291308 - samples/sec: 15.04\n",
            "2020-02-12 13:31:06,301 epoch 31 - iter 22/28 - loss 0.96829541 - samples/sec: 26.22\n",
            "2020-02-12 13:31:10,698 epoch 31 - iter 24/28 - loss 0.93650465 - samples/sec: 25.28\n",
            "2020-02-12 13:31:14,338 epoch 31 - iter 26/28 - loss 0.97204339 - samples/sec: 30.37\n",
            "2020-02-12 13:31:15,230 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 13:31:15,232 EPOCH 31 done: loss 0.9585 - lr 0.0031\n",
            "2020-02-12 13:31:21,457 DEV : loss 0.9882117509841919 - score 0.6383\n",
            "Epoch    31: reducing learning rate of group 0 to 1.5625e-03.\n",
            "2020-02-12 13:31:21,494 BAD EPOCHS (no improvement): 4\n",
            "2020-02-12 13:32:38,707 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 13:32:39,912 epoch 32 - iter 0/28 - loss 2.06008530 - samples/sec: 54.05\n",
            "2020-02-12 13:32:42,426 epoch 32 - iter 2/28 - loss 1.58787870 - samples/sec: 30.71\n",
            "2020-02-12 13:32:44,521 epoch 32 - iter 4/28 - loss 1.39432135 - samples/sec: 34.56\n",
            "2020-02-12 13:32:47,344 epoch 32 - iter 6/28 - loss 1.27056006 - samples/sec: 24.60\n",
            "2020-02-12 13:32:50,707 epoch 32 - iter 8/28 - loss 1.15533325 - samples/sec: 20.89\n",
            "2020-02-12 13:32:55,206 epoch 32 - iter 10/28 - loss 1.09829382 - samples/sec: 24.27\n",
            "2020-02-12 13:33:00,172 epoch 32 - iter 12/28 - loss 1.11244180 - samples/sec: 24.62\n",
            "2020-02-12 13:33:04,788 epoch 32 - iter 14/28 - loss 1.14026114 - samples/sec: 28.80\n",
            "2020-02-12 13:33:09,588 epoch 32 - iter 16/28 - loss 1.07199632 - samples/sec: 28.93\n",
            "2020-02-12 13:33:13,342 epoch 32 - iter 18/28 - loss 1.10810656 - samples/sec: 38.28\n",
            "2020-02-12 13:33:17,966 epoch 32 - iter 20/28 - loss 1.08995385 - samples/sec: 23.75\n",
            "2020-02-12 13:33:23,913 epoch 32 - iter 22/28 - loss 1.07150113 - samples/sec: 17.07\n",
            "2020-02-12 13:33:28,611 epoch 32 - iter 24/28 - loss 1.06948877 - samples/sec: 25.10\n",
            "2020-02-12 13:33:32,708 epoch 32 - iter 26/28 - loss 1.01674143 - samples/sec: 31.37\n",
            "2020-02-12 13:33:36,794 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 13:33:36,796 EPOCH 32 done: loss 1.0167 - lr 0.0016\n",
            "2020-02-12 13:33:43,058 DEV : loss 0.9639190435409546 - score 0.6383\n",
            "2020-02-12 13:33:43,089 BAD EPOCHS (no improvement): 1\n",
            "2020-02-12 13:35:00,789 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 13:35:01,762 epoch 33 - iter 0/28 - loss 1.91172075 - samples/sec: 66.27\n",
            "2020-02-12 13:35:08,236 epoch 33 - iter 2/28 - loss 1.51300891 - samples/sec: 22.68\n",
            "2020-02-12 13:35:12,618 epoch 33 - iter 4/28 - loss 1.18890686 - samples/sec: 27.68\n",
            "2020-02-12 13:35:18,033 epoch 33 - iter 6/28 - loss 1.07671220 - samples/sec: 23.25\n",
            "2020-02-12 13:35:22,425 epoch 33 - iter 8/28 - loss 1.08889490 - samples/sec: 30.01\n",
            "2020-02-12 13:35:28,572 epoch 33 - iter 10/28 - loss 1.04021536 - samples/sec: 16.52\n",
            "2020-02-12 13:35:33,196 epoch 33 - iter 12/28 - loss 0.98086430 - samples/sec: 23.66\n",
            "2020-02-12 13:35:37,445 epoch 33 - iter 14/28 - loss 0.97848120 - samples/sec: 31.12\n",
            "2020-02-12 13:35:41,681 epoch 33 - iter 16/28 - loss 1.06961447 - samples/sec: 26.70\n",
            "2020-02-12 13:35:46,069 epoch 33 - iter 18/28 - loss 1.05684677 - samples/sec: 30.76\n",
            "2020-02-12 13:35:51,947 epoch 33 - iter 20/28 - loss 1.06378051 - samples/sec: 21.60\n",
            "2020-02-12 13:35:56,909 epoch 33 - iter 22/28 - loss 1.08025789 - samples/sec: 22.64\n",
            "2020-02-12 13:36:00,840 epoch 33 - iter 24/28 - loss 1.04890085 - samples/sec: 32.78\n",
            "2020-02-12 13:36:04,758 epoch 33 - iter 26/28 - loss 1.01170974 - samples/sec: 26.89\n",
            "2020-02-12 13:36:08,395 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 13:36:08,398 EPOCH 33 done: loss 1.0039 - lr 0.0016\n",
            "2020-02-12 13:36:14,733 DEV : loss 0.9740992784500122 - score 0.6383\n",
            "2020-02-12 13:36:14,762 BAD EPOCHS (no improvement): 2\n",
            "2020-02-12 13:37:29,529 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 13:37:30,464 epoch 34 - iter 0/28 - loss 0.85620928 - samples/sec: 68.60\n",
            "2020-02-12 13:37:41,715 epoch 34 - iter 2/28 - loss 0.79898310 - samples/sec: 20.99\n",
            "2020-02-12 13:37:46,098 epoch 34 - iter 4/28 - loss 1.20293207 - samples/sec: 25.40\n",
            "2020-02-12 13:37:50,494 epoch 34 - iter 6/28 - loss 1.16145236 - samples/sec: 31.61\n",
            "2020-02-12 13:37:55,904 epoch 34 - iter 8/28 - loss 1.03388415 - samples/sec: 20.46\n",
            "2020-02-12 13:38:00,397 epoch 34 - iter 10/28 - loss 0.95669460 - samples/sec: 26.34\n",
            "2020-02-12 13:38:04,944 epoch 34 - iter 12/28 - loss 0.96776020 - samples/sec: 30.78\n",
            "2020-02-12 13:38:09,394 epoch 34 - iter 14/28 - loss 0.94363378 - samples/sec: 28.76\n",
            "2020-02-12 13:38:15,498 epoch 34 - iter 16/28 - loss 0.93079982 - samples/sec: 17.62\n",
            "2020-02-12 13:38:17,904 epoch 34 - iter 18/28 - loss 0.99523529 - samples/sec: 30.94\n",
            "2020-02-12 13:38:20,868 epoch 34 - iter 20/28 - loss 0.96970876 - samples/sec: 24.62\n",
            "2020-02-12 13:38:23,535 epoch 34 - iter 22/28 - loss 0.94354117 - samples/sec: 27.37\n",
            "2020-02-12 13:38:26,576 epoch 34 - iter 24/28 - loss 0.96202291 - samples/sec: 23.18\n",
            "2020-02-12 13:38:29,698 epoch 34 - iter 26/28 - loss 0.93590726 - samples/sec: 22.86\n",
            "2020-02-12 13:38:31,362 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 13:38:31,364 EPOCH 34 done: loss 0.9363 - lr 0.0016\n",
            "2020-02-12 13:38:37,850 DEV : loss 0.9659738540649414 - score 0.6383\n",
            "2020-02-12 13:38:37,878 BAD EPOCHS (no improvement): 3\n",
            "2020-02-12 13:39:59,009 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 13:39:59,954 epoch 35 - iter 0/28 - loss 1.82789564 - samples/sec: 73.09\n",
            "2020-02-12 13:40:05,116 epoch 35 - iter 2/28 - loss 1.13454040 - samples/sec: 22.90\n",
            "2020-02-12 13:40:08,843 epoch 35 - iter 4/28 - loss 0.96148720 - samples/sec: 35.35\n",
            "2020-02-12 13:40:13,652 epoch 35 - iter 6/28 - loss 0.87131636 - samples/sec: 24.48\n",
            "2020-02-12 13:40:17,722 epoch 35 - iter 8/28 - loss 0.82123041 - samples/sec: 31.93\n",
            "2020-02-12 13:40:22,663 epoch 35 - iter 10/28 - loss 0.80443291 - samples/sec: 21.79\n",
            "2020-02-12 13:40:29,280 epoch 35 - iter 12/28 - loss 0.82936379 - samples/sec: 16.20\n",
            "2020-02-12 13:40:33,747 epoch 35 - iter 14/28 - loss 0.86018629 - samples/sec: 28.93\n",
            "2020-02-12 13:40:38,849 epoch 35 - iter 16/28 - loss 0.83880584 - samples/sec: 25.25\n",
            "2020-02-12 13:40:43,395 epoch 35 - iter 18/28 - loss 0.83089964 - samples/sec: 32.37\n",
            "2020-02-12 13:40:47,867 epoch 35 - iter 20/28 - loss 0.87377532 - samples/sec: 27.20\n",
            "2020-02-12 13:40:52,428 epoch 35 - iter 22/28 - loss 0.93860216 - samples/sec: 22.21\n",
            "2020-02-12 13:40:55,037 epoch 35 - iter 24/28 - loss 0.93151434 - samples/sec: 28.34\n",
            "2020-02-12 13:40:57,921 epoch 35 - iter 26/28 - loss 0.97201766 - samples/sec: 24.93\n",
            "2020-02-12 13:40:59,135 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 13:40:59,136 EPOCH 35 done: loss 0.9527 - lr 0.0016\n",
            "2020-02-12 13:41:05,122 DEV : loss 0.9649791717529297 - score 0.6383\n",
            "Epoch    35: reducing learning rate of group 0 to 7.8125e-04.\n",
            "2020-02-12 13:41:05,163 BAD EPOCHS (no improvement): 4\n",
            "2020-02-12 13:42:27,304 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 13:42:28,582 epoch 36 - iter 0/28 - loss 0.81462383 - samples/sec: 50.45\n",
            "2020-02-12 13:42:33,579 epoch 36 - iter 2/28 - loss 0.83078432 - samples/sec: 25.23\n",
            "2020-02-12 13:42:37,455 epoch 36 - iter 4/28 - loss 0.82893801 - samples/sec: 27.56\n",
            "2020-02-12 13:42:41,981 epoch 36 - iter 6/28 - loss 0.88324486 - samples/sec: 31.17\n",
            "2020-02-12 13:42:47,045 epoch 36 - iter 8/28 - loss 0.78421052 - samples/sec: 29.02\n",
            "2020-02-12 13:42:52,152 epoch 36 - iter 10/28 - loss 0.92157828 - samples/sec: 20.50\n",
            "2020-02-12 13:42:56,967 epoch 36 - iter 12/28 - loss 0.88022199 - samples/sec: 24.32\n",
            "2020-02-12 13:43:01,731 epoch 36 - iter 14/28 - loss 0.90016858 - samples/sec: 23.72\n",
            "2020-02-12 13:43:05,176 epoch 36 - iter 16/28 - loss 0.89005417 - samples/sec: 36.03\n",
            "2020-02-12 13:43:07,719 epoch 36 - iter 18/28 - loss 0.86819535 - samples/sec: 28.99\n",
            "2020-02-12 13:43:10,182 epoch 36 - iter 20/28 - loss 0.86947880 - samples/sec: 29.79\n",
            "2020-02-12 13:43:14,296 epoch 36 - iter 22/28 - loss 0.89752389 - samples/sec: 16.79\n",
            "2020-02-12 13:43:17,530 epoch 36 - iter 24/28 - loss 0.93108890 - samples/sec: 22.18\n",
            "2020-02-12 13:43:20,554 epoch 36 - iter 26/28 - loss 0.94130957 - samples/sec: 23.66\n",
            "2020-02-12 13:43:21,653 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 13:43:21,654 EPOCH 36 done: loss 0.9432 - lr 0.0008\n",
            "2020-02-12 13:43:27,842 DEV : loss 0.9629755020141602 - score 0.6383\n",
            "2020-02-12 13:43:27,873 BAD EPOCHS (no improvement): 1\n",
            "2020-02-12 13:44:49,605 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 13:44:50,637 epoch 37 - iter 0/28 - loss 1.56783915 - samples/sec: 63.17\n",
            "2020-02-12 13:44:55,201 epoch 37 - iter 2/28 - loss 1.19014851 - samples/sec: 29.05\n",
            "2020-02-12 13:44:59,669 epoch 37 - iter 4/28 - loss 1.14945326 - samples/sec: 25.86\n",
            "2020-02-12 13:45:05,351 epoch 37 - iter 6/28 - loss 1.17336246 - samples/sec: 17.44\n",
            "2020-02-12 13:45:09,665 epoch 37 - iter 8/28 - loss 1.10966947 - samples/sec: 32.58\n",
            "2020-02-12 13:45:14,375 epoch 37 - iter 10/28 - loss 1.03647514 - samples/sec: 23.83\n",
            "2020-02-12 13:45:18,825 epoch 37 - iter 12/28 - loss 1.05334847 - samples/sec: 23.39\n",
            "2020-02-12 13:45:22,850 epoch 37 - iter 14/28 - loss 1.07712119 - samples/sec: 29.65\n",
            "2020-02-12 13:45:27,525 epoch 37 - iter 16/28 - loss 1.04625988 - samples/sec: 25.13\n",
            "2020-02-12 13:45:32,638 epoch 37 - iter 18/28 - loss 1.01793821 - samples/sec: 24.17\n",
            "2020-02-12 13:45:35,819 epoch 37 - iter 20/28 - loss 1.00072838 - samples/sec: 22.32\n",
            "2020-02-12 13:45:37,750 epoch 37 - iter 22/28 - loss 0.98246946 - samples/sec: 39.72\n",
            "2020-02-12 13:45:40,640 epoch 37 - iter 24/28 - loss 1.00215204 - samples/sec: 25.17\n",
            "2020-02-12 13:45:43,746 epoch 37 - iter 26/28 - loss 0.97047629 - samples/sec: 23.05\n",
            "2020-02-12 13:45:45,666 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 13:45:45,668 EPOCH 37 done: loss 0.9706 - lr 0.0008\n",
            "2020-02-12 13:45:52,098 DEV : loss 0.9667491912841797 - score 0.6383\n",
            "2020-02-12 13:45:52,131 BAD EPOCHS (no improvement): 2\n",
            "2020-02-12 13:47:08,844 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 13:47:09,869 epoch 38 - iter 0/28 - loss 1.28428221 - samples/sec: 62.64\n",
            "2020-02-12 13:47:12,518 epoch 38 - iter 2/28 - loss 1.15781164 - samples/sec: 29.18\n",
            "2020-02-12 13:47:15,089 epoch 38 - iter 4/28 - loss 1.02490578 - samples/sec: 28.57\n",
            "2020-02-12 13:47:17,630 epoch 38 - iter 6/28 - loss 0.99560969 - samples/sec: 28.17\n",
            "2020-02-12 13:47:20,224 epoch 38 - iter 8/28 - loss 0.93589269 - samples/sec: 27.86\n",
            "2020-02-12 13:47:26,089 epoch 38 - iter 10/28 - loss 0.87454436 - samples/sec: 16.98\n",
            "2020-02-12 13:47:30,730 epoch 38 - iter 12/28 - loss 0.89774972 - samples/sec: 22.75\n",
            "2020-02-12 13:47:35,962 epoch 38 - iter 14/28 - loss 0.88968627 - samples/sec: 34.75\n",
            "2020-02-12 13:47:40,887 epoch 38 - iter 16/28 - loss 0.88009383 - samples/sec: 26.88\n",
            "2020-02-12 13:47:45,365 epoch 38 - iter 18/28 - loss 0.86582144 - samples/sec: 22.47\n",
            "2020-02-12 13:47:52,148 epoch 38 - iter 20/28 - loss 0.91352290 - samples/sec: 24.31\n",
            "2020-02-12 13:47:56,741 epoch 38 - iter 22/28 - loss 0.92405547 - samples/sec: 27.44\n",
            "2020-02-12 13:48:02,224 epoch 38 - iter 24/28 - loss 0.89686195 - samples/sec: 22.04\n",
            "2020-02-12 13:48:06,774 epoch 38 - iter 26/28 - loss 0.92699058 - samples/sec: 27.06\n",
            "2020-02-12 13:48:10,188 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 13:48:10,190 EPOCH 38 done: loss 0.9518 - lr 0.0008\n",
            "2020-02-12 13:48:16,350 DEV : loss 0.9725138545036316 - score 0.6383\n",
            "2020-02-12 13:48:16,380 BAD EPOCHS (no improvement): 3\n",
            "2020-02-12 13:49:32,854 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 13:49:34,045 epoch 39 - iter 0/28 - loss 1.35504341 - samples/sec: 53.84\n",
            "2020-02-12 13:49:39,502 epoch 39 - iter 2/28 - loss 1.09935443 - samples/sec: 29.52\n",
            "2020-02-12 13:49:42,270 epoch 39 - iter 4/28 - loss 0.89811792 - samples/sec: 26.09\n",
            "2020-02-12 13:49:47,114 epoch 39 - iter 6/28 - loss 0.97946099 - samples/sec: 25.68\n",
            "2020-02-12 13:49:52,251 epoch 39 - iter 8/28 - loss 1.13031430 - samples/sec: 23.38\n",
            "2020-02-12 13:49:56,698 epoch 39 - iter 10/28 - loss 1.04904088 - samples/sec: 29.55\n",
            "2020-02-12 13:50:01,016 epoch 39 - iter 12/28 - loss 1.04436174 - samples/sec: 27.81\n",
            "2020-02-12 13:50:05,700 epoch 39 - iter 14/28 - loss 1.13007205 - samples/sec: 28.12\n",
            "2020-02-12 13:50:11,871 epoch 39 - iter 16/28 - loss 1.13242786 - samples/sec: 16.22\n",
            "2020-02-12 13:50:16,091 epoch 39 - iter 18/28 - loss 1.08738794 - samples/sec: 38.50\n",
            "2020-02-12 13:50:21,895 epoch 39 - iter 20/28 - loss 1.05688041 - samples/sec: 19.01\n",
            "2020-02-12 13:50:27,289 epoch 39 - iter 22/28 - loss 1.04290912 - samples/sec: 28.22\n",
            "2020-02-12 13:50:32,513 epoch 39 - iter 24/28 - loss 1.03207338 - samples/sec: 25.21\n",
            "2020-02-12 13:50:34,863 epoch 39 - iter 26/28 - loss 1.03446701 - samples/sec: 31.25\n",
            "2020-02-12 13:50:36,113 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 13:50:36,115 EPOCH 39 done: loss 1.0566 - lr 0.0008\n",
            "2020-02-12 13:50:42,069 DEV : loss 0.9780969619750977 - score 0.6383\n",
            "Epoch    39: reducing learning rate of group 0 to 3.9063e-04.\n",
            "2020-02-12 13:50:42,099 BAD EPOCHS (no improvement): 4\n",
            "2020-02-12 13:51:57,333 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 13:51:58,027 epoch 40 - iter 0/28 - loss 0.43235302 - samples/sec: 92.70\n",
            "2020-02-12 13:52:01,048 epoch 40 - iter 2/28 - loss 0.74546432 - samples/sec: 24.11\n",
            "2020-02-12 13:52:03,376 epoch 40 - iter 4/28 - loss 0.74640503 - samples/sec: 32.09\n",
            "2020-02-12 13:52:07,110 epoch 40 - iter 6/28 - loss 0.86283520 - samples/sec: 24.56\n",
            "2020-02-12 13:52:11,314 epoch 40 - iter 8/28 - loss 0.95738872 - samples/sec: 30.96\n",
            "2020-02-12 13:52:17,674 epoch 40 - iter 10/28 - loss 0.96437316 - samples/sec: 17.65\n",
            "2020-02-12 13:52:22,289 epoch 40 - iter 12/28 - loss 1.05218165 - samples/sec: 28.60\n",
            "2020-02-12 13:52:26,616 epoch 40 - iter 14/28 - loss 1.03847984 - samples/sec: 26.96\n",
            "2020-02-12 13:52:31,197 epoch 40 - iter 16/28 - loss 1.01565361 - samples/sec: 24.22\n",
            "2020-02-12 13:52:36,278 epoch 40 - iter 18/28 - loss 0.99370123 - samples/sec: 23.39\n",
            "2020-02-12 13:52:41,147 epoch 40 - iter 20/28 - loss 0.99554432 - samples/sec: 23.69\n",
            "2020-02-12 13:52:46,519 epoch 40 - iter 22/28 - loss 1.01914053 - samples/sec: 22.29\n",
            "2020-02-12 13:52:51,543 epoch 40 - iter 24/28 - loss 1.02204247 - samples/sec: 24.68\n",
            "2020-02-12 13:52:53,885 epoch 40 - iter 26/28 - loss 0.99808140 - samples/sec: 31.41\n",
            "2020-02-12 13:52:55,209 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 13:52:55,211 EPOCH 40 done: loss 0.9742 - lr 0.0004\n",
            "2020-02-12 13:53:01,458 DEV : loss 0.9780851602554321 - score 0.6383\n",
            "2020-02-12 13:53:01,489 BAD EPOCHS (no improvement): 1\n",
            "2020-02-12 13:54:15,245 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 13:54:16,153 epoch 41 - iter 0/28 - loss 0.81122398 - samples/sec: 70.80\n",
            "2020-02-12 13:54:18,224 epoch 41 - iter 2/28 - loss 0.92693488 - samples/sec: 36.92\n",
            "2020-02-12 13:54:22,361 epoch 41 - iter 4/28 - loss 0.85695257 - samples/sec: 16.63\n",
            "2020-02-12 13:54:25,807 epoch 41 - iter 6/28 - loss 0.93881975 - samples/sec: 20.24\n",
            "2020-02-12 13:54:30,294 epoch 41 - iter 8/28 - loss 0.92932887 - samples/sec: 27.63\n",
            "2020-02-12 13:54:35,490 epoch 41 - iter 10/28 - loss 1.00279583 - samples/sec: 22.79\n",
            "2020-02-12 13:54:40,110 epoch 41 - iter 12/28 - loss 1.03822121 - samples/sec: 27.63\n",
            "2020-02-12 13:54:44,929 epoch 41 - iter 14/28 - loss 1.05517441 - samples/sec: 24.22\n",
            "2020-02-12 13:54:49,357 epoch 41 - iter 16/28 - loss 1.05404534 - samples/sec: 26.90\n",
            "2020-02-12 13:54:53,865 epoch 41 - iter 18/28 - loss 1.02715628 - samples/sec: 29.55\n",
            "2020-02-12 13:54:58,279 epoch 41 - iter 20/28 - loss 1.03650263 - samples/sec: 35.56\n",
            "2020-02-12 13:55:02,867 epoch 41 - iter 22/28 - loss 1.04460577 - samples/sec: 25.80\n",
            "2020-02-12 13:55:07,251 epoch 41 - iter 24/28 - loss 1.03638680 - samples/sec: 26.97\n",
            "2020-02-12 13:55:12,125 epoch 41 - iter 26/28 - loss 0.99599416 - samples/sec: 22.60\n",
            "2020-02-12 13:55:13,565 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 13:55:13,567 EPOCH 41 done: loss 0.9805 - lr 0.0004\n",
            "2020-02-12 13:55:19,646 DEV : loss 0.9777716994285583 - score 0.6383\n",
            "2020-02-12 13:55:19,675 BAD EPOCHS (no improvement): 2\n",
            "2020-02-12 13:56:35,281 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 13:56:36,113 epoch 42 - iter 0/28 - loss 0.98135853 - samples/sec: 77.14\n",
            "2020-02-12 13:56:43,760 epoch 42 - iter 2/28 - loss 0.82965517 - samples/sec: 36.11\n",
            "2020-02-12 13:56:46,417 epoch 42 - iter 4/28 - loss 0.93433256 - samples/sec: 26.35\n",
            "2020-02-12 13:56:52,200 epoch 42 - iter 6/28 - loss 0.82686193 - samples/sec: 25.37\n",
            "2020-02-12 13:56:56,504 epoch 42 - iter 8/28 - loss 0.87245358 - samples/sec: 26.49\n",
            "2020-02-12 13:57:02,227 epoch 42 - iter 10/28 - loss 0.85287328 - samples/sec: 18.06\n",
            "2020-02-12 13:57:08,620 epoch 42 - iter 12/28 - loss 0.87593999 - samples/sec: 19.80\n",
            "2020-02-12 13:57:13,574 epoch 42 - iter 14/28 - loss 0.84286467 - samples/sec: 24.58\n",
            "2020-02-12 13:57:18,656 epoch 42 - iter 16/28 - loss 0.87325952 - samples/sec: 24.79\n",
            "2020-02-12 13:57:23,237 epoch 42 - iter 18/28 - loss 0.90609096 - samples/sec: 26.02\n",
            "2020-02-12 13:57:25,703 epoch 42 - iter 20/28 - loss 0.96970413 - samples/sec: 30.09\n",
            "2020-02-12 13:57:28,827 epoch 42 - iter 22/28 - loss 0.95363072 - samples/sec: 22.77\n",
            "2020-02-12 13:57:31,555 epoch 42 - iter 24/28 - loss 0.91741064 - samples/sec: 26.22\n",
            "2020-02-12 13:57:34,565 epoch 42 - iter 26/28 - loss 0.93394666 - samples/sec: 23.91\n",
            "2020-02-12 13:57:35,747 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 13:57:35,749 EPOCH 42 done: loss 0.9489 - lr 0.0004\n",
            "2020-02-12 13:57:42,172 DEV : loss 0.9775170087814331 - score 0.6383\n",
            "2020-02-12 13:57:42,203 BAD EPOCHS (no improvement): 3\n",
            "2020-02-12 13:58:58,209 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 13:58:59,172 epoch 43 - iter 0/28 - loss 1.03111029 - samples/sec: 66.59\n",
            "2020-02-12 13:59:02,187 epoch 43 - iter 2/28 - loss 1.20366319 - samples/sec: 23.88\n",
            "2020-02-12 13:59:05,199 epoch 43 - iter 4/28 - loss 1.07161856 - samples/sec: 23.63\n",
            "2020-02-12 13:59:07,638 epoch 43 - iter 6/28 - loss 1.19687986 - samples/sec: 29.17\n",
            "2020-02-12 13:59:11,266 epoch 43 - iter 8/28 - loss 1.15693993 - samples/sec: 32.44\n",
            "2020-02-12 13:59:15,306 epoch 43 - iter 10/28 - loss 1.17747901 - samples/sec: 29.17\n",
            "2020-02-12 13:59:20,030 epoch 43 - iter 12/28 - loss 1.09918334 - samples/sec: 26.32\n",
            "2020-02-12 13:59:25,028 epoch 43 - iter 14/28 - loss 1.08829209 - samples/sec: 22.56\n",
            "2020-02-12 13:59:29,267 epoch 43 - iter 16/28 - loss 1.03876784 - samples/sec: 27.00\n",
            "2020-02-12 13:59:34,027 epoch 43 - iter 18/28 - loss 0.98801174 - samples/sec: 33.52\n",
            "2020-02-12 13:59:39,297 epoch 43 - iter 20/28 - loss 1.00880709 - samples/sec: 22.93\n",
            "2020-02-12 13:59:43,702 epoch 43 - iter 22/28 - loss 0.98778824 - samples/sec: 30.42\n",
            "2020-02-12 13:59:49,347 epoch 43 - iter 24/28 - loss 0.96073385 - samples/sec: 21.75\n",
            "2020-02-12 13:59:54,908 epoch 43 - iter 26/28 - loss 0.92682233 - samples/sec: 15.71\n",
            "2020-02-12 13:59:56,651 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 13:59:56,653 EPOCH 43 done: loss 0.9772 - lr 0.0004\n",
            "2020-02-12 14:00:02,604 DEV : loss 0.976887583732605 - score 0.6383\n",
            "Epoch    43: reducing learning rate of group 0 to 1.9531e-04.\n",
            "2020-02-12 14:00:02,636 BAD EPOCHS (no improvement): 4\n",
            "2020-02-12 14:01:16,480 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 14:01:17,843 epoch 44 - iter 0/28 - loss 1.27800465 - samples/sec: 47.05\n",
            "2020-02-12 14:01:20,206 epoch 44 - iter 2/28 - loss 1.13224824 - samples/sec: 36.59\n",
            "2020-02-12 14:01:27,937 epoch 44 - iter 4/28 - loss 1.06637411 - samples/sec: 25.68\n",
            "2020-02-12 14:01:33,087 epoch 44 - iter 6/28 - loss 1.00160572 - samples/sec: 23.36\n",
            "2020-02-12 14:01:37,676 epoch 44 - iter 8/28 - loss 0.96420405 - samples/sec: 25.28\n",
            "2020-02-12 14:01:44,295 epoch 44 - iter 10/28 - loss 1.05056238 - samples/sec: 17.49\n",
            "2020-02-12 14:01:48,531 epoch 44 - iter 12/28 - loss 1.04800910 - samples/sec: 25.78\n",
            "2020-02-12 14:01:52,736 epoch 44 - iter 14/28 - loss 1.06184597 - samples/sec: 29.27\n",
            "2020-02-12 14:01:57,086 epoch 44 - iter 16/28 - loss 1.07095163 - samples/sec: 26.11\n",
            "2020-02-12 14:02:02,394 epoch 44 - iter 18/28 - loss 1.02050922 - samples/sec: 23.28\n",
            "2020-02-12 14:02:06,296 epoch 44 - iter 20/28 - loss 1.01677331 - samples/sec: 32.79\n",
            "2020-02-12 14:02:11,259 epoch 44 - iter 22/28 - loss 1.00842901 - samples/sec: 24.43\n",
            "2020-02-12 14:02:15,895 epoch 44 - iter 24/28 - loss 0.96493238 - samples/sec: 26.02\n",
            "2020-02-12 14:02:20,945 epoch 44 - iter 26/28 - loss 0.99490277 - samples/sec: 20.75\n",
            "2020-02-12 14:02:23,695 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 14:02:23,696 EPOCH 44 done: loss 0.9862 - lr 0.0002\n",
            "2020-02-12 14:02:29,931 DEV : loss 0.9755634665489197 - score 0.6383\n",
            "2020-02-12 14:02:29,967 BAD EPOCHS (no improvement): 1\n",
            "2020-02-12 14:03:47,138 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 14:03:48,172 epoch 45 - iter 0/28 - loss 1.44550228 - samples/sec: 62.25\n",
            "2020-02-12 14:03:50,720 epoch 45 - iter 2/28 - loss 1.19334809 - samples/sec: 30.51\n",
            "2020-02-12 14:03:53,537 epoch 45 - iter 4/28 - loss 1.28530550 - samples/sec: 25.31\n",
            "2020-02-12 14:03:55,992 epoch 45 - iter 6/28 - loss 1.15318046 - samples/sec: 28.87\n",
            "2020-02-12 14:04:00,120 epoch 45 - iter 8/28 - loss 1.15004094 - samples/sec: 29.89\n",
            "2020-02-12 14:04:04,453 epoch 45 - iter 10/28 - loss 1.12409045 - samples/sec: 28.27\n",
            "2020-02-12 14:04:09,241 epoch 45 - iter 12/28 - loss 1.08438965 - samples/sec: 24.94\n",
            "2020-02-12 14:04:13,098 epoch 45 - iter 14/28 - loss 1.12760652 - samples/sec: 33.29\n",
            "2020-02-12 14:04:18,343 epoch 45 - iter 16/28 - loss 1.08863716 - samples/sec: 20.86\n",
            "2020-02-12 14:04:24,458 epoch 45 - iter 18/28 - loss 1.02600276 - samples/sec: 16.10\n",
            "2020-02-12 14:04:29,004 epoch 45 - iter 20/28 - loss 1.01249881 - samples/sec: 31.57\n",
            "2020-02-12 14:04:33,360 epoch 45 - iter 22/28 - loss 1.03097464 - samples/sec: 26.78\n",
            "2020-02-12 14:04:37,641 epoch 45 - iter 24/28 - loss 1.03720350 - samples/sec: 29.62\n",
            "2020-02-12 14:04:42,491 epoch 45 - iter 26/28 - loss 1.01645484 - samples/sec: 24.56\n",
            "2020-02-12 14:04:45,522 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 14:04:45,524 EPOCH 45 done: loss 1.0039 - lr 0.0002\n",
            "2020-02-12 14:04:51,706 DEV : loss 0.9760252833366394 - score 0.6383\n",
            "2020-02-12 14:04:51,734 BAD EPOCHS (no improvement): 2\n",
            "2020-02-12 14:06:08,534 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 14:06:09,868 epoch 46 - iter 0/28 - loss 1.19877529 - samples/sec: 48.18\n",
            "2020-02-12 14:06:16,623 epoch 46 - iter 2/28 - loss 1.28732920 - samples/sec: 41.03\n",
            "2020-02-12 14:06:21,334 epoch 46 - iter 4/28 - loss 0.94572487 - samples/sec: 25.90\n",
            "2020-02-12 14:06:25,850 epoch 46 - iter 6/28 - loss 0.97370618 - samples/sec: 25.67\n",
            "2020-02-12 14:06:30,254 epoch 46 - iter 8/28 - loss 0.96522056 - samples/sec: 25.72\n",
            "2020-02-12 14:06:35,566 epoch 46 - iter 10/28 - loss 1.06309006 - samples/sec: 22.76\n",
            "2020-02-12 14:06:40,175 epoch 46 - iter 12/28 - loss 1.01899239 - samples/sec: 27.52\n",
            "2020-02-12 14:06:45,444 epoch 46 - iter 14/28 - loss 1.08843292 - samples/sec: 28.02\n",
            "2020-02-12 14:06:49,721 epoch 46 - iter 16/28 - loss 1.05763082 - samples/sec: 26.09\n",
            "2020-02-12 14:06:54,204 epoch 46 - iter 18/28 - loss 1.04837420 - samples/sec: 26.27\n",
            "2020-02-12 14:06:59,051 epoch 46 - iter 20/28 - loss 1.01080490 - samples/sec: 26.67\n",
            "2020-02-12 14:07:04,224 epoch 46 - iter 22/28 - loss 1.04447786 - samples/sec: 20.96\n",
            "2020-02-12 14:07:11,310 epoch 46 - iter 24/28 - loss 1.01111727 - samples/sec: 19.63\n",
            "2020-02-12 14:07:16,887 epoch 46 - iter 26/28 - loss 0.99187007 - samples/sec: 18.20\n",
            "2020-02-12 14:07:18,396 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 14:07:18,397 EPOCH 46 done: loss 0.9917 - lr 0.0002\n",
            "2020-02-12 14:07:24,477 DEV : loss 0.9749504327774048 - score 0.6383\n",
            "2020-02-12 14:07:24,508 BAD EPOCHS (no improvement): 3\n",
            "2020-02-12 14:08:42,387 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 14:08:43,340 epoch 47 - iter 0/28 - loss 1.60977650 - samples/sec: 67.34\n",
            "2020-02-12 14:08:47,643 epoch 47 - iter 2/28 - loss 0.97468456 - samples/sec: 26.61\n",
            "2020-02-12 14:08:50,599 epoch 47 - iter 4/28 - loss 0.99692764 - samples/sec: 23.89\n",
            "2020-02-12 14:08:55,024 epoch 47 - iter 6/28 - loss 0.89195674 - samples/sec: 29.74\n",
            "2020-02-12 14:08:59,741 epoch 47 - iter 8/28 - loss 0.94304265 - samples/sec: 24.74\n",
            "2020-02-12 14:09:04,193 epoch 47 - iter 10/28 - loss 0.92052269 - samples/sec: 28.66\n",
            "2020-02-12 14:09:09,580 epoch 47 - iter 12/28 - loss 0.89591525 - samples/sec: 22.74\n",
            "2020-02-12 14:09:13,890 epoch 47 - iter 14/28 - loss 0.92296934 - samples/sec: 27.59\n",
            "2020-02-12 14:09:18,980 epoch 47 - iter 16/28 - loss 0.97748313 - samples/sec: 20.59\n",
            "2020-02-12 14:09:22,951 epoch 47 - iter 18/28 - loss 0.94687615 - samples/sec: 27.90\n",
            "2020-02-12 14:09:28,029 epoch 47 - iter 20/28 - loss 0.96755212 - samples/sec: 23.22\n",
            "2020-02-12 14:09:32,573 epoch 47 - iter 22/28 - loss 0.93912189 - samples/sec: 15.21\n",
            "2020-02-12 14:09:35,670 epoch 47 - iter 24/28 - loss 0.93970978 - samples/sec: 23.07\n",
            "2020-02-12 14:09:38,155 epoch 47 - iter 26/28 - loss 0.94820918 - samples/sec: 29.20\n",
            "2020-02-12 14:09:39,898 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 14:09:39,899 EPOCH 47 done: loss 0.9414 - lr 0.0002\n",
            "2020-02-12 14:09:46,717 DEV : loss 0.9720700979232788 - score 0.6383\n",
            "Epoch    47: reducing learning rate of group 0 to 9.7656e-05.\n",
            "2020-02-12 14:09:46,764 BAD EPOCHS (no improvement): 4\n",
            "2020-02-12 14:11:09,189 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 14:11:09,194 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 14:11:09,196 learning rate too small - quitting training!\n",
            "2020-02-12 14:11:09,198 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 14:12:47,483 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 14:12:47,491 Testing using best model ...\n",
            "2020-02-12 14:12:47,575 loading file /content/drive/My Drive/Colab Notebooks/Fall-Recognition/Data/FOLDER_1/TRN-FD1/best-model.pt\n",
            "2020-02-12 14:17:55,629 0.5856\t0.6092\t0.5972\n",
            "2020-02-12 14:17:55,630 \n",
            "MICRO_AVG: acc 0.4257 - f1-score 0.5972\n",
            "MACRO_AVG: acc 0.4257 - f1-score 0.5972\n",
            "QUEDA      tp: 106 - fp: 75 - fn: 68 - tn: 106 - precision: 0.5856 - recall: 0.6092 - accuracy: 0.4257 - f1-score: 0.5972\n",
            "2020-02-12 14:17:55,631 ----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'test_score': 0.5972,\n",
              " 'dev_score_history': [0.4913,\n",
              "  0.6046,\n",
              "  0.5417,\n",
              "  0.5957,\n",
              "  0.6383,\n",
              "  0.6364,\n",
              "  0.5957,\n",
              "  0.5652,\n",
              "  0.6364,\n",
              "  0.6087,\n",
              "  0.6667,\n",
              "  0.6087,\n",
              "  0.625,\n",
              "  0.6,\n",
              "  0.6522,\n",
              "  0.6522,\n",
              "  0.6667,\n",
              "  0.6522,\n",
              "  0.5715,\n",
              "  0.6667,\n",
              "  0.6383,\n",
              "  0.625,\n",
              "  0.625,\n",
              "  0.625,\n",
              "  0.6383,\n",
              "  0.6383,\n",
              "  0.625,\n",
              "  0.625,\n",
              "  0.625,\n",
              "  0.625,\n",
              "  0.6383,\n",
              "  0.6383,\n",
              "  0.6383,\n",
              "  0.6383,\n",
              "  0.6383,\n",
              "  0.6383,\n",
              "  0.6383,\n",
              "  0.6383,\n",
              "  0.6383,\n",
              "  0.6383,\n",
              "  0.6383,\n",
              "  0.6383,\n",
              "  0.6383,\n",
              "  0.6383,\n",
              "  0.6383,\n",
              "  0.6383,\n",
              "  0.6383],\n",
              " 'train_loss_history': [31.945099455969675,\n",
              "  2.8073516147477284,\n",
              "  2.325678672109331,\n",
              "  2.0447819318090166,\n",
              "  1.8833965403693063,\n",
              "  1.6827706694602966,\n",
              "  1.5696230615888322,\n",
              "  1.4505006628377097,\n",
              "  1.3877758809498377,\n",
              "  1.299524085862296,\n",
              "  1.2179920162473405,\n",
              "  1.2768209746905737,\n",
              "  1.1658373858247484,\n",
              "  1.2321813787732805,\n",
              "  1.2051009365490504,\n",
              "  1.1651398880141122,\n",
              "  1.144176324563367,\n",
              "  1.0472690165042877,\n",
              "  1.029554226568767,\n",
              "  1.0403904403959001,\n",
              "  1.0619499768529619,\n",
              "  1.040403093610491,\n",
              "  1.0137641153165273,\n",
              "  1.000370877129691,\n",
              "  1.0240896599633353,\n",
              "  1.028770135981696,\n",
              "  0.9907353562968118,\n",
              "  0.9500516653060913,\n",
              "  1.0285803931100028,\n",
              "  0.9959820977279118,\n",
              "  0.9585186988115311,\n",
              "  1.0167104857308524,\n",
              "  1.003922043102128,\n",
              "  0.936286211013794,\n",
              "  0.95267751706498,\n",
              "  0.9431780448981694,\n",
              "  0.9706041472298759,\n",
              "  0.9518049785069057,\n",
              "  1.0566392370632716,\n",
              "  0.9741687604359218,\n",
              "  0.9805024181093488,\n",
              "  0.9488861731120518,\n",
              "  0.9771971447127206,\n",
              "  0.9862115106412342,\n",
              "  1.0039493697030204,\n",
              "  0.9917355392660413,\n",
              "  0.941388589995248],\n",
              " 'dev_loss_history': [tensor(1.8937, device='cuda:0'),\n",
              "  tensor(1.2908, device='cuda:0'),\n",
              "  tensor(1.5343, device='cuda:0'),\n",
              "  tensor(1.0906, device='cuda:0'),\n",
              "  tensor(1.1064, device='cuda:0'),\n",
              "  tensor(1.0710, device='cuda:0'),\n",
              "  tensor(1.1380, device='cuda:0'),\n",
              "  tensor(1.0936, device='cuda:0'),\n",
              "  tensor(1.2035, device='cuda:0'),\n",
              "  tensor(0.9160, device='cuda:0'),\n",
              "  tensor(0.8447, device='cuda:0'),\n",
              "  tensor(0.9330, device='cuda:0'),\n",
              "  tensor(0.9098, device='cuda:0'),\n",
              "  tensor(1.0893, device='cuda:0'),\n",
              "  tensor(0.9606, device='cuda:0'),\n",
              "  tensor(0.8758, device='cuda:0'),\n",
              "  tensor(0.8393, device='cuda:0'),\n",
              "  tensor(0.8731, device='cuda:0'),\n",
              "  tensor(1.0255, device='cuda:0'),\n",
              "  tensor(0.8591, device='cuda:0'),\n",
              "  tensor(0.9254, device='cuda:0'),\n",
              "  tensor(0.9465, device='cuda:0'),\n",
              "  tensor(0.9412, device='cuda:0'),\n",
              "  tensor(0.9350, device='cuda:0'),\n",
              "  tensor(0.9375, device='cuda:0'),\n",
              "  tensor(0.9440, device='cuda:0'),\n",
              "  tensor(1.0152, device='cuda:0'),\n",
              "  tensor(0.9613, device='cuda:0'),\n",
              "  tensor(0.9906, device='cuda:0'),\n",
              "  tensor(1.0042, device='cuda:0'),\n",
              "  tensor(0.9882, device='cuda:0'),\n",
              "  tensor(0.9639, device='cuda:0'),\n",
              "  tensor(0.9741, device='cuda:0'),\n",
              "  tensor(0.9660, device='cuda:0'),\n",
              "  tensor(0.9650, device='cuda:0'),\n",
              "  tensor(0.9630, device='cuda:0'),\n",
              "  tensor(0.9667, device='cuda:0'),\n",
              "  tensor(0.9725, device='cuda:0'),\n",
              "  tensor(0.9781, device='cuda:0'),\n",
              "  tensor(0.9781, device='cuda:0'),\n",
              "  tensor(0.9778, device='cuda:0'),\n",
              "  tensor(0.9775, device='cuda:0'),\n",
              "  tensor(0.9769, device='cuda:0'),\n",
              "  tensor(0.9756, device='cuda:0'),\n",
              "  tensor(0.9760, device='cuda:0'),\n",
              "  tensor(0.9750, device='cuda:0'),\n",
              "  tensor(0.9721, device='cuda:0')]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3vQbkKNLk_h",
        "colab_type": "text"
      },
      "source": [
        "## FOLD 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eic1wNOLLlSv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e454fe94-0be9-4a8f-be0c-26122efb9e09"
      },
      "source": [
        "pathCorpus : str = '/content/Fall-Recognition/Data/FOLDER_2/'\n",
        "train_file : str = 'Train-SPLIT-2.txt'\n",
        "test_file : str = 'Test-SPLIT-2.txt'\n",
        "dev_file : str = 'CoNLL-dev.txt'\n",
        "pathCheckpoint: str = '/content/Fall-Recognition/Data/FOLDER_2/TRN-FD2'\n",
        "pathWordEmbeddings : str = 'health_fasttext_300.model'\n",
        "pathFlairEmbeddingsForward : str = None\n",
        "pathFlairEmbeddingsBackward : str =  None\n",
        "\n",
        "print('--------------------------START TRAINING (TOKEN)------------------------------')\n",
        "\n",
        "columns = {0:'token', 1:'label'}\n",
        "\n",
        "corpus: Corpus = ColumnCorpus(pathCorpus, columns,\n",
        "\ttrain_file = train_file,\n",
        "\ttest_file = test_file,\n",
        "\tdev_file = dev_file)\n",
        "\n",
        "print(\" \")\n",
        "print(\"Train len: \", len(corpus.train))\n",
        "print(\"Test len: \", len(corpus.test))\n",
        "print(\"Dev len: \", len(corpus.dev))\n",
        "\n",
        "tag_type = 'label'\n",
        "tag_dictionary = corpus.make_tag_dictionary(tag_type=tag_type)\n",
        "\n",
        "print(tag_dictionary.idx2item)\n",
        "print(\"len: \", len(tag_dictionary.idx2item))\n",
        "\n",
        "health_embedding = WordEmbeddings(pathWordEmbeddings)\n",
        "#flair_forward_embedding = FlairEmbeddings(pathFlairEmbeddingsForward)\n",
        "#flair_backward_embedding = FlairEmbeddings(pathFlairEmbeddingsBackward)\n",
        "\n",
        "embedding_types: List[TokenEmbeddings] = [\n",
        "\thealth_embedding,\n",
        "]\n",
        "  \n",
        "embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)\n",
        "\t\n",
        "tagger: SequenceTagger = SequenceTagger(hidden_size=256,\n",
        "\t\t\t\t\t\t\t\t\t\tembeddings=embeddings,\n",
        "\t\t\t\t\t\t\t\t\t\ttag_dictionary=tag_dictionary,\n",
        "\t\t\t\t\t\t\t\t\t\ttag_type=tag_type,\n",
        "\t\t\t\t\t\t\t\t\t\tuse_crf=True)\n",
        "\n",
        "trainer: ModelTrainer = ModelTrainer(tagger, corpus, optimizer=SGDW)\n",
        "\n",
        "trainer.train(pathCheckpoint,\n",
        "\t\t\t  learning_rate=0.1,\n",
        "\t\t\t  mini_batch_size=32,\n",
        "\t\t\t  max_epochs=150,\n",
        "\t\t\t  checkpoint=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------------START TRAINING (TOKEN)------------------------------\n",
            "2020-02-12 14:29:19,376 Reading data from /content/drive/My Drive/Colab Notebooks/Fall-Recognition/Data/FOLDER_2\n",
            "2020-02-12 14:29:19,380 Train: /content/drive/My Drive/Colab Notebooks/Fall-Recognition/Data/FOLDER_2/Train-SPLIT-2.txt\n",
            "2020-02-12 14:29:19,381 Dev: /content/drive/My Drive/Colab Notebooks/Fall-Recognition/Data/FOLDER_2/CoNLL-dev.txt\n",
            "2020-02-12 14:29:19,382 Test: /content/drive/My Drive/Colab Notebooks/Fall-Recognition/Data/FOLDER_2/Test-SPLIT-2.txt\n",
            " \n",
            "Train len:  888\n",
            "Test len:  444\n",
            "Dev len:  70\n",
            "[b'<unk>', b'O', b'B-QUEDA', b'I-QUEDA', b'<START>', b'<STOP>']\n",
            "len:  6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-02-12 14:31:28,557 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 14:31:28,559 Model: \"SequenceTagger(\n",
            "  (embeddings): StackedEmbeddings(\n",
            "    (list_embedding_0): WordEmbeddings('health_fasttext_300.model')\n",
            "  )\n",
            "  (word_dropout): WordDropout(p=0.05)\n",
            "  (locked_dropout): LockedDropout(p=0.5)\n",
            "  (embedding2nn): Linear(in_features=300, out_features=300, bias=True)\n",
            "  (rnn): LSTM(300, 256, bidirectional=True)\n",
            "  (linear): Linear(in_features=512, out_features=6, bias=True)\n",
            ")\"\n",
            "2020-02-12 14:31:28,560 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 14:31:28,563 Corpus: \"Corpus: 888 train + 70 dev + 444 test sentences\"\n",
            "2020-02-12 14:31:28,564 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 14:31:28,567 Parameters:\n",
            "2020-02-12 14:31:28,568  - learning_rate: \"0.1\"\n",
            "2020-02-12 14:31:28,569  - mini_batch_size: \"32\"\n",
            "2020-02-12 14:31:28,571  - patience: \"3\"\n",
            "2020-02-12 14:31:28,573  - anneal_factor: \"0.5\"\n",
            "2020-02-12 14:31:28,574  - max_epochs: \"150\"\n",
            "2020-02-12 14:31:28,576  - shuffle: \"True\"\n",
            "2020-02-12 14:31:28,578  - train_with_dev: \"False\"\n",
            "2020-02-12 14:31:28,579 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 14:31:28,581 Model training base path: \"/content/drive/My Drive/Colab Notebooks/Fall-Recognition/Data/FOLDER_2/TRN-FD2\"\n",
            "2020-02-12 14:31:28,583 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 14:31:28,584 Device: cuda:0\n",
            "2020-02-12 14:31:28,585 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 14:31:28,588 Embeddings storage mode: cpu\n",
            "2020-02-12 14:31:28,599 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 14:31:31,075 epoch 1 - iter 0/28 - loss 396.33093262 - samples/sec: 25.87\n",
            "2020-02-12 14:31:35,205 epoch 1 - iter 2/28 - loss 229.25619253 - samples/sec: 16.73\n",
            "2020-02-12 14:31:40,132 epoch 1 - iter 4/28 - loss 149.95267982 - samples/sec: 13.83\n",
            "2020-02-12 14:31:44,589 epoch 1 - iter 6/28 - loss 110.59659740 - samples/sec: 15.35\n",
            "2020-02-12 14:31:48,402 epoch 1 - iter 8/28 - loss 88.07971764 - samples/sec: 18.21\n",
            "2020-02-12 14:31:52,713 epoch 1 - iter 10/28 - loss 73.45309119 - samples/sec: 15.98\n",
            "2020-02-12 14:31:56,272 epoch 1 - iter 12/28 - loss 63.06892655 - samples/sec: 19.30\n",
            "2020-02-12 14:32:00,286 epoch 1 - iter 14/28 - loss 55.49645294 - samples/sec: 17.34\n",
            "2020-02-12 14:32:04,097 epoch 1 - iter 16/28 - loss 49.36919615 - samples/sec: 18.09\n",
            "2020-02-12 14:32:07,632 epoch 1 - iter 18/28 - loss 44.90014891 - samples/sec: 19.51\n",
            "2020-02-12 14:32:12,011 epoch 1 - iter 20/28 - loss 41.01742237 - samples/sec: 15.60\n",
            "2020-02-12 14:32:15,896 epoch 1 - iter 22/28 - loss 37.73253168 - samples/sec: 17.80\n",
            "2020-02-12 14:32:19,213 epoch 1 - iter 24/28 - loss 35.05060937 - samples/sec: 21.39\n",
            "2020-02-12 14:32:24,707 epoch 1 - iter 26/28 - loss 32.75137053 - samples/sec: 12.21\n",
            "2020-02-12 14:32:26,409 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 14:32:26,413 EPOCH 1 done: loss 31.7196 - lr 0.1000\n",
            "2020-02-12 14:32:34,054 DEV : loss 1.9769978523254395 - score 0.4\n",
            "2020-02-12 14:32:34,086 BAD EPOCHS (no improvement): 0\n",
            "2020-02-12 14:35:36,616 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 14:35:37,705 epoch 2 - iter 0/28 - loss 4.70117903 - samples/sec: 58.94\n",
            "2020-02-12 14:35:42,044 epoch 2 - iter 2/28 - loss 4.92409627 - samples/sec: 29.42\n",
            "2020-02-12 14:35:46,945 epoch 2 - iter 4/28 - loss 3.95693188 - samples/sec: 25.29\n",
            "2020-02-12 14:35:54,720 epoch 2 - iter 6/28 - loss 3.55092805 - samples/sec: 25.02\n",
            "2020-02-12 14:36:01,932 epoch 2 - iter 8/28 - loss 3.71826039 - samples/sec: 26.92\n",
            "2020-02-12 14:36:07,903 epoch 2 - iter 10/28 - loss 3.75772095 - samples/sec: 27.39\n",
            "2020-02-12 14:36:15,193 epoch 2 - iter 12/28 - loss 3.71128273 - samples/sec: 24.24\n",
            "2020-02-12 14:36:22,963 epoch 2 - iter 14/28 - loss 3.69580352 - samples/sec: 24.55\n",
            "2020-02-12 14:36:30,837 epoch 2 - iter 16/28 - loss 3.77374862 - samples/sec: 23.11\n",
            "2020-02-12 14:36:38,463 epoch 2 - iter 18/28 - loss 3.63542727 - samples/sec: 21.38\n",
            "2020-02-12 14:36:44,607 epoch 2 - iter 20/28 - loss 3.59504716 - samples/sec: 34.55\n",
            "2020-02-12 14:36:52,180 epoch 2 - iter 22/28 - loss 3.59654984 - samples/sec: 22.66\n",
            "2020-02-12 14:37:00,906 epoch 2 - iter 24/28 - loss 3.54948875 - samples/sec: 17.09\n",
            "2020-02-12 14:37:07,926 epoch 2 - iter 26/28 - loss 3.47047995 - samples/sec: 24.91\n",
            "2020-02-12 14:37:14,707 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 14:37:14,709 EPOCH 2 done: loss 3.5065 - lr 0.1000\n",
            "2020-02-12 14:37:20,963 DEV : loss 2.3950257301330566 - score 0.3824\n",
            "2020-02-12 14:37:20,994 BAD EPOCHS (no improvement): 1\n",
            "2020-02-12 14:38:44,331 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 14:38:45,607 epoch 3 - iter 0/28 - loss 4.92952013 - samples/sec: 50.28\n",
            "2020-02-12 14:38:50,312 epoch 3 - iter 2/28 - loss 3.80091238 - samples/sec: 22.64\n",
            "2020-02-12 14:38:52,959 epoch 3 - iter 4/28 - loss 3.43848410 - samples/sec: 27.44\n",
            "2020-02-12 14:38:57,879 epoch 3 - iter 6/28 - loss 3.22092744 - samples/sec: 29.55\n",
            "2020-02-12 14:39:03,434 epoch 3 - iter 8/28 - loss 3.14939351 - samples/sec: 18.16\n",
            "2020-02-12 14:39:08,042 epoch 3 - iter 10/28 - loss 2.97032452 - samples/sec: 26.42\n",
            "2020-02-12 14:39:12,990 epoch 3 - iter 12/28 - loss 2.92038976 - samples/sec: 23.90\n",
            "2020-02-12 14:39:17,901 epoch 3 - iter 14/28 - loss 2.85433521 - samples/sec: 24.77\n",
            "2020-02-12 14:39:22,235 epoch 3 - iter 16/28 - loss 3.00579133 - samples/sec: 24.46\n",
            "2020-02-12 14:39:28,997 epoch 3 - iter 18/28 - loss 2.93543088 - samples/sec: 14.94\n",
            "2020-02-12 14:39:34,523 epoch 3 - iter 20/28 - loss 2.83286358 - samples/sec: 22.01\n",
            "2020-02-12 14:39:39,332 epoch 3 - iter 22/28 - loss 2.98622162 - samples/sec: 25.31\n",
            "2020-02-12 14:39:44,122 epoch 3 - iter 24/28 - loss 3.02194935 - samples/sec: 26.62\n",
            "2020-02-12 14:39:49,225 epoch 3 - iter 26/28 - loss 2.95968762 - samples/sec: 22.81\n",
            "2020-02-12 14:39:53,176 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 14:39:53,180 EPOCH 3 done: loss 2.9300 - lr 0.1000\n",
            "2020-02-12 14:39:59,600 DEV : loss 1.169939637184143 - score 0.619\n",
            "2020-02-12 14:39:59,638 BAD EPOCHS (no improvement): 0\n",
            "2020-02-12 14:43:00,683 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 14:43:01,896 epoch 4 - iter 0/28 - loss 2.32553911 - samples/sec: 53.18\n",
            "2020-02-12 14:43:08,227 epoch 4 - iter 2/28 - loss 2.17781385 - samples/sec: 33.02\n",
            "2020-02-12 14:43:16,099 epoch 4 - iter 4/28 - loss 2.08362122 - samples/sec: 19.94\n",
            "2020-02-12 14:43:23,820 epoch 4 - iter 6/28 - loss 2.17843614 - samples/sec: 21.79\n",
            "2020-02-12 14:43:30,966 epoch 4 - iter 8/28 - loss 2.15685500 - samples/sec: 22.96\n",
            "2020-02-12 14:43:37,448 epoch 4 - iter 10/28 - loss 2.43569131 - samples/sec: 23.97\n",
            "2020-02-12 14:43:45,134 epoch 4 - iter 12/28 - loss 2.24617092 - samples/sec: 32.85\n",
            "2020-02-12 14:43:53,638 epoch 4 - iter 14/28 - loss 2.24936250 - samples/sec: 20.99\n",
            "2020-02-12 14:44:00,911 epoch 4 - iter 16/28 - loss 2.27309872 - samples/sec: 25.29\n",
            "2020-02-12 14:44:07,869 epoch 4 - iter 18/28 - loss 2.35970465 - samples/sec: 26.93\n",
            "2020-02-12 14:44:17,031 epoch 4 - iter 20/28 - loss 2.46248163 - samples/sec: 15.04\n",
            "2020-02-12 14:44:24,198 epoch 4 - iter 22/28 - loss 2.61796514 - samples/sec: 27.68\n",
            "2020-02-12 14:44:31,272 epoch 4 - iter 24/28 - loss 2.65051077 - samples/sec: 30.68\n",
            "2020-02-12 14:44:39,672 epoch 4 - iter 26/28 - loss 2.61911694 - samples/sec: 22.99\n",
            "2020-02-12 14:44:46,999 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 14:44:47,001 EPOCH 4 done: loss 2.5572 - lr 0.1000\n",
            "2020-02-12 14:44:53,420 DEV : loss 1.2317380905151367 - score 0.6809\n",
            "2020-02-12 14:44:53,450 BAD EPOCHS (no improvement): 0\n",
            "2020-02-12 14:47:53,962 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 14:47:55,111 epoch 5 - iter 0/28 - loss 1.26642990 - samples/sec: 55.87\n",
            "2020-02-12 14:48:00,739 epoch 5 - iter 2/28 - loss 2.15462907 - samples/sec: 24.06\n",
            "2020-02-12 14:48:08,148 epoch 5 - iter 4/28 - loss 2.15142612 - samples/sec: 30.46\n",
            "2020-02-12 14:48:17,576 epoch 5 - iter 6/28 - loss 2.01765449 - samples/sec: 22.65\n",
            "2020-02-12 14:48:25,256 epoch 5 - iter 8/28 - loss 2.20981121 - samples/sec: 23.64\n",
            "2020-02-12 14:48:33,585 epoch 5 - iter 10/28 - loss 2.11252191 - samples/sec: 23.39\n",
            "2020-02-12 14:48:40,648 epoch 5 - iter 12/28 - loss 2.07337618 - samples/sec: 25.59\n",
            "2020-02-12 14:48:48,910 epoch 5 - iter 14/28 - loss 1.99961532 - samples/sec: 24.92\n",
            "2020-02-12 14:48:56,142 epoch 5 - iter 16/28 - loss 1.98129404 - samples/sec: 31.97\n",
            "2020-02-12 14:49:02,524 epoch 5 - iter 18/28 - loss 2.00022891 - samples/sec: 22.98\n",
            "2020-02-12 14:49:09,982 epoch 5 - iter 20/28 - loss 2.07574486 - samples/sec: 27.41\n",
            "2020-02-12 14:49:18,296 epoch 5 - iter 22/28 - loss 2.11892213 - samples/sec: 15.79\n",
            "2020-02-12 14:49:25,723 epoch 5 - iter 24/28 - loss 2.22100513 - samples/sec: 22.29\n",
            "2020-02-12 14:49:33,363 epoch 5 - iter 26/28 - loss 2.22273207 - samples/sec: 27.61\n",
            "2020-02-12 14:49:39,083 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 14:49:39,087 EPOCH 5 done: loss 2.2359 - lr 0.1000\n",
            "2020-02-12 14:49:45,683 DEV : loss 1.051695466041565 - score 0.7111\n",
            "2020-02-12 14:49:45,712 BAD EPOCHS (no improvement): 0\n",
            "2020-02-12 14:52:47,243 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 14:52:48,773 epoch 6 - iter 0/28 - loss 1.47314453 - samples/sec: 41.92\n",
            "2020-02-12 14:52:54,283 epoch 6 - iter 2/28 - loss 1.57132880 - samples/sec: 23.48\n",
            "2020-02-12 14:53:01,961 epoch 6 - iter 4/28 - loss 1.62448483 - samples/sec: 25.50\n",
            "2020-02-12 14:53:12,601 epoch 6 - iter 6/28 - loss 1.76833126 - samples/sec: 20.97\n",
            "2020-02-12 14:53:18,859 epoch 6 - iter 8/28 - loss 2.08302026 - samples/sec: 26.52\n",
            "2020-02-12 14:53:29,082 epoch 6 - iter 10/28 - loss 1.93471224 - samples/sec: 16.70\n",
            "2020-02-12 14:53:36,058 epoch 6 - iter 12/28 - loss 1.96304864 - samples/sec: 31.76\n",
            "2020-02-12 14:53:44,430 epoch 6 - iter 14/28 - loss 2.00820583 - samples/sec: 20.13\n",
            "2020-02-12 14:53:52,331 epoch 6 - iter 16/28 - loss 2.06869210 - samples/sec: 34.02\n",
            "2020-02-12 14:53:59,076 epoch 6 - iter 18/28 - loss 2.03844239 - samples/sec: 35.07\n",
            "2020-02-12 14:54:07,913 epoch 6 - iter 20/28 - loss 2.05552989 - samples/sec: 20.20\n",
            "2020-02-12 14:54:16,580 epoch 6 - iter 22/28 - loss 2.01139697 - samples/sec: 24.35\n",
            "2020-02-12 14:54:24,934 epoch 6 - iter 24/28 - loss 2.01105545 - samples/sec: 25.71\n",
            "2020-02-12 14:54:31,955 epoch 6 - iter 26/28 - loss 2.03999221 - samples/sec: 21.30\n",
            "2020-02-12 14:54:35,279 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 14:54:35,281 EPOCH 6 done: loss 2.0810 - lr 0.1000\n",
            "2020-02-12 14:54:42,201 DEV : loss 1.0676213502883911 - score 0.625\n",
            "2020-02-12 14:54:42,234 BAD EPOCHS (no improvement): 1\n",
            "2020-02-12 14:56:05,804 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 14:56:07,141 epoch 7 - iter 0/28 - loss 1.69051647 - samples/sec: 47.98\n",
            "2020-02-12 14:56:09,591 epoch 7 - iter 2/28 - loss 1.61003399 - samples/sec: 30.48\n",
            "2020-02-12 14:56:12,353 epoch 7 - iter 4/28 - loss 1.66270809 - samples/sec: 26.18\n",
            "2020-02-12 14:56:15,631 epoch 7 - iter 6/28 - loss 1.73044688 - samples/sec: 21.41\n",
            "2020-02-12 14:56:20,927 epoch 7 - iter 8/28 - loss 1.88515711 - samples/sec: 20.60\n",
            "2020-02-12 14:56:25,080 epoch 7 - iter 10/28 - loss 2.04756719 - samples/sec: 27.21\n",
            "2020-02-12 14:56:29,127 epoch 7 - iter 12/28 - loss 1.99907901 - samples/sec: 28.91\n",
            "2020-02-12 14:56:33,784 epoch 7 - iter 14/28 - loss 1.99965833 - samples/sec: 29.57\n",
            "2020-02-12 14:56:38,171 epoch 7 - iter 16/28 - loss 1.95507801 - samples/sec: 29.70\n",
            "2020-02-12 14:56:44,937 epoch 7 - iter 18/28 - loss 1.99490216 - samples/sec: 17.24\n",
            "2020-02-12 14:56:49,327 epoch 7 - iter 20/28 - loss 1.96200902 - samples/sec: 28.80\n",
            "2020-02-12 14:56:54,437 epoch 7 - iter 22/28 - loss 2.01715816 - samples/sec: 24.39\n",
            "2020-02-12 14:56:59,245 epoch 7 - iter 24/28 - loss 1.99401121 - samples/sec: 25.32\n",
            "2020-02-12 14:57:04,970 epoch 7 - iter 26/28 - loss 1.91977870 - samples/sec: 20.95\n",
            "2020-02-12 14:57:08,916 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 14:57:08,920 EPOCH 7 done: loss 1.8983 - lr 0.1000\n",
            "2020-02-12 14:57:15,292 DEV : loss 0.9588057398796082 - score 0.6809\n",
            "2020-02-12 14:57:15,335 BAD EPOCHS (no improvement): 2\n",
            "2020-02-12 14:58:34,991 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 14:58:36,237 epoch 8 - iter 0/28 - loss 2.59880209 - samples/sec: 51.52\n",
            "2020-02-12 14:58:40,467 epoch 8 - iter 2/28 - loss 2.27809286 - samples/sec: 17.37\n",
            "2020-02-12 14:58:43,030 epoch 8 - iter 4/28 - loss 2.16571188 - samples/sec: 28.41\n",
            "2020-02-12 14:58:45,514 epoch 8 - iter 6/28 - loss 2.19872945 - samples/sec: 29.24\n",
            "2020-02-12 14:58:51,034 epoch 8 - iter 8/28 - loss 2.00894186 - samples/sec: 21.90\n",
            "2020-02-12 14:58:56,320 epoch 8 - iter 10/28 - loss 1.90839871 - samples/sec: 24.51\n",
            "2020-02-12 14:59:00,937 epoch 8 - iter 12/28 - loss 1.80368996 - samples/sec: 24.41\n",
            "2020-02-12 14:59:05,561 epoch 8 - iter 14/28 - loss 1.80247084 - samples/sec: 27.21\n",
            "2020-02-12 14:59:10,553 epoch 8 - iter 16/28 - loss 1.85085546 - samples/sec: 25.09\n",
            "2020-02-12 14:59:15,101 epoch 8 - iter 18/28 - loss 1.88707506 - samples/sec: 25.61\n",
            "2020-02-12 14:59:20,340 epoch 8 - iter 20/28 - loss 1.83863459 - samples/sec: 19.92\n",
            "2020-02-12 14:59:25,200 epoch 8 - iter 22/28 - loss 1.78693756 - samples/sec: 22.90\n",
            "2020-02-12 14:59:30,318 epoch 8 - iter 24/28 - loss 1.75599566 - samples/sec: 21.32\n",
            "2020-02-12 14:59:35,040 epoch 8 - iter 26/28 - loss 1.77659226 - samples/sec: 31.65\n",
            "2020-02-12 14:59:38,899 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 14:59:38,900 EPOCH 8 done: loss 1.7724 - lr 0.1000\n",
            "2020-02-12 14:59:45,526 DEV : loss 0.9092196226119995 - score 0.6829\n",
            "2020-02-12 14:59:45,556 BAD EPOCHS (no improvement): 3\n",
            "2020-02-12 15:01:05,764 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 15:01:07,162 epoch 9 - iter 0/28 - loss 2.26736975 - samples/sec: 46.04\n",
            "2020-02-12 15:01:09,565 epoch 9 - iter 2/28 - loss 1.96779315 - samples/sec: 31.53\n",
            "2020-02-12 15:01:12,300 epoch 9 - iter 4/28 - loss 2.00727835 - samples/sec: 26.37\n",
            "2020-02-12 15:01:15,265 epoch 9 - iter 6/28 - loss 1.89916222 - samples/sec: 24.24\n",
            "2020-02-12 15:01:19,523 epoch 9 - iter 8/28 - loss 1.85238303 - samples/sec: 20.62\n",
            "2020-02-12 15:01:24,531 epoch 9 - iter 10/28 - loss 1.85783113 - samples/sec: 22.62\n",
            "2020-02-12 15:01:29,090 epoch 9 - iter 12/28 - loss 1.85680411 - samples/sec: 23.93\n",
            "2020-02-12 15:01:33,556 epoch 9 - iter 14/28 - loss 1.81403065 - samples/sec: 26.21\n",
            "2020-02-12 15:01:37,429 epoch 9 - iter 16/28 - loss 1.74258616 - samples/sec: 35.32\n",
            "2020-02-12 15:01:43,289 epoch 9 - iter 18/28 - loss 1.77112065 - samples/sec: 18.40\n",
            "2020-02-12 15:01:48,184 epoch 9 - iter 20/28 - loss 1.75768516 - samples/sec: 27.00\n",
            "2020-02-12 15:01:52,735 epoch 9 - iter 22/28 - loss 1.74280784 - samples/sec: 26.38\n",
            "2020-02-12 15:01:58,705 epoch 9 - iter 24/28 - loss 1.72894049 - samples/sec: 24.70\n",
            "2020-02-12 15:02:06,206 epoch 9 - iter 26/28 - loss 1.69320345 - samples/sec: 14.87\n",
            "2020-02-12 15:02:09,877 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 15:02:09,880 EPOCH 9 done: loss 1.7004 - lr 0.1000\n",
            "2020-02-12 15:02:16,231 DEV : loss 0.8594745993614197 - score 0.6977\n",
            "Epoch     9: reducing learning rate of group 0 to 5.0000e-02.\n",
            "2020-02-12 15:02:16,313 BAD EPOCHS (no improvement): 4\n",
            "2020-02-12 15:03:29,218 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 15:03:30,414 epoch 10 - iter 0/28 - loss 0.98986340 - samples/sec: 53.66\n",
            "2020-02-12 15:03:33,369 epoch 10 - iter 2/28 - loss 1.10502354 - samples/sec: 24.90\n",
            "2020-02-12 15:03:41,171 epoch 10 - iter 4/28 - loss 1.46687469 - samples/sec: 23.58\n",
            "2020-02-12 15:03:45,428 epoch 10 - iter 6/28 - loss 1.51828235 - samples/sec: 25.59\n",
            "2020-02-12 15:03:50,349 epoch 10 - iter 8/28 - loss 1.48274856 - samples/sec: 28.56\n",
            "2020-02-12 15:03:56,485 epoch 10 - iter 10/28 - loss 1.49250013 - samples/sec: 18.43\n",
            "2020-02-12 15:04:02,171 epoch 10 - iter 12/28 - loss 1.63069300 - samples/sec: 21.66\n",
            "2020-02-12 15:04:07,484 epoch 10 - iter 14/28 - loss 1.63168478 - samples/sec: 21.51\n",
            "2020-02-12 15:04:12,860 epoch 10 - iter 16/28 - loss 1.66351899 - samples/sec: 23.24\n",
            "2020-02-12 15:04:17,072 epoch 10 - iter 18/28 - loss 1.63915318 - samples/sec: 31.07\n",
            "2020-02-12 15:04:21,457 epoch 10 - iter 20/28 - loss 1.64064505 - samples/sec: 28.47\n",
            "2020-02-12 15:04:25,893 epoch 10 - iter 22/28 - loss 1.63746973 - samples/sec: 26.92\n",
            "2020-02-12 15:04:32,182 epoch 10 - iter 24/28 - loss 1.61712536 - samples/sec: 15.36\n",
            "2020-02-12 15:04:36,790 epoch 10 - iter 26/28 - loss 1.56234983 - samples/sec: 25.94\n",
            "2020-02-12 15:04:40,742 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 15:04:40,744 EPOCH 10 done: loss 1.5559 - lr 0.0500\n",
            "2020-02-12 15:04:47,115 DEV : loss 0.8664900064468384 - score 0.6818\n",
            "2020-02-12 15:04:47,148 BAD EPOCHS (no improvement): 1\n",
            "2020-02-12 15:06:08,345 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 15:06:09,633 epoch 11 - iter 0/28 - loss 3.18049622 - samples/sec: 49.88\n",
            "2020-02-12 15:06:12,042 epoch 11 - iter 2/28 - loss 2.10334365 - samples/sec: 30.63\n",
            "2020-02-12 15:06:15,337 epoch 11 - iter 4/28 - loss 1.80652294 - samples/sec: 21.22\n",
            "2020-02-12 15:06:20,297 epoch 11 - iter 6/28 - loss 1.80145632 - samples/sec: 22.91\n",
            "2020-02-12 15:06:25,475 epoch 11 - iter 8/28 - loss 1.72514200 - samples/sec: 21.46\n",
            "2020-02-12 15:06:30,309 epoch 11 - iter 10/28 - loss 1.68254328 - samples/sec: 21.23\n",
            "2020-02-12 15:06:34,960 epoch 11 - iter 12/28 - loss 1.68569624 - samples/sec: 24.11\n",
            "2020-02-12 15:06:40,322 epoch 11 - iter 14/28 - loss 1.57096214 - samples/sec: 16.74\n",
            "2020-02-12 15:06:44,784 epoch 11 - iter 16/28 - loss 1.51531797 - samples/sec: 27.98\n",
            "2020-02-12 15:06:49,399 epoch 11 - iter 18/28 - loss 1.51388214 - samples/sec: 24.66\n",
            "2020-02-12 15:06:54,239 epoch 11 - iter 20/28 - loss 1.48397366 - samples/sec: 24.20\n",
            "2020-02-12 15:06:59,011 epoch 11 - iter 22/28 - loss 1.59538642 - samples/sec: 23.67\n",
            "2020-02-12 15:07:03,912 epoch 11 - iter 24/28 - loss 1.53551235 - samples/sec: 23.59\n",
            "2020-02-12 15:07:08,623 epoch 11 - iter 26/28 - loss 1.50535319 - samples/sec: 28.61\n",
            "2020-02-12 15:07:12,051 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 15:07:12,053 EPOCH 11 done: loss 1.5022 - lr 0.0500\n",
            "2020-02-12 15:07:18,818 DEV : loss 0.9203168153762817 - score 0.6809\n",
            "2020-02-12 15:07:18,850 BAD EPOCHS (no improvement): 2\n",
            "2020-02-12 15:08:35,431 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 15:08:36,675 epoch 12 - iter 0/28 - loss 0.84928656 - samples/sec: 51.69\n",
            "2020-02-12 15:08:39,746 epoch 12 - iter 2/28 - loss 1.09514888 - samples/sec: 23.99\n",
            "2020-02-12 15:08:44,592 epoch 12 - iter 4/28 - loss 1.33470802 - samples/sec: 18.27\n",
            "2020-02-12 15:08:49,740 epoch 12 - iter 6/28 - loss 1.37632704 - samples/sec: 21.84\n",
            "2020-02-12 15:08:54,652 epoch 12 - iter 8/28 - loss 1.46058390 - samples/sec: 26.24\n",
            "2020-02-12 15:08:58,788 epoch 12 - iter 10/28 - loss 1.41402908 - samples/sec: 28.12\n",
            "2020-02-12 15:09:03,430 epoch 12 - iter 12/28 - loss 1.38509354 - samples/sec: 23.51\n",
            "2020-02-12 15:09:07,567 epoch 12 - iter 14/28 - loss 1.28367678 - samples/sec: 27.09\n",
            "2020-02-12 15:09:11,834 epoch 12 - iter 16/28 - loss 1.28297256 - samples/sec: 27.58\n",
            "2020-02-12 15:09:16,588 epoch 12 - iter 18/28 - loss 1.36881412 - samples/sec: 29.35\n",
            "2020-02-12 15:09:21,729 epoch 12 - iter 20/28 - loss 1.42330115 - samples/sec: 22.61\n",
            "2020-02-12 15:09:26,750 epoch 12 - iter 22/28 - loss 1.37846532 - samples/sec: 22.45\n",
            "2020-02-12 15:09:30,674 epoch 12 - iter 24/28 - loss 1.40848869 - samples/sec: 34.33\n",
            "2020-02-12 15:09:37,563 epoch 12 - iter 26/28 - loss 1.41344863 - samples/sec: 15.42\n",
            "2020-02-12 15:09:40,802 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 15:09:40,808 EPOCH 12 done: loss 1.4588 - lr 0.0500\n",
            "2020-02-12 15:09:47,133 DEV : loss 0.867432713508606 - score 0.6957\n",
            "2020-02-12 15:09:47,166 BAD EPOCHS (no improvement): 3\n",
            "2020-02-12 15:11:02,543 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 15:11:03,728 epoch 13 - iter 0/28 - loss 0.85978794 - samples/sec: 54.13\n",
            "2020-02-12 15:11:11,433 epoch 13 - iter 2/28 - loss 1.18611797 - samples/sec: 28.39\n",
            "2020-02-12 15:11:16,121 epoch 13 - iter 4/28 - loss 1.19567461 - samples/sec: 28.27\n",
            "2020-02-12 15:11:22,523 epoch 13 - iter 6/28 - loss 1.18546043 - samples/sec: 14.69\n",
            "2020-02-12 15:11:26,478 epoch 13 - iter 8/28 - loss 1.24015268 - samples/sec: 27.63\n",
            "2020-02-12 15:11:31,619 epoch 13 - iter 10/28 - loss 1.28034743 - samples/sec: 26.11\n",
            "2020-02-12 15:11:36,297 epoch 13 - iter 12/28 - loss 1.38802833 - samples/sec: 23.56\n",
            "2020-02-12 15:11:41,343 epoch 13 - iter 14/28 - loss 1.40565310 - samples/sec: 25.67\n",
            "2020-02-12 15:11:46,657 epoch 13 - iter 16/28 - loss 1.53449050 - samples/sec: 22.20\n",
            "2020-02-12 15:11:50,314 epoch 13 - iter 18/28 - loss 1.51706169 - samples/sec: 19.13\n",
            "2020-02-12 15:11:53,243 epoch 13 - iter 20/28 - loss 1.45907370 - samples/sec: 24.85\n",
            "2020-02-12 15:11:56,242 epoch 13 - iter 22/28 - loss 1.43549055 - samples/sec: 23.54\n",
            "2020-02-12 15:11:58,861 epoch 13 - iter 24/28 - loss 1.39498350 - samples/sec: 28.37\n",
            "2020-02-12 15:12:01,494 epoch 13 - iter 26/28 - loss 1.38963777 - samples/sec: 27.78\n",
            "2020-02-12 15:12:03,153 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 15:12:03,155 EPOCH 13 done: loss 1.3762 - lr 0.0500\n",
            "2020-02-12 15:12:10,031 DEV : loss 0.8597683310508728 - score 0.6809\n",
            "Epoch    13: reducing learning rate of group 0 to 2.5000e-02.\n",
            "2020-02-12 15:12:10,077 BAD EPOCHS (no improvement): 4\n",
            "2020-02-12 15:13:29,572 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 15:13:30,919 epoch 14 - iter 0/28 - loss 2.16594696 - samples/sec: 47.64\n",
            "2020-02-12 15:13:36,448 epoch 14 - iter 2/28 - loss 1.93016386 - samples/sec: 23.91\n",
            "2020-02-12 15:13:41,082 epoch 14 - iter 4/28 - loss 1.72536640 - samples/sec: 26.55\n",
            "2020-02-12 15:13:45,781 epoch 14 - iter 6/28 - loss 1.48970304 - samples/sec: 22.64\n",
            "2020-02-12 15:13:49,596 epoch 14 - iter 8/28 - loss 1.48058981 - samples/sec: 33.05\n",
            "2020-02-12 15:13:54,296 epoch 14 - iter 10/28 - loss 1.48548343 - samples/sec: 24.34\n",
            "2020-02-12 15:13:59,884 epoch 14 - iter 12/28 - loss 1.42821206 - samples/sec: 20.54\n",
            "2020-02-12 15:14:05,410 epoch 14 - iter 14/28 - loss 1.52336162 - samples/sec: 20.34\n",
            "2020-02-12 15:14:10,379 epoch 14 - iter 16/28 - loss 1.52651599 - samples/sec: 21.16\n",
            "2020-02-12 15:14:15,452 epoch 14 - iter 18/28 - loss 1.45294478 - samples/sec: 25.94\n",
            "2020-02-12 15:14:18,165 epoch 14 - iter 20/28 - loss 1.43478968 - samples/sec: 26.36\n",
            "2020-02-12 15:14:22,869 epoch 14 - iter 22/28 - loss 1.42738118 - samples/sec: 14.69\n",
            "2020-02-12 15:14:25,745 epoch 14 - iter 24/28 - loss 1.38607616 - samples/sec: 24.53\n",
            "2020-02-12 15:14:28,566 epoch 14 - iter 26/28 - loss 1.40485991 - samples/sec: 25.31\n",
            "2020-02-12 15:14:30,252 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 15:14:30,255 EPOCH 14 done: loss 1.3837 - lr 0.0250\n",
            "2020-02-12 15:14:36,392 DEV : loss 0.9820358157157898 - score 0.6122\n",
            "2020-02-12 15:14:36,422 BAD EPOCHS (no improvement): 1\n",
            "2020-02-12 15:15:58,157 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 15:15:59,274 epoch 15 - iter 0/28 - loss 1.60073471 - samples/sec: 57.83\n",
            "2020-02-12 15:16:04,398 epoch 15 - iter 2/28 - loss 1.31792037 - samples/sec: 20.85\n",
            "2020-02-12 15:16:08,833 epoch 15 - iter 4/28 - loss 1.22179050 - samples/sec: 29.00\n",
            "2020-02-12 15:16:14,242 epoch 15 - iter 6/28 - loss 1.21440847 - samples/sec: 19.80\n",
            "2020-02-12 15:16:19,747 epoch 15 - iter 8/28 - loss 1.32075919 - samples/sec: 21.17\n",
            "2020-02-12 15:16:24,522 epoch 15 - iter 10/28 - loss 1.34409220 - samples/sec: 24.62\n",
            "2020-02-12 15:16:29,517 epoch 15 - iter 12/28 - loss 1.32868301 - samples/sec: 22.99\n",
            "2020-02-12 15:16:33,683 epoch 15 - iter 14/28 - loss 1.32985481 - samples/sec: 28.34\n",
            "2020-02-12 15:16:38,861 epoch 15 - iter 16/28 - loss 1.27353943 - samples/sec: 21.10\n",
            "2020-02-12 15:16:42,702 epoch 15 - iter 18/28 - loss 1.27688995 - samples/sec: 22.94\n",
            "2020-02-12 15:16:45,939 epoch 15 - iter 20/28 - loss 1.27385298 - samples/sec: 21.99\n",
            "2020-02-12 15:16:48,785 epoch 15 - iter 22/28 - loss 1.29957110 - samples/sec: 25.15\n",
            "2020-02-12 15:16:51,624 epoch 15 - iter 24/28 - loss 1.25760723 - samples/sec: 25.50\n",
            "2020-02-12 15:16:55,986 epoch 15 - iter 26/28 - loss 1.31066970 - samples/sec: 15.77\n",
            "2020-02-12 15:16:57,734 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 15:16:57,736 EPOCH 15 done: loss 1.2923 - lr 0.0250\n",
            "2020-02-12 15:17:03,970 DEV : loss 0.8947633504867554 - score 0.6122\n",
            "2020-02-12 15:17:04,001 BAD EPOCHS (no improvement): 2\n",
            "2020-02-12 15:18:22,505 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 15:18:23,670 epoch 16 - iter 0/28 - loss 1.56695080 - samples/sec: 55.08\n",
            "2020-02-12 15:18:26,387 epoch 16 - iter 2/28 - loss 1.58005428 - samples/sec: 27.27\n",
            "2020-02-12 15:18:30,158 epoch 16 - iter 4/28 - loss 1.45013132 - samples/sec: 18.53\n",
            "2020-02-12 15:18:33,473 epoch 16 - iter 6/28 - loss 1.29326800 - samples/sec: 21.30\n",
            "2020-02-12 15:18:38,360 epoch 16 - iter 8/28 - loss 1.24719355 - samples/sec: 21.79\n",
            "2020-02-12 15:18:42,214 epoch 16 - iter 10/28 - loss 1.36727428 - samples/sec: 35.86\n",
            "2020-02-12 15:18:47,609 epoch 16 - iter 12/28 - loss 1.44515657 - samples/sec: 20.15\n",
            "2020-02-12 15:18:51,985 epoch 16 - iter 14/28 - loss 1.38806906 - samples/sec: 28.42\n",
            "2020-02-12 15:18:56,748 epoch 16 - iter 16/28 - loss 1.33565617 - samples/sec: 23.44\n",
            "2020-02-12 15:19:00,707 epoch 16 - iter 18/28 - loss 1.33637054 - samples/sec: 30.83\n",
            "2020-02-12 15:19:05,707 epoch 16 - iter 20/28 - loss 1.30287650 - samples/sec: 23.10\n",
            "2020-02-12 15:19:10,548 epoch 16 - iter 22/28 - loss 1.30173880 - samples/sec: 24.48\n",
            "2020-02-12 15:19:14,921 epoch 16 - iter 24/28 - loss 1.31460924 - samples/sec: 25.64\n",
            "2020-02-12 15:19:19,598 epoch 16 - iter 26/28 - loss 1.33534020 - samples/sec: 24.94\n",
            "2020-02-12 15:19:23,827 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 15:19:23,831 EPOCH 16 done: loss 1.3231 - lr 0.0250\n",
            "2020-02-12 15:19:30,552 DEV : loss 0.8236134052276611 - score 0.6809\n",
            "2020-02-12 15:19:30,582 BAD EPOCHS (no improvement): 3\n",
            "2020-02-12 15:20:45,354 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 15:20:46,720 epoch 17 - iter 0/28 - loss 1.32615948 - samples/sec: 46.96\n",
            "2020-02-12 15:20:49,484 epoch 17 - iter 2/28 - loss 0.96250470 - samples/sec: 26.94\n",
            "2020-02-12 15:20:55,481 epoch 17 - iter 4/28 - loss 1.16941891 - samples/sec: 25.16\n",
            "2020-02-12 15:21:00,135 epoch 17 - iter 6/28 - loss 1.20031984 - samples/sec: 27.20\n",
            "2020-02-12 15:21:06,869 epoch 17 - iter 8/28 - loss 1.31961028 - samples/sec: 15.30\n",
            "2020-02-12 15:21:12,303 epoch 17 - iter 10/28 - loss 1.37104468 - samples/sec: 20.52\n",
            "2020-02-12 15:21:17,053 epoch 17 - iter 12/28 - loss 1.34070694 - samples/sec: 28.34\n",
            "2020-02-12 15:21:21,310 epoch 17 - iter 14/28 - loss 1.28865353 - samples/sec: 24.51\n",
            "2020-02-12 15:21:25,938 epoch 17 - iter 16/28 - loss 1.24211954 - samples/sec: 25.11\n",
            "2020-02-12 15:21:31,112 epoch 17 - iter 18/28 - loss 1.20869157 - samples/sec: 19.82\n",
            "2020-02-12 15:21:35,323 epoch 17 - iter 20/28 - loss 1.24365986 - samples/sec: 27.28\n",
            "2020-02-12 15:21:40,262 epoch 17 - iter 22/28 - loss 1.18608898 - samples/sec: 22.28\n",
            "2020-02-12 15:21:45,032 epoch 17 - iter 24/28 - loss 1.21087923 - samples/sec: 21.06\n",
            "2020-02-12 15:21:49,862 epoch 17 - iter 26/28 - loss 1.25841598 - samples/sec: 22.33\n",
            "2020-02-12 15:21:54,138 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 15:21:54,140 EPOCH 17 done: loss 1.2861 - lr 0.0250\n",
            "2020-02-12 15:22:00,825 DEV : loss 0.8984953761100769 - score 0.6531\n",
            "Epoch    17: reducing learning rate of group 0 to 1.2500e-02.\n",
            "2020-02-12 15:22:00,856 BAD EPOCHS (no improvement): 4\n",
            "2020-02-12 15:23:13,931 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 15:23:15,053 epoch 18 - iter 0/28 - loss 1.18141031 - samples/sec: 57.18\n",
            "2020-02-12 15:23:26,967 epoch 18 - iter 2/28 - loss 1.56826162 - samples/sec: 21.37\n",
            "2020-02-12 15:23:31,690 epoch 18 - iter 4/28 - loss 1.42428455 - samples/sec: 23.65\n",
            "2020-02-12 15:23:38,356 epoch 18 - iter 6/28 - loss 1.36954532 - samples/sec: 15.33\n",
            "2020-02-12 15:23:43,435 epoch 18 - iter 8/28 - loss 1.24008380 - samples/sec: 25.06\n",
            "2020-02-12 15:23:48,943 epoch 18 - iter 10/28 - loss 1.24460697 - samples/sec: 19.68\n",
            "2020-02-12 15:23:54,302 epoch 18 - iter 12/28 - loss 1.17135859 - samples/sec: 24.36\n",
            "2020-02-12 15:23:58,809 epoch 18 - iter 14/28 - loss 1.19132388 - samples/sec: 25.35\n",
            "2020-02-12 15:24:03,612 epoch 18 - iter 16/28 - loss 1.25393250 - samples/sec: 23.47\n",
            "2020-02-12 15:24:09,107 epoch 18 - iter 18/28 - loss 1.26455106 - samples/sec: 26.51\n",
            "2020-02-12 15:24:13,589 epoch 18 - iter 20/28 - loss 1.27245288 - samples/sec: 26.55\n",
            "2020-02-12 15:24:18,094 epoch 18 - iter 22/28 - loss 1.27717070 - samples/sec: 25.52\n",
            "2020-02-12 15:24:23,359 epoch 18 - iter 24/28 - loss 1.28227243 - samples/sec: 21.41\n",
            "2020-02-12 15:24:28,772 epoch 18 - iter 26/28 - loss 1.25927386 - samples/sec: 18.92\n",
            "2020-02-12 15:24:32,580 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 15:24:32,582 EPOCH 18 done: loss 1.2599 - lr 0.0125\n",
            "2020-02-12 15:24:39,367 DEV : loss 0.8199312686920166 - score 0.6667\n",
            "2020-02-12 15:24:39,402 BAD EPOCHS (no improvement): 1\n",
            "2020-02-12 15:25:54,537 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 15:25:56,037 epoch 19 - iter 0/28 - loss 1.25915480 - samples/sec: 42.73\n",
            "2020-02-12 15:25:58,922 epoch 19 - iter 2/28 - loss 1.06956164 - samples/sec: 26.10\n",
            "2020-02-12 15:26:04,178 epoch 19 - iter 4/28 - loss 1.01283941 - samples/sec: 25.94\n",
            "2020-02-12 15:26:10,332 epoch 19 - iter 6/28 - loss 1.13219104 - samples/sec: 17.02\n",
            "2020-02-12 15:26:15,569 epoch 19 - iter 8/28 - loss 1.24991438 - samples/sec: 22.91\n",
            "2020-02-12 15:26:20,782 epoch 19 - iter 10/28 - loss 1.22904249 - samples/sec: 24.63\n",
            "2020-02-12 15:26:25,803 epoch 19 - iter 12/28 - loss 1.25058464 - samples/sec: 22.56\n",
            "2020-02-12 15:26:30,338 epoch 19 - iter 14/28 - loss 1.23367685 - samples/sec: 24.77\n",
            "2020-02-12 15:26:35,317 epoch 19 - iter 16/28 - loss 1.24061102 - samples/sec: 24.10\n",
            "2020-02-12 15:26:40,940 epoch 19 - iter 18/28 - loss 1.24887645 - samples/sec: 17.94\n",
            "2020-02-12 15:26:45,625 epoch 19 - iter 20/28 - loss 1.22452974 - samples/sec: 23.14\n",
            "2020-02-12 15:26:50,106 epoch 19 - iter 22/28 - loss 1.18784660 - samples/sec: 28.53\n",
            "2020-02-12 15:26:54,442 epoch 19 - iter 24/28 - loss 1.18838860 - samples/sec: 26.85\n",
            "2020-02-12 15:26:59,232 epoch 19 - iter 26/28 - loss 1.18098197 - samples/sec: 23.15\n",
            "2020-02-12 15:27:00,928 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 15:27:00,930 EPOCH 19 done: loss 1.1846 - lr 0.0125\n",
            "2020-02-12 15:27:07,774 DEV : loss 0.8390376567840576 - score 0.6667\n",
            "2020-02-12 15:27:07,810 BAD EPOCHS (no improvement): 2\n",
            "2020-02-12 15:28:24,765 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 15:28:26,201 epoch 20 - iter 0/28 - loss 1.56748009 - samples/sec: 44.66\n",
            "2020-02-12 15:28:28,646 epoch 20 - iter 2/28 - loss 1.19612106 - samples/sec: 31.42\n",
            "2020-02-12 15:28:31,249 epoch 20 - iter 4/28 - loss 1.34693003 - samples/sec: 29.08\n",
            "2020-02-12 15:28:34,728 epoch 20 - iter 6/28 - loss 1.23257521 - samples/sec: 20.32\n",
            "2020-02-12 15:28:39,444 epoch 20 - iter 8/28 - loss 1.20968395 - samples/sec: 27.39\n",
            "2020-02-12 15:28:45,241 epoch 20 - iter 10/28 - loss 1.20499958 - samples/sec: 18.13\n",
            "2020-02-12 15:28:49,811 epoch 20 - iter 12/28 - loss 1.20598786 - samples/sec: 25.39\n",
            "2020-02-12 15:28:56,438 epoch 20 - iter 14/28 - loss 1.18475151 - samples/sec: 14.79\n",
            "2020-02-12 15:29:00,102 epoch 20 - iter 16/28 - loss 1.19165892 - samples/sec: 33.73\n",
            "2020-02-12 15:29:05,235 epoch 20 - iter 18/28 - loss 1.13425177 - samples/sec: 24.27\n",
            "2020-02-12 15:29:10,033 epoch 20 - iter 20/28 - loss 1.11639245 - samples/sec: 27.52\n",
            "2020-02-12 15:29:15,717 epoch 20 - iter 22/28 - loss 1.14893864 - samples/sec: 19.95\n",
            "2020-02-12 15:29:20,809 epoch 20 - iter 24/28 - loss 1.23007160 - samples/sec: 30.39\n",
            "2020-02-12 15:29:27,614 epoch 20 - iter 26/28 - loss 1.21563359 - samples/sec: 19.92\n",
            "2020-02-12 15:29:30,633 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 15:29:30,635 EPOCH 20 done: loss 1.2242 - lr 0.0125\n",
            "2020-02-12 15:29:37,295 DEV : loss 0.8072618842124939 - score 0.6667\n",
            "2020-02-12 15:29:37,331 BAD EPOCHS (no improvement): 3\n",
            "2020-02-12 15:30:59,272 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 15:31:00,977 epoch 21 - iter 0/28 - loss 1.58095169 - samples/sec: 37.65\n",
            "2020-02-12 15:31:03,320 epoch 21 - iter 2/28 - loss 1.69840495 - samples/sec: 32.27\n",
            "2020-02-12 15:31:06,298 epoch 21 - iter 4/28 - loss 1.31319723 - samples/sec: 23.75\n",
            "2020-02-12 15:31:11,894 epoch 21 - iter 6/28 - loss 1.23056691 - samples/sec: 20.55\n",
            "2020-02-12 15:31:16,585 epoch 21 - iter 8/28 - loss 1.10825904 - samples/sec: 24.73\n",
            "2020-02-12 15:31:22,847 epoch 21 - iter 10/28 - loss 1.03381985 - samples/sec: 23.13\n",
            "2020-02-12 15:31:28,394 epoch 21 - iter 12/28 - loss 0.97073368 - samples/sec: 22.77\n",
            "2020-02-12 15:31:34,738 epoch 21 - iter 14/28 - loss 1.07356396 - samples/sec: 15.80\n",
            "2020-02-12 15:31:39,698 epoch 21 - iter 16/28 - loss 1.06762822 - samples/sec: 23.56\n",
            "2020-02-12 15:31:44,408 epoch 21 - iter 18/28 - loss 1.06860969 - samples/sec: 23.47\n",
            "2020-02-12 15:31:48,933 epoch 21 - iter 20/28 - loss 1.04481170 - samples/sec: 28.31\n",
            "2020-02-12 15:31:54,220 epoch 21 - iter 22/28 - loss 1.00880440 - samples/sec: 21.01\n",
            "2020-02-12 15:31:59,101 epoch 21 - iter 24/28 - loss 1.11190350 - samples/sec: 25.59\n",
            "2020-02-12 15:32:04,035 epoch 21 - iter 26/28 - loss 1.16100873 - samples/sec: 25.02\n",
            "2020-02-12 15:32:07,712 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 15:32:07,713 EPOCH 21 done: loss 1.1742 - lr 0.0125\n",
            "2020-02-12 15:32:14,456 DEV : loss 0.815535306930542 - score 0.6667\n",
            "Epoch    21: reducing learning rate of group 0 to 6.2500e-03.\n",
            "2020-02-12 15:32:14,586 BAD EPOCHS (no improvement): 4\n",
            "2020-02-12 15:33:30,175 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 15:33:31,642 epoch 22 - iter 0/28 - loss 1.10821724 - samples/sec: 43.68\n",
            "2020-02-12 15:33:34,475 epoch 22 - iter 2/28 - loss 1.47473129 - samples/sec: 28.02\n",
            "2020-02-12 15:33:40,082 epoch 22 - iter 4/28 - loss 1.19147148 - samples/sec: 24.38\n",
            "2020-02-12 15:33:45,132 epoch 22 - iter 6/28 - loss 1.13572141 - samples/sec: 20.74\n",
            "2020-02-12 15:33:50,662 epoch 22 - iter 8/28 - loss 1.13762453 - samples/sec: 26.47\n",
            "2020-02-12 15:33:56,158 epoch 22 - iter 10/28 - loss 1.11725777 - samples/sec: 21.29\n",
            "2020-02-12 15:34:00,976 epoch 22 - iter 12/28 - loss 1.06343842 - samples/sec: 26.30\n",
            "2020-02-12 15:34:07,702 epoch 22 - iter 14/28 - loss 1.14004450 - samples/sec: 13.77\n",
            "2020-02-12 15:34:12,900 epoch 22 - iter 16/28 - loss 1.14839832 - samples/sec: 19.71\n",
            "2020-02-12 15:34:17,273 epoch 22 - iter 18/28 - loss 1.12136570 - samples/sec: 26.32\n",
            "2020-02-12 15:34:21,641 epoch 22 - iter 20/28 - loss 1.15940936 - samples/sec: 23.77\n",
            "2020-02-12 15:34:26,081 epoch 22 - iter 22/28 - loss 1.13437462 - samples/sec: 26.31\n",
            "2020-02-12 15:34:30,573 epoch 22 - iter 24/28 - loss 1.16880350 - samples/sec: 27.60\n",
            "2020-02-12 15:34:35,222 epoch 22 - iter 26/28 - loss 1.15381818 - samples/sec: 30.76\n",
            "2020-02-12 15:34:38,758 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 15:34:38,759 EPOCH 22 done: loss 1.1576 - lr 0.0063\n",
            "2020-02-12 15:34:45,235 DEV : loss 0.8354865312576294 - score 0.6667\n",
            "2020-02-12 15:34:45,271 BAD EPOCHS (no improvement): 1\n",
            "2020-02-12 15:36:01,259 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 15:36:02,580 epoch 23 - iter 0/28 - loss 0.93020201 - samples/sec: 48.53\n",
            "2020-02-12 15:36:09,864 epoch 23 - iter 2/28 - loss 1.07178036 - samples/sec: 27.29\n",
            "2020-02-12 15:36:14,576 epoch 23 - iter 4/28 - loss 1.00757189 - samples/sec: 23.64\n",
            "2020-02-12 15:36:19,688 epoch 23 - iter 6/28 - loss 1.00315237 - samples/sec: 21.81\n",
            "2020-02-12 15:36:24,035 epoch 23 - iter 8/28 - loss 1.04243061 - samples/sec: 29.53\n",
            "2020-02-12 15:36:29,024 epoch 23 - iter 10/28 - loss 1.06195047 - samples/sec: 20.87\n",
            "2020-02-12 15:36:33,642 epoch 23 - iter 12/28 - loss 1.04433170 - samples/sec: 25.77\n",
            "2020-02-12 15:36:38,715 epoch 23 - iter 14/28 - loss 1.02436152 - samples/sec: 19.67\n",
            "2020-02-12 15:36:43,352 epoch 23 - iter 16/28 - loss 1.04961460 - samples/sec: 23.87\n",
            "2020-02-12 15:36:47,953 epoch 23 - iter 18/28 - loss 1.10941970 - samples/sec: 26.76\n",
            "2020-02-12 15:36:52,459 epoch 23 - iter 20/28 - loss 1.19502236 - samples/sec: 27.88\n",
            "2020-02-12 15:36:57,856 epoch 23 - iter 22/28 - loss 1.21763826 - samples/sec: 29.36\n",
            "2020-02-12 15:37:03,865 epoch 23 - iter 24/28 - loss 1.23217476 - samples/sec: 21.35\n",
            "2020-02-12 15:37:11,606 epoch 23 - iter 26/28 - loss 1.20999921 - samples/sec: 13.80\n",
            "2020-02-12 15:37:15,797 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 15:37:15,798 EPOCH 23 done: loss 1.2186 - lr 0.0063\n",
            "2020-02-12 15:37:22,403 DEV : loss 0.798872709274292 - score 0.6667\n",
            "2020-02-12 15:37:22,433 BAD EPOCHS (no improvement): 2\n",
            "2020-02-12 15:38:35,319 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 15:38:36,745 epoch 24 - iter 0/28 - loss 1.25364971 - samples/sec: 45.02\n",
            "2020-02-12 15:38:48,681 epoch 24 - iter 2/28 - loss 1.02327617 - samples/sec: 28.15\n",
            "2020-02-12 15:38:53,429 epoch 24 - iter 4/28 - loss 0.90767632 - samples/sec: 31.34\n",
            "2020-02-12 15:38:58,990 epoch 24 - iter 6/28 - loss 0.88099895 - samples/sec: 22.01\n",
            "2020-02-12 15:39:03,015 epoch 24 - iter 8/28 - loss 0.94276995 - samples/sec: 31.90\n",
            "2020-02-12 15:39:08,299 epoch 24 - iter 10/28 - loss 0.94324498 - samples/sec: 24.45\n",
            "2020-02-12 15:39:13,396 epoch 24 - iter 12/28 - loss 1.04796666 - samples/sec: 23.80\n",
            "2020-02-12 15:39:19,210 epoch 24 - iter 14/28 - loss 1.08593280 - samples/sec: 18.69\n",
            "2020-02-12 15:39:24,053 epoch 24 - iter 16/28 - loss 1.12872822 - samples/sec: 22.50\n",
            "2020-02-12 15:39:28,901 epoch 24 - iter 18/28 - loss 1.14687325 - samples/sec: 24.56\n",
            "2020-02-12 15:39:34,284 epoch 24 - iter 20/28 - loss 1.15999360 - samples/sec: 25.71\n",
            "2020-02-12 15:39:40,463 epoch 24 - iter 22/28 - loss 1.12595716 - samples/sec: 18.97\n",
            "2020-02-12 15:39:44,956 epoch 24 - iter 24/28 - loss 1.12170990 - samples/sec: 24.99\n",
            "2020-02-12 15:39:51,227 epoch 24 - iter 26/28 - loss 1.15860759 - samples/sec: 15.46\n",
            "2020-02-12 15:39:54,474 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 15:39:54,476 EPOCH 24 done: loss 1.1419 - lr 0.0063\n",
            "2020-02-12 15:40:01,014 DEV : loss 0.7910181283950806 - score 0.6667\n",
            "2020-02-12 15:40:01,044 BAD EPOCHS (no improvement): 3\n",
            "2020-02-12 15:41:21,784 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 15:41:22,604 epoch 25 - iter 0/28 - loss 1.34555244 - samples/sec: 78.25\n",
            "2020-02-12 15:41:26,253 epoch 25 - iter 2/28 - loss 1.41298723 - samples/sec: 19.90\n",
            "2020-02-12 15:41:28,954 epoch 25 - iter 4/28 - loss 1.20239000 - samples/sec: 26.05\n",
            "2020-02-12 15:41:32,011 epoch 25 - iter 6/28 - loss 1.24636780 - samples/sec: 22.90\n",
            "2020-02-12 15:41:37,291 epoch 25 - iter 8/28 - loss 1.34351905 - samples/sec: 22.77\n",
            "2020-02-12 15:41:41,889 epoch 25 - iter 10/28 - loss 1.42914148 - samples/sec: 26.54\n",
            "2020-02-12 15:41:47,303 epoch 25 - iter 12/28 - loss 1.34881695 - samples/sec: 22.66\n",
            "2020-02-12 15:41:52,862 epoch 25 - iter 14/28 - loss 1.33299519 - samples/sec: 21.48\n",
            "2020-02-12 15:41:58,287 epoch 25 - iter 16/28 - loss 1.29071191 - samples/sec: 21.24\n",
            "2020-02-12 15:42:02,905 epoch 25 - iter 18/28 - loss 1.25147408 - samples/sec: 24.44\n",
            "2020-02-12 15:42:08,156 epoch 25 - iter 20/28 - loss 1.22398760 - samples/sec: 21.46\n",
            "2020-02-12 15:42:13,160 epoch 25 - iter 22/28 - loss 1.24671140 - samples/sec: 24.69\n",
            "2020-02-12 15:42:17,854 epoch 25 - iter 24/28 - loss 1.22235266 - samples/sec: 25.85\n",
            "2020-02-12 15:42:24,491 epoch 25 - iter 26/28 - loss 1.18814124 - samples/sec: 16.36\n",
            "2020-02-12 15:42:26,422 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 15:42:26,424 EPOCH 25 done: loss 1.1586 - lr 0.0063\n",
            "2020-02-12 15:42:33,049 DEV : loss 0.816828191280365 - score 0.6667\n",
            "Epoch    25: reducing learning rate of group 0 to 3.1250e-03.\n",
            "2020-02-12 15:42:33,101 BAD EPOCHS (no improvement): 4\n",
            "2020-02-12 15:43:46,620 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 15:43:48,078 epoch 26 - iter 0/28 - loss 0.63985634 - samples/sec: 44.05\n",
            "2020-02-12 15:43:51,389 epoch 26 - iter 2/28 - loss 0.52706114 - samples/sec: 21.89\n",
            "2020-02-12 15:43:54,803 epoch 26 - iter 4/28 - loss 0.72066231 - samples/sec: 20.39\n",
            "2020-02-12 15:44:00,035 epoch 26 - iter 6/28 - loss 0.84956401 - samples/sec: 23.45\n",
            "2020-02-12 15:44:06,623 epoch 26 - iter 8/28 - loss 1.09330469 - samples/sec: 15.21\n",
            "2020-02-12 15:44:11,105 epoch 26 - iter 10/28 - loss 1.10611083 - samples/sec: 26.61\n",
            "2020-02-12 15:44:16,508 epoch 26 - iter 12/28 - loss 1.10540577 - samples/sec: 22.06\n",
            "2020-02-12 15:44:21,867 epoch 26 - iter 14/28 - loss 1.07575172 - samples/sec: 20.27\n",
            "2020-02-12 15:44:25,772 epoch 26 - iter 16/28 - loss 1.07006393 - samples/sec: 32.65\n",
            "2020-02-12 15:44:30,212 epoch 26 - iter 18/28 - loss 1.09781825 - samples/sec: 26.77\n",
            "2020-02-12 15:44:34,152 epoch 26 - iter 20/28 - loss 1.12282585 - samples/sec: 32.85\n",
            "2020-02-12 15:44:38,097 epoch 26 - iter 22/28 - loss 1.13989283 - samples/sec: 32.41\n",
            "2020-02-12 15:44:43,323 epoch 26 - iter 24/28 - loss 1.19312023 - samples/sec: 21.94\n",
            "2020-02-12 15:44:48,691 epoch 26 - iter 26/28 - loss 1.13789700 - samples/sec: 21.44\n",
            "2020-02-12 15:44:52,288 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 15:44:52,290 EPOCH 26 done: loss 1.1506 - lr 0.0031\n",
            "2020-02-12 15:44:59,168 DEV : loss 0.8043724894523621 - score 0.6667\n",
            "2020-02-12 15:44:59,199 BAD EPOCHS (no improvement): 1\n",
            "2020-02-12 15:46:19,018 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 15:46:20,088 epoch 27 - iter 0/28 - loss 1.06873322 - samples/sec: 59.92\n",
            "2020-02-12 15:46:23,843 epoch 27 - iter 2/28 - loss 1.04863389 - samples/sec: 19.18\n",
            "2020-02-12 15:46:26,791 epoch 27 - iter 4/28 - loss 0.98698759 - samples/sec: 23.87\n",
            "2020-02-12 15:46:29,446 epoch 27 - iter 6/28 - loss 1.13344363 - samples/sec: 27.41\n",
            "2020-02-12 15:46:33,974 epoch 27 - iter 8/28 - loss 1.11932961 - samples/sec: 25.84\n",
            "2020-02-12 15:46:38,522 epoch 27 - iter 10/28 - loss 1.12097385 - samples/sec: 25.16\n",
            "2020-02-12 15:46:44,869 epoch 27 - iter 12/28 - loss 1.18077825 - samples/sec: 14.65\n",
            "2020-02-12 15:46:49,676 epoch 27 - iter 14/28 - loss 1.15282936 - samples/sec: 21.47\n",
            "2020-02-12 15:46:53,511 epoch 27 - iter 16/28 - loss 1.16180414 - samples/sec: 27.53\n",
            "2020-02-12 15:46:57,840 epoch 27 - iter 18/28 - loss 1.14682612 - samples/sec: 28.48\n",
            "2020-02-12 15:47:01,914 epoch 27 - iter 20/28 - loss 1.15444860 - samples/sec: 28.73\n",
            "2020-02-12 15:47:07,302 epoch 27 - iter 22/28 - loss 1.13793311 - samples/sec: 22.71\n",
            "2020-02-12 15:47:12,177 epoch 27 - iter 24/28 - loss 1.14481606 - samples/sec: 22.15\n",
            "2020-02-12 15:47:17,298 epoch 27 - iter 26/28 - loss 1.14367529 - samples/sec: 22.73\n",
            "2020-02-12 15:47:21,211 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 15:47:21,213 EPOCH 27 done: loss 1.1802 - lr 0.0031\n",
            "2020-02-12 15:47:28,035 DEV : loss 0.8083627223968506 - score 0.6667\n",
            "2020-02-12 15:47:28,065 BAD EPOCHS (no improvement): 2\n",
            "2020-02-12 15:48:40,835 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 15:48:42,096 epoch 28 - iter 0/28 - loss 1.09102821 - samples/sec: 50.88\n",
            "2020-02-12 15:48:53,367 epoch 28 - iter 2/28 - loss 1.40095965 - samples/sec: 29.51\n",
            "2020-02-12 15:48:58,605 epoch 28 - iter 4/28 - loss 1.25158787 - samples/sec: 26.49\n",
            "2020-02-12 15:49:03,730 epoch 28 - iter 6/28 - loss 1.34922246 - samples/sec: 21.81\n",
            "2020-02-12 15:49:07,918 epoch 28 - iter 8/28 - loss 1.34321573 - samples/sec: 26.45\n",
            "2020-02-12 15:49:14,156 epoch 28 - iter 10/28 - loss 1.39867527 - samples/sec: 15.40\n",
            "2020-02-12 15:49:18,746 epoch 28 - iter 12/28 - loss 1.31754255 - samples/sec: 20.35\n",
            "2020-02-12 15:49:23,961 epoch 28 - iter 14/28 - loss 1.34058240 - samples/sec: 19.58\n",
            "2020-02-12 15:49:29,318 epoch 28 - iter 16/28 - loss 1.28406491 - samples/sec: 20.56\n",
            "2020-02-12 15:49:34,263 epoch 28 - iter 18/28 - loss 1.24677116 - samples/sec: 24.99\n",
            "2020-02-12 15:49:38,470 epoch 28 - iter 20/28 - loss 1.29451036 - samples/sec: 25.91\n",
            "2020-02-12 15:49:43,401 epoch 28 - iter 22/28 - loss 1.28368931 - samples/sec: 22.90\n",
            "2020-02-12 15:49:48,614 epoch 28 - iter 24/28 - loss 1.21121634 - samples/sec: 20.49\n",
            "2020-02-12 15:49:53,806 epoch 28 - iter 26/28 - loss 1.21911294 - samples/sec: 26.65\n",
            "2020-02-12 15:49:57,162 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 15:49:57,164 EPOCH 28 done: loss 1.1832 - lr 0.0031\n",
            "2020-02-12 15:50:03,813 DEV : loss 0.8216960430145264 - score 0.6667\n",
            "2020-02-12 15:50:03,847 BAD EPOCHS (no improvement): 3\n",
            "2020-02-12 15:51:18,153 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 15:51:19,284 epoch 29 - iter 0/28 - loss 1.45258904 - samples/sec: 56.72\n",
            "2020-02-12 15:51:22,494 epoch 29 - iter 2/28 - loss 1.00425450 - samples/sec: 23.20\n",
            "2020-02-12 15:51:28,427 epoch 29 - iter 4/28 - loss 1.09111891 - samples/sec: 28.07\n",
            "2020-02-12 15:51:32,845 epoch 29 - iter 6/28 - loss 1.09993049 - samples/sec: 25.27\n",
            "2020-02-12 15:51:37,159 epoch 29 - iter 8/28 - loss 1.20551374 - samples/sec: 27.23\n",
            "2020-02-12 15:51:42,328 epoch 29 - iter 10/28 - loss 1.12209541 - samples/sec: 20.57\n",
            "2020-02-12 15:51:47,713 epoch 29 - iter 12/28 - loss 1.19298355 - samples/sec: 23.76\n",
            "2020-02-12 15:51:53,766 epoch 29 - iter 14/28 - loss 1.13579960 - samples/sec: 17.00\n",
            "2020-02-12 15:51:58,393 epoch 29 - iter 16/28 - loss 1.12059038 - samples/sec: 22.98\n",
            "2020-02-12 15:52:03,016 epoch 29 - iter 18/28 - loss 1.15072742 - samples/sec: 20.06\n",
            "2020-02-12 15:52:07,331 epoch 29 - iter 20/28 - loss 1.15964454 - samples/sec: 29.02\n",
            "2020-02-12 15:52:11,796 epoch 29 - iter 22/28 - loss 1.14296246 - samples/sec: 23.87\n",
            "2020-02-12 15:52:16,727 epoch 29 - iter 24/28 - loss 1.13337240 - samples/sec: 26.63\n",
            "2020-02-12 15:52:21,532 epoch 29 - iter 26/28 - loss 1.11720256 - samples/sec: 23.57\n",
            "2020-02-12 15:52:25,104 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 15:52:25,105 EPOCH 29 done: loss 1.1391 - lr 0.0031\n",
            "2020-02-12 15:52:31,531 DEV : loss 0.8258496522903442 - score 0.6667\n",
            "Epoch    29: reducing learning rate of group 0 to 1.5625e-03.\n",
            "2020-02-12 15:52:31,611 BAD EPOCHS (no improvement): 4\n",
            "2020-02-12 15:53:49,289 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 15:53:53,093 epoch 30 - iter 0/28 - loss 0.92813730 - samples/sec: 46.45\n",
            "2020-02-12 15:53:55,736 epoch 30 - iter 2/28 - loss 1.26567602 - samples/sec: 28.46\n",
            "2020-02-12 15:53:58,278 epoch 30 - iter 4/28 - loss 1.06625233 - samples/sec: 28.23\n",
            "2020-02-12 15:54:04,826 epoch 30 - iter 6/28 - loss 1.37500484 - samples/sec: 14.45\n",
            "2020-02-12 15:54:10,091 epoch 30 - iter 8/28 - loss 1.31632386 - samples/sec: 20.04\n",
            "2020-02-12 15:54:14,710 epoch 30 - iter 10/28 - loss 1.25274767 - samples/sec: 27.55\n",
            "2020-02-12 15:54:19,489 epoch 30 - iter 12/28 - loss 1.36288654 - samples/sec: 22.21\n",
            "2020-02-12 15:54:24,747 epoch 30 - iter 14/28 - loss 1.36123978 - samples/sec: 22.46\n",
            "2020-02-12 15:54:29,294 epoch 30 - iter 16/28 - loss 1.38267464 - samples/sec: 26.56\n",
            "2020-02-12 15:54:34,207 epoch 30 - iter 18/28 - loss 1.34652559 - samples/sec: 23.49\n",
            "2020-02-12 15:54:38,835 epoch 30 - iter 20/28 - loss 1.29945755 - samples/sec: 26.24\n",
            "2020-02-12 15:54:43,412 epoch 30 - iter 22/28 - loss 1.26931066 - samples/sec: 26.48\n",
            "2020-02-12 15:54:48,531 epoch 30 - iter 24/28 - loss 1.28801001 - samples/sec: 27.48\n",
            "2020-02-12 15:54:53,611 epoch 30 - iter 26/28 - loss 1.26549825 - samples/sec: 23.58\n",
            "2020-02-12 15:54:57,169 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 15:54:57,171 EPOCH 30 done: loss 1.2531 - lr 0.0016\n",
            "2020-02-12 15:55:03,713 DEV : loss 0.8331857919692993 - score 0.6667\n",
            "2020-02-12 15:55:03,746 BAD EPOCHS (no improvement): 1\n",
            "2020-02-12 15:56:19,990 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 15:56:21,164 epoch 31 - iter 0/28 - loss 1.63051319 - samples/sec: 54.83\n",
            "2020-02-12 15:56:24,369 epoch 31 - iter 2/28 - loss 1.30323267 - samples/sec: 22.62\n",
            "2020-02-12 15:56:27,080 epoch 31 - iter 4/28 - loss 1.10761271 - samples/sec: 26.75\n",
            "2020-02-12 15:56:30,355 epoch 31 - iter 6/28 - loss 1.09397909 - samples/sec: 21.08\n",
            "2020-02-12 15:56:35,685 epoch 31 - iter 8/28 - loss 1.14187702 - samples/sec: 18.65\n",
            "2020-02-12 15:56:39,965 epoch 31 - iter 10/28 - loss 1.20402601 - samples/sec: 24.38\n",
            "2020-02-12 15:56:45,849 epoch 31 - iter 12/28 - loss 1.17685523 - samples/sec: 15.99\n",
            "2020-02-12 15:56:51,021 epoch 31 - iter 14/28 - loss 1.20134017 - samples/sec: 23.92\n",
            "2020-02-12 15:56:55,239 epoch 31 - iter 16/28 - loss 1.20740666 - samples/sec: 24.62\n",
            "2020-02-12 15:56:59,574 epoch 31 - iter 18/28 - loss 1.22281368 - samples/sec: 28.64\n",
            "2020-02-12 15:57:04,348 epoch 31 - iter 20/28 - loss 1.25182860 - samples/sec: 24.54\n",
            "2020-02-12 15:57:08,416 epoch 31 - iter 22/28 - loss 1.23521581 - samples/sec: 29.39\n",
            "2020-02-12 15:57:12,499 epoch 31 - iter 24/28 - loss 1.26460629 - samples/sec: 27.19\n",
            "2020-02-12 15:57:17,319 epoch 31 - iter 26/28 - loss 1.23876441 - samples/sec: 24.01\n",
            "2020-02-12 15:57:21,793 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 15:57:21,795 EPOCH 31 done: loss 1.2138 - lr 0.0016\n",
            "2020-02-12 15:57:30,198 DEV : loss 0.8211212158203125 - score 0.6667\n",
            "2020-02-12 15:57:30,229 BAD EPOCHS (no improvement): 2\n",
            "2020-02-12 15:58:47,747 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 15:58:48,958 epoch 32 - iter 0/28 - loss 0.59197903 - samples/sec: 52.96\n",
            "2020-02-12 15:58:52,439 epoch 32 - iter 2/28 - loss 1.35092529 - samples/sec: 20.97\n",
            "2020-02-12 15:58:55,648 epoch 32 - iter 4/28 - loss 1.33756561 - samples/sec: 22.27\n",
            "2020-02-12 15:58:58,746 epoch 32 - iter 6/28 - loss 1.21195684 - samples/sec: 22.60\n",
            "2020-02-12 15:59:02,589 epoch 32 - iter 8/28 - loss 1.22242689 - samples/sec: 34.17\n",
            "2020-02-12 15:59:07,085 epoch 32 - iter 10/28 - loss 1.21763372 - samples/sec: 26.98\n",
            "2020-02-12 15:59:12,027 epoch 32 - iter 12/28 - loss 1.21829789 - samples/sec: 23.53\n",
            "2020-02-12 15:59:19,271 epoch 32 - iter 14/28 - loss 1.18393078 - samples/sec: 13.41\n",
            "2020-02-12 15:59:24,228 epoch 32 - iter 16/28 - loss 1.17245015 - samples/sec: 20.48\n",
            "2020-02-12 15:59:31,030 epoch 32 - iter 18/28 - loss 1.18799127 - samples/sec: 22.69\n",
            "2020-02-12 15:59:35,776 epoch 32 - iter 20/28 - loss 1.14213707 - samples/sec: 26.01\n",
            "2020-02-12 15:59:40,855 epoch 32 - iter 22/28 - loss 1.09759938 - samples/sec: 21.70\n",
            "2020-02-12 15:59:45,769 epoch 32 - iter 24/28 - loss 1.11818617 - samples/sec: 26.01\n",
            "2020-02-12 15:59:50,962 epoch 32 - iter 26/28 - loss 1.15071581 - samples/sec: 24.15\n",
            "2020-02-12 15:59:54,023 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 15:59:54,025 EPOCH 32 done: loss 1.1422 - lr 0.0016\n",
            "2020-02-12 16:00:00,303 DEV : loss 0.8289414644241333 - score 0.6667\n",
            "2020-02-12 16:00:00,337 BAD EPOCHS (no improvement): 3\n",
            "2020-02-12 16:01:16,052 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 16:01:17,156 epoch 33 - iter 0/28 - loss 1.49663448 - samples/sec: 58.26\n",
            "2020-02-12 16:01:20,760 epoch 33 - iter 2/28 - loss 0.96982129 - samples/sec: 20.09\n",
            "2020-02-12 16:01:24,659 epoch 33 - iter 4/28 - loss 0.80961971 - samples/sec: 29.54\n",
            "2020-02-12 16:01:26,845 epoch 33 - iter 6/28 - loss 0.91457142 - samples/sec: 33.33\n",
            "2020-02-12 16:01:29,371 epoch 33 - iter 8/28 - loss 0.94450797 - samples/sec: 28.66\n",
            "2020-02-12 16:01:34,648 epoch 33 - iter 10/28 - loss 0.96338966 - samples/sec: 21.40\n",
            "2020-02-12 16:01:39,382 epoch 33 - iter 12/28 - loss 1.03254168 - samples/sec: 24.27\n",
            "2020-02-12 16:01:45,824 epoch 33 - iter 14/28 - loss 1.03683186 - samples/sec: 20.89\n",
            "2020-02-12 16:01:50,624 epoch 33 - iter 16/28 - loss 1.08263176 - samples/sec: 23.11\n",
            "2020-02-12 16:01:55,159 epoch 33 - iter 18/28 - loss 1.13362350 - samples/sec: 25.59\n",
            "2020-02-12 16:02:00,740 epoch 33 - iter 20/28 - loss 1.11367235 - samples/sec: 17.85\n",
            "2020-02-12 16:02:05,478 epoch 33 - iter 22/28 - loss 1.10429347 - samples/sec: 21.90\n",
            "2020-02-12 16:02:10,364 epoch 33 - iter 24/28 - loss 1.13125500 - samples/sec: 22.89\n",
            "2020-02-12 16:02:14,983 epoch 33 - iter 26/28 - loss 1.12225711 - samples/sec: 26.26\n",
            "2020-02-12 16:02:18,634 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 16:02:18,638 EPOCH 33 done: loss 1.1107 - lr 0.0016\n",
            "2020-02-12 16:02:25,326 DEV : loss 0.8223955035209656 - score 0.6667\n",
            "Epoch    33: reducing learning rate of group 0 to 7.8125e-04.\n",
            "2020-02-12 16:02:25,456 BAD EPOCHS (no improvement): 4\n",
            "2020-02-12 16:03:39,517 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 16:03:40,729 epoch 34 - iter 0/28 - loss 1.46865845 - samples/sec: 53.01\n",
            "2020-02-12 16:03:43,174 epoch 34 - iter 2/28 - loss 0.98383649 - samples/sec: 32.15\n",
            "2020-02-12 16:03:47,347 epoch 34 - iter 4/28 - loss 1.10069828 - samples/sec: 16.52\n",
            "2020-02-12 16:03:51,184 epoch 34 - iter 6/28 - loss 1.11161368 - samples/sec: 24.19\n",
            "2020-02-12 16:03:57,650 epoch 34 - iter 8/28 - loss 1.22541820 - samples/sec: 23.73\n",
            "2020-02-12 16:04:02,243 epoch 34 - iter 10/28 - loss 1.14587207 - samples/sec: 24.73\n",
            "2020-02-12 16:04:06,652 epoch 34 - iter 12/28 - loss 1.13207157 - samples/sec: 29.11\n",
            "2020-02-12 16:04:11,825 epoch 34 - iter 14/28 - loss 1.21260967 - samples/sec: 19.57\n",
            "2020-02-12 16:04:16,634 epoch 34 - iter 16/28 - loss 1.17797866 - samples/sec: 23.06\n",
            "2020-02-12 16:04:21,313 epoch 34 - iter 18/28 - loss 1.19421650 - samples/sec: 26.09\n",
            "2020-02-12 16:04:26,555 epoch 34 - iter 20/28 - loss 1.23032976 - samples/sec: 20.56\n",
            "2020-02-12 16:04:31,976 epoch 34 - iter 22/28 - loss 1.23552963 - samples/sec: 20.48\n",
            "2020-02-12 16:04:36,056 epoch 34 - iter 24/28 - loss 1.22729149 - samples/sec: 30.67\n",
            "2020-02-12 16:04:41,075 epoch 34 - iter 26/28 - loss 1.18235834 - samples/sec: 20.54\n",
            "2020-02-12 16:04:44,132 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 16:04:44,134 EPOCH 34 done: loss 1.1856 - lr 0.0008\n",
            "2020-02-12 16:04:50,825 DEV : loss 0.8230285048484802 - score 0.6667\n",
            "2020-02-12 16:04:50,867 BAD EPOCHS (no improvement): 1\n",
            "2020-02-12 16:06:04,566 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 16:06:05,857 epoch 35 - iter 0/28 - loss 0.33110428 - samples/sec: 49.75\n",
            "2020-02-12 16:06:08,515 epoch 35 - iter 2/28 - loss 0.74624523 - samples/sec: 27.99\n",
            "2020-02-12 16:06:11,276 epoch 35 - iter 4/28 - loss 0.99526052 - samples/sec: 25.83\n",
            "2020-02-12 16:06:14,499 epoch 35 - iter 6/28 - loss 1.11069959 - samples/sec: 21.84\n",
            "2020-02-12 16:06:19,459 epoch 35 - iter 8/28 - loss 1.06101174 - samples/sec: 23.24\n",
            "2020-02-12 16:06:24,279 epoch 35 - iter 10/28 - loss 1.10725958 - samples/sec: 23.84\n",
            "2020-02-12 16:06:28,793 epoch 35 - iter 12/28 - loss 1.05893128 - samples/sec: 22.87\n",
            "2020-02-12 16:06:33,120 epoch 35 - iter 14/28 - loss 1.06245489 - samples/sec: 27.69\n",
            "2020-02-12 16:06:38,091 epoch 35 - iter 16/28 - loss 1.04006613 - samples/sec: 24.77\n",
            "2020-02-12 16:06:44,961 epoch 35 - iter 18/28 - loss 1.07621557 - samples/sec: 15.01\n",
            "2020-02-12 16:06:50,016 epoch 35 - iter 20/28 - loss 1.08053523 - samples/sec: 22.04\n",
            "2020-02-12 16:06:54,197 epoch 35 - iter 22/28 - loss 1.20457239 - samples/sec: 30.50\n",
            "2020-02-12 16:06:58,782 epoch 35 - iter 24/28 - loss 1.17248455 - samples/sec: 25.77\n",
            "2020-02-12 16:07:03,612 epoch 35 - iter 26/28 - loss 1.19762557 - samples/sec: 20.55\n",
            "2020-02-12 16:07:06,970 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 16:07:06,972 EPOCH 35 done: loss 1.1906 - lr 0.0008\n",
            "2020-02-12 16:07:13,504 DEV : loss 0.828427255153656 - score 0.6667\n",
            "2020-02-12 16:07:13,538 BAD EPOCHS (no improvement): 2\n",
            "2020-02-12 16:08:32,697 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 16:08:33,445 epoch 36 - iter 0/28 - loss 0.63951159 - samples/sec: 85.94\n",
            "2020-02-12 16:08:36,117 epoch 36 - iter 2/28 - loss 1.44827827 - samples/sec: 28.85\n",
            "2020-02-12 16:08:38,953 epoch 36 - iter 4/28 - loss 1.31876030 - samples/sec: 25.08\n",
            "2020-02-12 16:08:42,009 epoch 36 - iter 6/28 - loss 1.17347540 - samples/sec: 23.40\n",
            "2020-02-12 16:08:49,001 epoch 36 - iter 8/28 - loss 1.16644298 - samples/sec: 14.31\n",
            "2020-02-12 16:08:53,218 epoch 36 - iter 10/28 - loss 1.14249914 - samples/sec: 28.12\n",
            "2020-02-12 16:08:58,332 epoch 36 - iter 12/28 - loss 1.20484315 - samples/sec: 20.59\n",
            "2020-02-12 16:09:03,204 epoch 36 - iter 14/28 - loss 1.17576542 - samples/sec: 28.05\n",
            "2020-02-12 16:09:08,544 epoch 36 - iter 16/28 - loss 1.13451217 - samples/sec: 18.70\n",
            "2020-02-12 16:09:13,575 epoch 36 - iter 18/28 - loss 1.19018459 - samples/sec: 20.40\n",
            "2020-02-12 16:09:18,314 epoch 36 - iter 20/28 - loss 1.19431673 - samples/sec: 26.87\n",
            "2020-02-12 16:09:22,842 epoch 36 - iter 22/28 - loss 1.18333105 - samples/sec: 24.41\n",
            "2020-02-12 16:09:26,517 epoch 36 - iter 24/28 - loss 1.22730053 - samples/sec: 32.32\n",
            "2020-02-12 16:09:31,192 epoch 36 - iter 26/28 - loss 1.18441221 - samples/sec: 23.07\n",
            "2020-02-12 16:09:33,890 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 16:09:33,891 EPOCH 36 done: loss 1.1822 - lr 0.0008\n",
            "2020-02-12 16:09:40,550 DEV : loss 0.828434407711029 - score 0.6667\n",
            "2020-02-12 16:09:40,583 BAD EPOCHS (no improvement): 3\n",
            "2020-02-12 16:10:54,544 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 16:10:55,896 epoch 37 - iter 0/28 - loss 0.41184759 - samples/sec: 51.63\n",
            "2020-02-12 16:11:06,781 epoch 37 - iter 2/28 - loss 0.88109684 - samples/sec: 21.68\n",
            "2020-02-12 16:11:10,976 epoch 37 - iter 4/28 - loss 0.96832552 - samples/sec: 32.84\n",
            "2020-02-12 16:11:16,468 epoch 37 - iter 6/28 - loss 1.21034786 - samples/sec: 23.39\n",
            "2020-02-12 16:11:23,169 epoch 37 - iter 8/28 - loss 1.24575520 - samples/sec: 13.78\n",
            "2020-02-12 16:11:27,855 epoch 37 - iter 10/28 - loss 1.25326993 - samples/sec: 23.52\n",
            "2020-02-12 16:11:32,237 epoch 37 - iter 12/28 - loss 1.28405578 - samples/sec: 23.69\n",
            "2020-02-12 16:11:37,513 epoch 37 - iter 14/28 - loss 1.32580741 - samples/sec: 23.08\n",
            "2020-02-12 16:11:42,454 epoch 37 - iter 16/28 - loss 1.23007993 - samples/sec: 27.59\n",
            "2020-02-12 16:11:47,647 epoch 37 - iter 18/28 - loss 1.17190466 - samples/sec: 26.48\n",
            "2020-02-12 16:11:53,144 epoch 37 - iter 20/28 - loss 1.21509130 - samples/sec: 21.20\n",
            "2020-02-12 16:11:57,977 epoch 37 - iter 22/28 - loss 1.27314493 - samples/sec: 23.27\n",
            "2020-02-12 16:12:02,345 epoch 37 - iter 24/28 - loss 1.24014622 - samples/sec: 30.22\n",
            "2020-02-12 16:12:07,016 epoch 37 - iter 26/28 - loss 1.23966966 - samples/sec: 29.20\n",
            "2020-02-12 16:12:11,676 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 16:12:11,677 EPOCH 37 done: loss 1.2272 - lr 0.0008\n",
            "2020-02-12 16:12:18,593 DEV : loss 0.8269326686859131 - score 0.6667\n",
            "Epoch    37: reducing learning rate of group 0 to 3.9063e-04.\n",
            "2020-02-12 16:12:18,638 BAD EPOCHS (no improvement): 4\n",
            "2020-02-12 16:13:37,686 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 16:13:39,774 epoch 38 - iter 0/28 - loss 1.47968769 - samples/sec: 38.74\n",
            "2020-02-12 16:13:43,188 epoch 38 - iter 2/28 - loss 1.13836114 - samples/sec: 21.12\n",
            "2020-02-12 16:13:47,509 epoch 38 - iter 4/28 - loss 0.99907064 - samples/sec: 23.06\n",
            "2020-02-12 16:13:53,101 epoch 38 - iter 6/28 - loss 0.99479852 - samples/sec: 23.02\n",
            "2020-02-12 16:13:58,801 epoch 38 - iter 8/28 - loss 0.98577907 - samples/sec: 20.80\n",
            "2020-02-12 16:14:03,600 epoch 38 - iter 10/28 - loss 1.07019719 - samples/sec: 25.87\n",
            "2020-02-12 16:14:07,792 epoch 38 - iter 12/28 - loss 1.10923441 - samples/sec: 29.44\n",
            "2020-02-12 16:14:12,894 epoch 38 - iter 14/28 - loss 1.05348183 - samples/sec: 20.93\n",
            "2020-02-12 16:14:17,880 epoch 38 - iter 16/28 - loss 1.03572688 - samples/sec: 23.30\n",
            "2020-02-12 16:14:22,786 epoch 38 - iter 18/28 - loss 1.04129985 - samples/sec: 23.96\n",
            "2020-02-12 16:14:28,897 epoch 38 - iter 20/28 - loss 1.06473957 - samples/sec: 15.72\n",
            "2020-02-12 16:14:33,884 epoch 38 - iter 22/28 - loss 1.08082900 - samples/sec: 21.58\n",
            "2020-02-12 16:14:39,189 epoch 38 - iter 24/28 - loss 1.14521521 - samples/sec: 20.29\n",
            "2020-02-12 16:14:43,623 epoch 38 - iter 26/28 - loss 1.11609240 - samples/sec: 27.77\n",
            "2020-02-12 16:14:47,055 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 16:14:47,058 EPOCH 38 done: loss 1.1325 - lr 0.0004\n",
            "2020-02-12 16:14:53,828 DEV : loss 0.8264094591140747 - score 0.6667\n",
            "2020-02-12 16:14:53,858 BAD EPOCHS (no improvement): 1\n",
            "2020-02-12 16:16:06,913 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 16:16:07,797 epoch 39 - iter 0/28 - loss 2.41349888 - samples/sec: 72.97\n",
            "2020-02-12 16:16:11,025 epoch 39 - iter 2/28 - loss 1.54357910 - samples/sec: 22.78\n",
            "2020-02-12 16:16:18,742 epoch 39 - iter 4/28 - loss 1.17336378 - samples/sec: 25.78\n",
            "2020-02-12 16:16:24,341 epoch 39 - iter 6/28 - loss 1.10769360 - samples/sec: 21.32\n",
            "2020-02-12 16:16:28,550 epoch 39 - iter 8/28 - loss 1.01208141 - samples/sec: 30.37\n",
            "2020-02-12 16:16:35,681 epoch 39 - iter 10/28 - loss 1.05059303 - samples/sec: 13.45\n",
            "2020-02-12 16:16:40,151 epoch 39 - iter 12/28 - loss 1.04228977 - samples/sec: 24.34\n",
            "2020-02-12 16:16:45,057 epoch 39 - iter 14/28 - loss 1.07610671 - samples/sec: 21.22\n",
            "2020-02-12 16:16:49,873 epoch 39 - iter 16/28 - loss 1.06190062 - samples/sec: 24.41\n",
            "2020-02-12 16:16:55,466 epoch 39 - iter 18/28 - loss 1.08297898 - samples/sec: 24.27\n",
            "2020-02-12 16:16:59,846 epoch 39 - iter 20/28 - loss 1.09740407 - samples/sec: 26.49\n",
            "2020-02-12 16:17:03,942 epoch 39 - iter 22/28 - loss 1.10308755 - samples/sec: 30.30\n",
            "2020-02-12 16:17:08,918 epoch 39 - iter 24/28 - loss 1.11751795 - samples/sec: 21.45\n",
            "2020-02-12 16:17:13,326 epoch 39 - iter 26/28 - loss 1.14176051 - samples/sec: 24.60\n",
            "2020-02-12 16:17:16,198 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 16:17:16,200 EPOCH 39 done: loss 1.1458 - lr 0.0004\n",
            "2020-02-12 16:17:22,458 DEV : loss 0.8266488313674927 - score 0.6667\n",
            "2020-02-12 16:17:22,488 BAD EPOCHS (no improvement): 2\n",
            "2020-02-12 16:18:41,335 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 16:18:44,533 epoch 40 - iter 0/28 - loss 0.71215868 - samples/sec: 51.22\n",
            "2020-02-12 16:18:47,363 epoch 40 - iter 2/28 - loss 1.16553370 - samples/sec: 28.12\n",
            "2020-02-12 16:18:49,387 epoch 40 - iter 4/28 - loss 1.35252647 - samples/sec: 35.73\n",
            "2020-02-12 16:18:53,837 epoch 40 - iter 6/28 - loss 1.23435804 - samples/sec: 24.70\n",
            "2020-02-12 16:18:57,911 epoch 40 - iter 8/28 - loss 1.24945307 - samples/sec: 27.13\n",
            "2020-02-12 16:19:02,726 epoch 40 - iter 10/28 - loss 1.23866168 - samples/sec: 23.07\n",
            "2020-02-12 16:19:07,704 epoch 40 - iter 12/28 - loss 1.20937259 - samples/sec: 21.65\n",
            "2020-02-12 16:19:13,212 epoch 40 - iter 14/28 - loss 1.18567867 - samples/sec: 17.01\n",
            "2020-02-12 16:19:18,164 epoch 40 - iter 16/28 - loss 1.16982163 - samples/sec: 23.61\n",
            "2020-02-12 16:19:24,937 epoch 40 - iter 18/28 - loss 1.15854078 - samples/sec: 14.26\n",
            "2020-02-12 16:19:29,640 epoch 40 - iter 20/28 - loss 1.15381252 - samples/sec: 23.79\n",
            "2020-02-12 16:19:34,842 epoch 40 - iter 22/28 - loss 1.11003436 - samples/sec: 27.89\n",
            "2020-02-12 16:19:40,013 epoch 40 - iter 24/28 - loss 1.11742113 - samples/sec: 24.04\n",
            "2020-02-12 16:19:43,330 epoch 40 - iter 26/28 - loss 1.14080629 - samples/sec: 24.18\n",
            "2020-02-12 16:19:45,033 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 16:19:45,037 EPOCH 40 done: loss 1.1633 - lr 0.0004\n",
            "2020-02-12 16:19:51,534 DEV : loss 0.8273439407348633 - score 0.6667\n",
            "2020-02-12 16:19:51,566 BAD EPOCHS (no improvement): 3\n",
            "2020-02-12 16:21:04,863 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 16:21:06,190 epoch 41 - iter 0/28 - loss 1.21793461 - samples/sec: 48.47\n",
            "2020-02-12 16:21:16,904 epoch 41 - iter 2/28 - loss 1.39090331 - samples/sec: 23.24\n",
            "2020-02-12 16:21:20,166 epoch 41 - iter 4/28 - loss 1.31558714 - samples/sec: 21.41\n",
            "2020-02-12 16:21:26,931 epoch 41 - iter 6/28 - loss 1.31170225 - samples/sec: 14.61\n",
            "2020-02-12 16:21:32,633 epoch 41 - iter 8/28 - loss 1.16393163 - samples/sec: 25.78\n",
            "2020-02-12 16:21:38,575 epoch 41 - iter 10/28 - loss 1.24509993 - samples/sec: 22.06\n",
            "2020-02-12 16:21:42,786 epoch 41 - iter 12/28 - loss 1.27870582 - samples/sec: 27.68\n",
            "2020-02-12 16:21:48,003 epoch 41 - iter 14/28 - loss 1.23312785 - samples/sec: 20.29\n",
            "2020-02-12 16:21:52,138 epoch 41 - iter 16/28 - loss 1.23248417 - samples/sec: 26.79\n",
            "2020-02-12 16:21:57,314 epoch 41 - iter 18/28 - loss 1.20347909 - samples/sec: 22.48\n",
            "2020-02-12 16:21:59,494 epoch 41 - iter 20/28 - loss 1.16383042 - samples/sec: 33.86\n",
            "2020-02-12 16:22:02,151 epoch 41 - iter 22/28 - loss 1.18159089 - samples/sec: 27.59\n",
            "2020-02-12 16:22:04,600 epoch 41 - iter 24/28 - loss 1.14770027 - samples/sec: 30.23\n",
            "2020-02-12 16:22:07,970 epoch 41 - iter 26/28 - loss 1.17365215 - samples/sec: 21.31\n",
            "2020-02-12 16:22:09,368 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 16:22:09,370 EPOCH 41 done: loss 1.1567 - lr 0.0004\n",
            "2020-02-12 16:22:15,720 DEV : loss 0.8280528783798218 - score 0.6667\n",
            "Epoch    41: reducing learning rate of group 0 to 1.9531e-04.\n",
            "2020-02-12 16:22:15,766 BAD EPOCHS (no improvement): 4\n",
            "2020-02-12 16:23:30,280 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 16:23:31,512 epoch 42 - iter 0/28 - loss 1.48349762 - samples/sec: 52.31\n",
            "2020-02-12 16:23:42,717 epoch 42 - iter 2/28 - loss 1.27271016 - samples/sec: 22.70\n",
            "2020-02-12 16:23:47,666 epoch 42 - iter 4/28 - loss 1.00531425 - samples/sec: 29.39\n",
            "2020-02-12 16:23:53,072 epoch 42 - iter 6/28 - loss 0.91916622 - samples/sec: 20.12\n",
            "2020-02-12 16:23:58,555 epoch 42 - iter 8/28 - loss 0.92955844 - samples/sec: 18.52\n",
            "2020-02-12 16:24:03,282 epoch 42 - iter 10/28 - loss 0.92401123 - samples/sec: 22.90\n",
            "2020-02-12 16:24:09,590 epoch 42 - iter 12/28 - loss 0.93826815 - samples/sec: 22.03\n",
            "2020-02-12 16:24:14,519 epoch 42 - iter 14/28 - loss 0.90616935 - samples/sec: 22.70\n",
            "2020-02-12 16:24:19,569 epoch 42 - iter 16/28 - loss 1.05215115 - samples/sec: 21.52\n",
            "2020-02-12 16:24:26,991 epoch 42 - iter 18/28 - loss 1.07852351 - samples/sec: 14.23\n",
            "2020-02-12 16:24:31,499 epoch 42 - iter 20/28 - loss 1.15087323 - samples/sec: 30.59\n",
            "2020-02-12 16:24:37,441 epoch 42 - iter 22/28 - loss 1.18065940 - samples/sec: 24.20\n",
            "2020-02-12 16:24:42,560 epoch 42 - iter 24/28 - loss 1.18475691 - samples/sec: 22.36\n",
            "2020-02-12 16:24:47,309 epoch 42 - iter 26/28 - loss 1.18646708 - samples/sec: 28.76\n",
            "2020-02-12 16:24:50,317 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 16:24:50,319 EPOCH 42 done: loss 1.1828 - lr 0.0002\n",
            "2020-02-12 16:24:56,876 DEV : loss 0.8282015323638916 - score 0.6667\n",
            "2020-02-12 16:24:56,911 BAD EPOCHS (no improvement): 1\n",
            "2020-02-12 16:26:12,243 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 16:26:13,198 epoch 43 - iter 0/28 - loss 1.38783264 - samples/sec: 67.17\n",
            "2020-02-12 16:26:17,773 epoch 43 - iter 2/28 - loss 1.39508009 - samples/sec: 15.48\n",
            "2020-02-12 16:26:21,733 epoch 43 - iter 4/28 - loss 1.03969212 - samples/sec: 24.60\n",
            "2020-02-12 16:26:26,681 epoch 43 - iter 6/28 - loss 1.17813322 - samples/sec: 23.62\n",
            "2020-02-12 16:26:31,135 epoch 43 - iter 8/28 - loss 1.13849825 - samples/sec: 23.11\n",
            "2020-02-12 16:26:35,850 epoch 43 - iter 10/28 - loss 1.02298654 - samples/sec: 23.00\n",
            "2020-02-12 16:26:40,343 epoch 43 - iter 12/28 - loss 1.08946921 - samples/sec: 28.08\n",
            "2020-02-12 16:26:46,444 epoch 43 - iter 14/28 - loss 1.07265148 - samples/sec: 18.94\n",
            "2020-02-12 16:26:50,816 epoch 43 - iter 16/28 - loss 1.08721340 - samples/sec: 26.05\n",
            "2020-02-12 16:26:55,256 epoch 43 - iter 18/28 - loss 1.06991856 - samples/sec: 27.89\n",
            "2020-02-12 16:27:00,775 epoch 43 - iter 20/28 - loss 1.16108481 - samples/sec: 23.59\n",
            "2020-02-12 16:27:06,296 epoch 43 - iter 22/28 - loss 1.17477680 - samples/sec: 21.12\n",
            "2020-02-12 16:27:11,563 epoch 43 - iter 24/28 - loss 1.18492924 - samples/sec: 23.81\n",
            "2020-02-12 16:27:16,179 epoch 43 - iter 26/28 - loss 1.14730706 - samples/sec: 33.67\n",
            "2020-02-12 16:27:18,910 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 16:27:18,912 EPOCH 43 done: loss 1.1498 - lr 0.0002\n",
            "2020-02-12 16:27:25,374 DEV : loss 0.8298224806785583 - score 0.6667\n",
            "2020-02-12 16:27:25,405 BAD EPOCHS (no improvement): 2\n",
            "2020-02-12 16:28:40,146 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 16:28:41,472 epoch 44 - iter 0/28 - loss 1.59242678 - samples/sec: 48.45\n",
            "2020-02-12 16:28:51,502 epoch 44 - iter 2/28 - loss 1.31648238 - samples/sec: 16.46\n",
            "2020-02-12 16:28:56,705 epoch 44 - iter 4/28 - loss 1.27160330 - samples/sec: 23.56\n",
            "2020-02-12 16:29:01,827 epoch 44 - iter 6/28 - loss 1.25554487 - samples/sec: 25.27\n",
            "2020-02-12 16:29:07,464 epoch 44 - iter 8/28 - loss 1.13007948 - samples/sec: 19.00\n",
            "2020-02-12 16:29:11,658 epoch 44 - iter 10/28 - loss 1.16896954 - samples/sec: 27.01\n",
            "2020-02-12 16:29:17,758 epoch 44 - iter 12/28 - loss 1.22338985 - samples/sec: 22.36\n",
            "2020-02-12 16:29:23,048 epoch 44 - iter 14/28 - loss 1.22930667 - samples/sec: 24.07\n",
            "2020-02-12 16:29:28,111 epoch 44 - iter 16/28 - loss 1.21425539 - samples/sec: 21.23\n",
            "2020-02-12 16:29:31,378 epoch 44 - iter 18/28 - loss 1.23129985 - samples/sec: 22.55\n",
            "2020-02-12 16:29:34,993 epoch 44 - iter 20/28 - loss 1.21909578 - samples/sec: 19.37\n",
            "2020-02-12 16:29:38,389 epoch 44 - iter 22/28 - loss 1.20585740 - samples/sec: 20.74\n",
            "2020-02-12 16:29:41,140 epoch 44 - iter 24/28 - loss 1.18141520 - samples/sec: 26.57\n",
            "2020-02-12 16:29:44,483 epoch 44 - iter 26/28 - loss 1.15567280 - samples/sec: 21.24\n",
            "2020-02-12 16:29:46,071 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 16:29:46,073 EPOCH 44 done: loss 1.1464 - lr 0.0002\n",
            "2020-02-12 16:29:52,813 DEV : loss 0.830018937587738 - score 0.6667\n",
            "2020-02-12 16:29:52,846 BAD EPOCHS (no improvement): 3\n",
            "2020-02-12 16:31:12,003 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 16:31:13,327 epoch 45 - iter 0/28 - loss 1.09531403 - samples/sec: 48.66\n",
            "2020-02-12 16:31:17,147 epoch 45 - iter 2/28 - loss 1.17843564 - samples/sec: 25.84\n",
            "2020-02-12 16:31:21,623 epoch 45 - iter 4/28 - loss 1.20569572 - samples/sec: 24.29\n",
            "2020-02-12 16:31:26,122 epoch 45 - iter 6/28 - loss 1.09117188 - samples/sec: 27.29\n",
            "2020-02-12 16:31:31,295 epoch 45 - iter 8/28 - loss 1.17597829 - samples/sec: 22.73\n",
            "2020-02-12 16:31:37,554 epoch 45 - iter 10/28 - loss 1.22191022 - samples/sec: 20.14\n",
            "2020-02-12 16:31:41,680 epoch 45 - iter 12/28 - loss 1.23973322 - samples/sec: 26.63\n",
            "2020-02-12 16:31:45,811 epoch 45 - iter 14/28 - loss 1.22580865 - samples/sec: 31.65\n",
            "2020-02-12 16:31:52,511 epoch 45 - iter 16/28 - loss 1.31315475 - samples/sec: 14.44\n",
            "2020-02-12 16:31:58,238 epoch 45 - iter 18/28 - loss 1.24828979 - samples/sec: 17.99\n",
            "2020-02-12 16:32:02,188 epoch 45 - iter 20/28 - loss 1.26624346 - samples/sec: 24.69\n",
            "2020-02-12 16:32:04,608 epoch 45 - iter 22/28 - loss 1.26162873 - samples/sec: 30.65\n",
            "2020-02-12 16:32:07,063 epoch 45 - iter 24/28 - loss 1.26121468 - samples/sec: 30.30\n",
            "2020-02-12 16:32:10,178 epoch 45 - iter 26/28 - loss 1.20103827 - samples/sec: 23.20\n",
            "2020-02-12 16:32:11,775 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 16:32:11,776 EPOCH 45 done: loss 1.1986 - lr 0.0002\n",
            "2020-02-12 16:32:18,177 DEV : loss 0.8313590884208679 - score 0.6667\n",
            "Epoch    45: reducing learning rate of group 0 to 9.7656e-05.\n",
            "2020-02-12 16:32:18,223 BAD EPOCHS (no improvement): 4\n",
            "2020-02-12 16:33:31,701 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 16:33:31,703 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 16:33:31,705 learning rate too small - quitting training!\n",
            "2020-02-12 16:33:31,706 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 16:35:13,041 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 16:35:13,043 Testing using best model ...\n",
            "2020-02-12 16:35:13,058 loading file /content/drive/My Drive/Colab Notebooks/Fall-Recognition/Data/FOLDER_2/TRN-FD2/best-model.pt\n",
            "2020-02-12 16:40:36,183 0.566\t0.5325\t0.5487\n",
            "2020-02-12 16:40:36,185 \n",
            "MICRO_AVG: acc 0.3782 - f1-score 0.5487\n",
            "MACRO_AVG: acc 0.3782 - f1-score 0.5487\n",
            "QUEDA      tp: 90 - fp: 69 - fn: 79 - tn: 90 - precision: 0.5660 - recall: 0.5325 - accuracy: 0.3782 - f1-score: 0.5487\n",
            "2020-02-12 16:40:36,186 ----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'test_score': 0.5487,\n",
              " 'dev_score_history': [0.4,\n",
              "  0.3824,\n",
              "  0.619,\n",
              "  0.6809,\n",
              "  0.7111,\n",
              "  0.625,\n",
              "  0.6809,\n",
              "  0.6829,\n",
              "  0.6977,\n",
              "  0.6818,\n",
              "  0.6809,\n",
              "  0.6957,\n",
              "  0.6809,\n",
              "  0.6122,\n",
              "  0.6122,\n",
              "  0.6809,\n",
              "  0.6531,\n",
              "  0.6667,\n",
              "  0.6667,\n",
              "  0.6667,\n",
              "  0.6667,\n",
              "  0.6667,\n",
              "  0.6667,\n",
              "  0.6667,\n",
              "  0.6667,\n",
              "  0.6667,\n",
              "  0.6667,\n",
              "  0.6667,\n",
              "  0.6667,\n",
              "  0.6667,\n",
              "  0.6667,\n",
              "  0.6667,\n",
              "  0.6667,\n",
              "  0.6667,\n",
              "  0.6667,\n",
              "  0.6667,\n",
              "  0.6667,\n",
              "  0.6667,\n",
              "  0.6667,\n",
              "  0.6667,\n",
              "  0.6667,\n",
              "  0.6667,\n",
              "  0.6667,\n",
              "  0.6667,\n",
              "  0.6667],\n",
              " 'train_loss_history': [31.719597629138402,\n",
              "  3.506468823977879,\n",
              "  2.929951557091304,\n",
              "  2.557249801499503,\n",
              "  2.2359372547694614,\n",
              "  2.0809710877282277,\n",
              "  1.8982645188059126,\n",
              "  1.7724333831242152,\n",
              "  1.7003732919692993,\n",
              "  1.5558743902615138,\n",
              "  1.502244621515274,\n",
              "  1.4588197299412318,\n",
              "  1.376197725534439,\n",
              "  1.3836767737354552,\n",
              "  1.292341330221721,\n",
              "  1.3230521636349815,\n",
              "  1.286066702433995,\n",
              "  1.2599465123244695,\n",
              "  1.184630913393838,\n",
              "  1.2242426020758492,\n",
              "  1.1742317931992667,\n",
              "  1.1576455278056008,\n",
              "  1.218596875667572,\n",
              "  1.14192562018122,\n",
              "  1.158649984214987,\n",
              "  1.150587878056935,\n",
              "  1.1802469406809126,\n",
              "  1.1832059962408883,\n",
              "  1.1390624684946877,\n",
              "  1.253063685127667,\n",
              "  1.2138372489384242,\n",
              "  1.1422114776713508,\n",
              "  1.1107355483940669,\n",
              "  1.1856386406081063,\n",
              "  1.1905803637845176,\n",
              "  1.182244028363909,\n",
              "  1.2271867266723089,\n",
              "  1.132530348641532,\n",
              "  1.1457814063344682,\n",
              "  1.1632514425686427,\n",
              "  1.1566548134599413,\n",
              "  1.1827726534434728,\n",
              "  1.1498384305409022,\n",
              "  1.1464089836393083,\n",
              "  1.1986337900161743],\n",
              " 'dev_loss_history': [tensor(1.9770, device='cuda:0'),\n",
              "  tensor(2.3950, device='cuda:0'),\n",
              "  tensor(1.1699, device='cuda:0'),\n",
              "  tensor(1.2317, device='cuda:0'),\n",
              "  tensor(1.0517, device='cuda:0'),\n",
              "  tensor(1.0676, device='cuda:0'),\n",
              "  tensor(0.9588, device='cuda:0'),\n",
              "  tensor(0.9092, device='cuda:0'),\n",
              "  tensor(0.8595, device='cuda:0'),\n",
              "  tensor(0.8665, device='cuda:0'),\n",
              "  tensor(0.9203, device='cuda:0'),\n",
              "  tensor(0.8674, device='cuda:0'),\n",
              "  tensor(0.8598, device='cuda:0'),\n",
              "  tensor(0.9820, device='cuda:0'),\n",
              "  tensor(0.8948, device='cuda:0'),\n",
              "  tensor(0.8236, device='cuda:0'),\n",
              "  tensor(0.8985, device='cuda:0'),\n",
              "  tensor(0.8199, device='cuda:0'),\n",
              "  tensor(0.8390, device='cuda:0'),\n",
              "  tensor(0.8073, device='cuda:0'),\n",
              "  tensor(0.8155, device='cuda:0'),\n",
              "  tensor(0.8355, device='cuda:0'),\n",
              "  tensor(0.7989, device='cuda:0'),\n",
              "  tensor(0.7910, device='cuda:0'),\n",
              "  tensor(0.8168, device='cuda:0'),\n",
              "  tensor(0.8044, device='cuda:0'),\n",
              "  tensor(0.8084, device='cuda:0'),\n",
              "  tensor(0.8217, device='cuda:0'),\n",
              "  tensor(0.8258, device='cuda:0'),\n",
              "  tensor(0.8332, device='cuda:0'),\n",
              "  tensor(0.8211, device='cuda:0'),\n",
              "  tensor(0.8289, device='cuda:0'),\n",
              "  tensor(0.8224, device='cuda:0'),\n",
              "  tensor(0.8230, device='cuda:0'),\n",
              "  tensor(0.8284, device='cuda:0'),\n",
              "  tensor(0.8284, device='cuda:0'),\n",
              "  tensor(0.8269, device='cuda:0'),\n",
              "  tensor(0.8264, device='cuda:0'),\n",
              "  tensor(0.8266, device='cuda:0'),\n",
              "  tensor(0.8273, device='cuda:0'),\n",
              "  tensor(0.8281, device='cuda:0'),\n",
              "  tensor(0.8282, device='cuda:0'),\n",
              "  tensor(0.8298, device='cuda:0'),\n",
              "  tensor(0.8300, device='cuda:0'),\n",
              "  tensor(0.8314, device='cuda:0')]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eoeiETcQLlk4",
        "colab_type": "text"
      },
      "source": [
        "## FOLD 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Lk2vO6OLl11",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b4a9157e-aaf0-4470-fe49-68ce32523774"
      },
      "source": [
        "pathCorpus : str = '/content/Fall-Recognition/Data/FOLDER_3/'\n",
        "train_file : str = 'Train-SPLIT-3.txt'\n",
        "test_file : str = 'Test-SPLIT-3.txt'\n",
        "dev_file : str = 'CoNLL-dev.txt'\n",
        "pathCheckpoint: str = '/content/Fall-Recognition/Data/FOLDER_3/TRN-FD3'\n",
        "pathWordEmbeddings : str = 'health_fasttext_300.model'\n",
        "pathFlairEmbeddingsForward : str = None\n",
        "pathFlairEmbeddingsBackward : str =  None\n",
        "\n",
        "print('--------------------------START TRAINING (TOKEN)------------------------------')\n",
        "\n",
        "columns = {0:'token', 1:'label'}\n",
        "\n",
        "corpus: Corpus = ColumnCorpus(pathCorpus, columns,\n",
        "\ttrain_file = train_file,\n",
        "\ttest_file = test_file,\n",
        "\tdev_file = dev_file)\n",
        "\n",
        "print(\" \")\n",
        "print(\"Train len: \", len(corpus.train))\n",
        "print(\"Test len: \", len(corpus.test))\n",
        "print(\"Dev len: \", len(corpus.dev))\n",
        "\n",
        "tag_type = 'label'\n",
        "tag_dictionary = corpus.make_tag_dictionary(tag_type=tag_type)\n",
        "\n",
        "print(tag_dictionary.idx2item)\n",
        "print(\"len: \", len(tag_dictionary.idx2item))\n",
        "\n",
        "health_embedding = WordEmbeddings(pathWordEmbeddings)\n",
        "#flair_forward_embedding = FlairEmbeddings(pathFlairEmbeddingsForward)\n",
        "#flair_backward_embedding = FlairEmbeddings(pathFlairEmbeddingsBackward)\n",
        "\n",
        "embedding_types: List[TokenEmbeddings] = [\n",
        "\thealth_embedding,\n",
        "]\n",
        "  \n",
        "embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)\n",
        "\t\n",
        "tagger: SequenceTagger = SequenceTagger(hidden_size=256,\n",
        "\t\t\t\t\t\t\t\t\t\tembeddings=embeddings,\n",
        "\t\t\t\t\t\t\t\t\t\ttag_dictionary=tag_dictionary,\n",
        "\t\t\t\t\t\t\t\t\t\ttag_type=tag_type,\n",
        "\t\t\t\t\t\t\t\t\t\tuse_crf=True)\n",
        "\n",
        "trainer: ModelTrainer = ModelTrainer(tagger, corpus, optimizer=SGDW)\n",
        "\n",
        "trainer.train(pathCheckpoint,\n",
        "\t\t\t  learning_rate=0.1,\n",
        "\t\t\t  mini_batch_size=32,\n",
        "\t\t\t  max_epochs=150,\n",
        "\t\t\t  checkpoint=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------------START TRAINING (TOKEN)------------------------------\n",
            "2020-02-12 17:03:01,509 Reading data from /content/drive/My Drive/Colab Notebooks/Fall-Recognition/Data/FOLDER_3\n",
            "2020-02-12 17:03:01,510 Train: /content/drive/My Drive/Colab Notebooks/Fall-Recognition/Data/FOLDER_3/Train-SPLIT-3.txt\n",
            "2020-02-12 17:03:01,511 Dev: /content/drive/My Drive/Colab Notebooks/Fall-Recognition/Data/FOLDER_3/CoNLL-dev.txt\n",
            "2020-02-12 17:03:01,512 Test: /content/drive/My Drive/Colab Notebooks/Fall-Recognition/Data/FOLDER_3/Test-SPLIT-3.txt\n",
            " \n",
            "Train len:  888\n",
            "Test len:  444\n",
            "Dev len:  70\n",
            "[b'<unk>', b'O', b'B-QUEDA', b'I-QUEDA', b'<START>', b'<STOP>']\n",
            "len:  6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-02-12 17:03:23,056 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 17:03:23,058 Model: \"SequenceTagger(\n",
            "  (embeddings): StackedEmbeddings(\n",
            "    (list_embedding_0): WordEmbeddings('health_fasttext_300.model')\n",
            "  )\n",
            "  (word_dropout): WordDropout(p=0.05)\n",
            "  (locked_dropout): LockedDropout(p=0.5)\n",
            "  (embedding2nn): Linear(in_features=300, out_features=300, bias=True)\n",
            "  (rnn): LSTM(300, 256, bidirectional=True)\n",
            "  (linear): Linear(in_features=512, out_features=6, bias=True)\n",
            ")\"\n",
            "2020-02-12 17:03:23,059 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 17:03:23,061 Corpus: \"Corpus: 888 train + 70 dev + 444 test sentences\"\n",
            "2020-02-12 17:03:23,062 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 17:03:23,064 Parameters:\n",
            "2020-02-12 17:03:23,066  - learning_rate: \"0.1\"\n",
            "2020-02-12 17:03:23,067  - mini_batch_size: \"32\"\n",
            "2020-02-12 17:03:23,069  - patience: \"3\"\n",
            "2020-02-12 17:03:23,071  - anneal_factor: \"0.5\"\n",
            "2020-02-12 17:03:23,072  - max_epochs: \"150\"\n",
            "2020-02-12 17:03:23,074  - shuffle: \"True\"\n",
            "2020-02-12 17:03:23,075  - train_with_dev: \"False\"\n",
            "2020-02-12 17:03:23,077 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 17:03:23,078 Model training base path: \"/content/drive/My Drive/Colab Notebooks/Fall-Recognition/Data/FOLDER_3/TRN-FD3\"\n",
            "2020-02-12 17:03:23,080 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 17:03:23,081 Device: cuda:0\n",
            "2020-02-12 17:03:23,083 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 17:03:23,084 Embeddings storage mode: cpu\n",
            "2020-02-12 17:03:23,094 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 17:03:25,081 epoch 1 - iter 0/28 - loss 245.06304932 - samples/sec: 32.23\n",
            "2020-02-12 17:03:30,367 epoch 1 - iter 2/28 - loss 174.43720754 - samples/sec: 12.86\n",
            "2020-02-12 17:03:34,372 epoch 1 - iter 4/28 - loss 113.57671013 - samples/sec: 17.13\n",
            "2020-02-12 17:03:39,178 epoch 1 - iter 6/28 - loss 83.31669610 - samples/sec: 14.24\n",
            "2020-02-12 17:03:43,596 epoch 1 - iter 8/28 - loss 66.53531737 - samples/sec: 15.53\n",
            "2020-02-12 17:03:47,503 epoch 1 - iter 10/28 - loss 55.67081612 - samples/sec: 17.54\n",
            "2020-02-12 17:03:51,868 epoch 1 - iter 12/28 - loss 47.98281798 - samples/sec: 15.46\n",
            "2020-02-12 17:03:55,142 epoch 1 - iter 14/28 - loss 42.23753421 - samples/sec: 21.18\n",
            "2020-02-12 17:03:59,882 epoch 1 - iter 16/28 - loss 37.70433162 - samples/sec: 14.30\n",
            "2020-02-12 17:04:03,604 epoch 1 - iter 18/28 - loss 34.26805822 - samples/sec: 18.74\n",
            "2020-02-12 17:04:07,337 epoch 1 - iter 20/28 - loss 31.36492563 - samples/sec: 18.57\n",
            "2020-02-12 17:04:11,659 epoch 1 - iter 22/28 - loss 29.04949787 - samples/sec: 15.72\n",
            "2020-02-12 17:04:16,801 epoch 1 - iter 24/28 - loss 26.99010832 - samples/sec: 13.27\n",
            "2020-02-12 17:04:20,214 epoch 1 - iter 26/28 - loss 25.33049534 - samples/sec: 20.17\n",
            "2020-02-12 17:04:21,879 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 17:04:21,881 EPOCH 1 done: loss 24.5403 - lr 0.1000\n",
            "2020-02-12 17:04:29,489 DEV : loss 1.7596242427825928 - score 0.4783\n",
            "2020-02-12 17:04:29,525 BAD EPOCHS (no improvement): 0\n",
            "2020-02-12 17:07:29,074 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 17:07:30,380 epoch 2 - iter 0/28 - loss 3.36129689 - samples/sec: 49.14\n",
            "2020-02-12 17:07:39,330 epoch 2 - iter 2/28 - loss 3.13167993 - samples/sec: 25.82\n",
            "2020-02-12 17:07:47,307 epoch 2 - iter 4/28 - loss 3.52614665 - samples/sec: 28.48\n",
            "2020-02-12 17:07:55,113 epoch 2 - iter 6/28 - loss 3.23875863 - samples/sec: 25.02\n",
            "2020-02-12 17:08:02,063 epoch 2 - iter 8/28 - loss 3.03094223 - samples/sec: 28.94\n",
            "2020-02-12 17:08:09,192 epoch 2 - iter 10/28 - loss 3.10560651 - samples/sec: 26.31\n",
            "2020-02-12 17:08:17,639 epoch 2 - iter 12/28 - loss 3.30569825 - samples/sec: 24.73\n",
            "2020-02-12 17:08:26,779 epoch 2 - iter 14/28 - loss 3.48078953 - samples/sec: 17.20\n",
            "2020-02-12 17:08:36,204 epoch 2 - iter 16/28 - loss 3.41224729 - samples/sec: 17.55\n",
            "2020-02-12 17:08:43,584 epoch 2 - iter 18/28 - loss 3.40023831 - samples/sec: 28.90\n",
            "2020-02-12 17:08:51,147 epoch 2 - iter 20/28 - loss 3.49288841 - samples/sec: 26.74\n",
            "2020-02-12 17:08:59,411 epoch 2 - iter 22/28 - loss 3.48373322 - samples/sec: 23.22\n",
            "2020-02-12 17:09:06,086 epoch 2 - iter 24/28 - loss 3.46844225 - samples/sec: 22.64\n",
            "2020-02-12 17:09:13,296 epoch 2 - iter 26/28 - loss 3.42058240 - samples/sec: 26.23\n",
            "2020-02-12 17:09:18,700 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 17:09:18,701 EPOCH 2 done: loss 3.3850 - lr 0.1000\n",
            "2020-02-12 17:09:24,898 DEV : loss 1.459777593612671 - score 0.6383\n",
            "2020-02-12 17:09:24,932 BAD EPOCHS (no improvement): 0\n",
            "2020-02-12 17:12:27,330 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 17:12:28,339 epoch 3 - iter 0/28 - loss 3.76588368 - samples/sec: 63.57\n",
            "2020-02-12 17:12:34,065 epoch 3 - iter 2/28 - loss 4.02895379 - samples/sec: 22.93\n",
            "2020-02-12 17:12:39,212 epoch 3 - iter 4/28 - loss 3.74412971 - samples/sec: 23.42\n",
            "2020-02-12 17:12:45,107 epoch 3 - iter 6/28 - loss 3.23689076 - samples/sec: 25.36\n",
            "2020-02-12 17:12:52,881 epoch 3 - iter 8/28 - loss 3.17895601 - samples/sec: 21.25\n",
            "2020-02-12 17:12:59,491 epoch 3 - iter 10/28 - loss 2.95579089 - samples/sec: 35.07\n",
            "2020-02-12 17:13:06,206 epoch 3 - iter 12/28 - loss 2.77793314 - samples/sec: 26.40\n",
            "2020-02-12 17:13:13,406 epoch 3 - iter 14/28 - loss 2.75993377 - samples/sec: 27.48\n",
            "2020-02-12 17:13:20,398 epoch 3 - iter 16/28 - loss 2.75070632 - samples/sec: 26.49\n",
            "2020-02-12 17:13:27,173 epoch 3 - iter 18/28 - loss 2.68908274 - samples/sec: 23.75\n",
            "2020-02-12 17:13:34,221 epoch 3 - iter 20/28 - loss 2.62501461 - samples/sec: 23.38\n",
            "2020-02-12 17:13:40,526 epoch 3 - iter 22/28 - loss 2.67970177 - samples/sec: 28.39\n",
            "2020-02-12 17:13:48,712 epoch 3 - iter 24/28 - loss 2.71978681 - samples/sec: 16.65\n",
            "2020-02-12 17:13:56,905 epoch 3 - iter 26/28 - loss 2.69623953 - samples/sec: 16.28\n",
            "2020-02-12 17:14:02,402 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 17:14:02,404 EPOCH 3 done: loss 2.6585 - lr 0.1000\n",
            "2020-02-12 17:14:08,832 DEV : loss 1.2847518920898438 - score 0.6809\n",
            "2020-02-12 17:14:08,868 BAD EPOCHS (no improvement): 0\n",
            "2020-02-12 17:17:12,869 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 17:17:14,437 epoch 4 - iter 0/28 - loss 2.07671928 - samples/sec: 43.31\n",
            "2020-02-12 17:17:18,722 epoch 4 - iter 2/28 - loss 2.00757678 - samples/sec: 27.18\n",
            "2020-02-12 17:17:24,491 epoch 4 - iter 4/28 - loss 2.16796989 - samples/sec: 16.36\n",
            "2020-02-12 17:17:31,109 epoch 4 - iter 6/28 - loss 2.81592451 - samples/sec: 29.97\n",
            "2020-02-12 17:17:38,687 epoch 4 - iter 8/28 - loss 2.91416346 - samples/sec: 22.76\n",
            "2020-02-12 17:17:47,427 epoch 4 - iter 10/28 - loss 3.05648914 - samples/sec: 20.99\n",
            "2020-02-12 17:17:53,998 epoch 4 - iter 12/28 - loss 2.77923468 - samples/sec: 26.37\n",
            "2020-02-12 17:18:00,167 epoch 4 - iter 14/28 - loss 2.56727354 - samples/sec: 32.27\n",
            "2020-02-12 17:18:08,443 epoch 4 - iter 16/28 - loss 2.49460448 - samples/sec: 17.91\n",
            "2020-02-12 17:18:17,426 epoch 4 - iter 18/28 - loss 2.60686596 - samples/sec: 31.04\n",
            "2020-02-12 17:18:24,922 epoch 4 - iter 20/28 - loss 2.47465100 - samples/sec: 28.46\n",
            "2020-02-12 17:18:31,157 epoch 4 - iter 22/28 - loss 2.37875014 - samples/sec: 27.99\n",
            "2020-02-12 17:18:38,217 epoch 4 - iter 24/28 - loss 2.34094206 - samples/sec: 27.25\n",
            "2020-02-12 17:18:45,874 epoch 4 - iter 26/28 - loss 2.34643049 - samples/sec: 26.71\n",
            "2020-02-12 17:18:51,162 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 17:18:51,165 EPOCH 4 done: loss 2.3566 - lr 0.1000\n",
            "2020-02-12 17:18:57,428 DEV : loss 1.3526039123535156 - score 0.6522\n",
            "2020-02-12 17:18:57,460 BAD EPOCHS (no improvement): 1\n",
            "2020-02-12 17:20:22,232 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 17:20:23,525 epoch 5 - iter 0/28 - loss 1.77601480 - samples/sec: 49.70\n",
            "2020-02-12 17:20:29,512 epoch 5 - iter 2/28 - loss 2.64614439 - samples/sec: 23.72\n",
            "2020-02-12 17:20:34,695 epoch 5 - iter 4/28 - loss 2.04372959 - samples/sec: 26.23\n",
            "2020-02-12 17:20:38,651 epoch 5 - iter 6/28 - loss 2.00156532 - samples/sec: 25.52\n",
            "2020-02-12 17:20:42,910 epoch 5 - iter 8/28 - loss 1.83636448 - samples/sec: 24.81\n",
            "2020-02-12 17:20:46,990 epoch 5 - iter 10/28 - loss 2.00592756 - samples/sec: 28.53\n",
            "2020-02-12 17:20:51,859 epoch 5 - iter 12/28 - loss 2.07447624 - samples/sec: 23.61\n",
            "2020-02-12 17:20:58,309 epoch 5 - iter 14/28 - loss 2.18270868 - samples/sec: 15.32\n",
            "2020-02-12 17:21:04,030 epoch 5 - iter 16/28 - loss 2.22265361 - samples/sec: 21.38\n",
            "2020-02-12 17:21:09,100 epoch 5 - iter 18/28 - loss 2.27279668 - samples/sec: 24.12\n",
            "2020-02-12 17:21:14,956 epoch 5 - iter 20/28 - loss 2.17626052 - samples/sec: 16.73\n",
            "2020-02-12 17:21:19,158 epoch 5 - iter 22/28 - loss 2.09031281 - samples/sec: 26.38\n",
            "2020-02-12 17:21:24,760 epoch 5 - iter 24/28 - loss 2.08199415 - samples/sec: 21.87\n",
            "2020-02-12 17:21:29,563 epoch 5 - iter 26/28 - loss 2.12680665 - samples/sec: 24.43\n",
            "2020-02-12 17:21:33,431 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 17:21:33,433 EPOCH 5 done: loss 2.1381 - lr 0.1000\n",
            "2020-02-12 17:21:41,870 DEV : loss 1.005042552947998 - score 0.579\n",
            "2020-02-12 17:21:41,906 BAD EPOCHS (no improvement): 2\n",
            "2020-02-12 17:23:02,240 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 17:23:03,986 epoch 6 - iter 0/28 - loss 1.38277578 - samples/sec: 45.59\n",
            "2020-02-12 17:23:10,553 epoch 6 - iter 2/28 - loss 1.53081687 - samples/sec: 24.02\n",
            "2020-02-12 17:23:17,268 epoch 6 - iter 4/28 - loss 1.54722672 - samples/sec: 14.42\n",
            "2020-02-12 17:23:21,752 epoch 6 - iter 6/28 - loss 1.46312959 - samples/sec: 27.56\n",
            "2020-02-12 17:23:27,163 epoch 6 - iter 8/28 - loss 1.53203318 - samples/sec: 25.19\n",
            "2020-02-12 17:23:32,674 epoch 6 - iter 10/28 - loss 1.52356928 - samples/sec: 20.98\n",
            "2020-02-12 17:23:37,117 epoch 6 - iter 12/28 - loss 1.68040078 - samples/sec: 29.26\n",
            "2020-02-12 17:23:41,717 epoch 6 - iter 14/28 - loss 1.69010607 - samples/sec: 23.87\n",
            "2020-02-12 17:23:46,292 epoch 6 - iter 16/28 - loss 1.70095517 - samples/sec: 24.96\n",
            "2020-02-12 17:23:52,282 epoch 6 - iter 18/28 - loss 1.75032952 - samples/sec: 17.03\n",
            "2020-02-12 17:23:56,803 epoch 6 - iter 20/28 - loss 1.75036476 - samples/sec: 28.00\n",
            "2020-02-12 17:24:01,964 epoch 6 - iter 22/28 - loss 1.77491918 - samples/sec: 26.18\n",
            "2020-02-12 17:24:06,014 epoch 6 - iter 24/28 - loss 1.83784554 - samples/sec: 35.82\n",
            "2020-02-12 17:24:11,188 epoch 6 - iter 26/28 - loss 1.84155390 - samples/sec: 21.66\n",
            "2020-02-12 17:24:14,729 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 17:24:14,731 EPOCH 6 done: loss 1.8553 - lr 0.1000\n",
            "2020-02-12 17:24:21,548 DEV : loss 1.3779791593551636 - score 0.4444\n",
            "2020-02-12 17:24:21,582 BAD EPOCHS (no improvement): 3\n",
            "2020-02-12 17:25:36,986 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 17:25:38,539 epoch 7 - iter 0/28 - loss 2.84281683 - samples/sec: 41.31\n",
            "2020-02-12 17:25:48,265 epoch 7 - iter 2/28 - loss 1.63241728 - samples/sec: 24.56\n",
            "2020-02-12 17:25:52,382 epoch 7 - iter 4/28 - loss 1.88577533 - samples/sec: 25.26\n",
            "2020-02-12 17:25:57,063 epoch 7 - iter 6/28 - loss 2.11205983 - samples/sec: 25.43\n",
            "2020-02-12 17:26:01,161 epoch 7 - iter 8/28 - loss 2.16809540 - samples/sec: 27.80\n",
            "2020-02-12 17:26:07,078 epoch 7 - iter 10/28 - loss 1.99306430 - samples/sec: 15.91\n",
            "2020-02-12 17:26:11,824 epoch 7 - iter 12/28 - loss 1.87756687 - samples/sec: 25.96\n",
            "2020-02-12 17:26:16,075 epoch 7 - iter 14/28 - loss 1.86669364 - samples/sec: 27.68\n",
            "2020-02-12 17:26:20,427 epoch 7 - iter 16/28 - loss 1.81220048 - samples/sec: 28.22\n",
            "2020-02-12 17:26:25,067 epoch 7 - iter 18/28 - loss 1.77982844 - samples/sec: 23.59\n",
            "2020-02-12 17:26:30,910 epoch 7 - iter 20/28 - loss 1.72022500 - samples/sec: 23.24\n",
            "2020-02-12 17:26:37,069 epoch 7 - iter 22/28 - loss 1.69975338 - samples/sec: 15.62\n",
            "2020-02-12 17:26:41,192 epoch 7 - iter 24/28 - loss 1.72978286 - samples/sec: 26.32\n",
            "2020-02-12 17:26:45,923 epoch 7 - iter 26/28 - loss 1.71348988 - samples/sec: 24.95\n",
            "2020-02-12 17:26:49,489 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 17:26:49,491 EPOCH 7 done: loss 1.7397 - lr 0.1000\n",
            "2020-02-12 17:26:55,760 DEV : loss 0.9451720714569092 - score 0.6809\n",
            "Epoch     7: reducing learning rate of group 0 to 5.0000e-02.\n",
            "2020-02-12 17:26:55,853 BAD EPOCHS (no improvement): 4\n",
            "2020-02-12 17:29:53,818 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 17:29:54,963 epoch 8 - iter 0/28 - loss 1.03849459 - samples/sec: 56.85\n",
            "2020-02-12 17:30:01,645 epoch 8 - iter 2/28 - loss 1.01379220 - samples/sec: 25.93\n",
            "2020-02-12 17:30:07,594 epoch 8 - iter 4/28 - loss 1.07365561 - samples/sec: 24.39\n",
            "2020-02-12 17:30:15,849 epoch 8 - iter 6/28 - loss 1.11981433 - samples/sec: 19.54\n",
            "2020-02-12 17:30:23,094 epoch 8 - iter 8/28 - loss 1.18723657 - samples/sec: 23.59\n",
            "2020-02-12 17:30:31,049 epoch 8 - iter 10/28 - loss 1.26423805 - samples/sec: 28.10\n",
            "2020-02-12 17:30:39,280 epoch 8 - iter 12/28 - loss 1.36684788 - samples/sec: 22.78\n",
            "2020-02-12 17:30:46,633 epoch 8 - iter 14/28 - loss 1.46674328 - samples/sec: 21.61\n",
            "2020-02-12 17:30:54,803 epoch 8 - iter 16/28 - loss 1.46966958 - samples/sec: 23.44\n",
            "2020-02-12 17:31:05,431 epoch 8 - iter 18/28 - loss 1.56766607 - samples/sec: 28.32\n",
            "2020-02-12 17:31:12,998 epoch 8 - iter 20/28 - loss 1.55733332 - samples/sec: 16.77\n",
            "2020-02-12 17:31:21,279 epoch 8 - iter 22/28 - loss 1.67450441 - samples/sec: 22.09\n",
            "2020-02-12 17:31:30,651 epoch 8 - iter 24/28 - loss 1.61372357 - samples/sec: 16.07\n",
            "2020-02-12 17:31:37,905 epoch 8 - iter 26/28 - loss 1.65428019 - samples/sec: 31.41\n",
            "2020-02-12 17:31:42,923 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 17:31:42,924 EPOCH 8 done: loss 1.6575 - lr 0.0500\n",
            "2020-02-12 17:31:49,624 DEV : loss 0.861011266708374 - score 0.6667\n",
            "2020-02-12 17:31:49,657 BAD EPOCHS (no improvement): 1\n",
            "2020-02-12 17:33:15,038 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 17:33:16,599 epoch 9 - iter 0/28 - loss 1.10693169 - samples/sec: 41.48\n",
            "2020-02-12 17:33:19,291 epoch 9 - iter 2/28 - loss 1.66422558 - samples/sec: 27.44\n",
            "2020-02-12 17:33:23,540 epoch 9 - iter 4/28 - loss 1.70467339 - samples/sec: 16.01\n",
            "2020-02-12 17:33:27,406 epoch 9 - iter 6/28 - loss 1.56724603 - samples/sec: 21.57\n",
            "2020-02-12 17:33:33,491 epoch 9 - iter 8/28 - loss 1.64437840 - samples/sec: 18.03\n",
            "2020-02-12 17:33:38,359 epoch 9 - iter 10/28 - loss 1.63692878 - samples/sec: 24.29\n",
            "2020-02-12 17:33:43,719 epoch 9 - iter 12/28 - loss 1.52749711 - samples/sec: 22.26\n",
            "2020-02-12 17:33:49,799 epoch 9 - iter 14/28 - loss 1.48266468 - samples/sec: 15.33\n",
            "2020-02-12 17:33:54,268 epoch 9 - iter 16/28 - loss 1.53648822 - samples/sec: 27.33\n",
            "2020-02-12 17:33:58,751 epoch 9 - iter 18/28 - loss 1.56538633 - samples/sec: 25.39\n",
            "2020-02-12 17:34:03,478 epoch 9 - iter 20/28 - loss 1.54160542 - samples/sec: 25.07\n",
            "2020-02-12 17:34:08,765 epoch 9 - iter 22/28 - loss 1.59620462 - samples/sec: 22.54\n",
            "2020-02-12 17:34:13,274 epoch 9 - iter 24/28 - loss 1.58145265 - samples/sec: 25.11\n",
            "2020-02-12 17:34:17,367 epoch 9 - iter 26/28 - loss 1.57909719 - samples/sec: 31.29\n",
            "2020-02-12 17:34:21,144 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 17:34:21,149 EPOCH 9 done: loss 1.5599 - lr 0.0500\n",
            "2020-02-12 17:34:27,787 DEV : loss 0.8989800810813904 - score 0.6809\n",
            "2020-02-12 17:34:27,818 BAD EPOCHS (no improvement): 2\n",
            "2020-02-12 17:37:28,946 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 17:37:30,370 epoch 10 - iter 0/28 - loss 2.37887859 - samples/sec: 45.47\n",
            "2020-02-12 17:37:36,299 epoch 10 - iter 2/28 - loss 1.96929010 - samples/sec: 19.83\n",
            "2020-02-12 17:37:41,037 epoch 10 - iter 4/28 - loss 1.91140432 - samples/sec: 23.87\n",
            "2020-02-12 17:37:49,960 epoch 10 - iter 6/28 - loss 1.64705740 - samples/sec: 16.41\n",
            "2020-02-12 17:37:56,736 epoch 10 - iter 8/28 - loss 1.64141745 - samples/sec: 24.83\n",
            "2020-02-12 17:38:05,434 epoch 10 - iter 10/28 - loss 1.58847809 - samples/sec: 22.21\n",
            "2020-02-12 17:38:12,712 epoch 10 - iter 12/28 - loss 1.49677577 - samples/sec: 28.33\n",
            "2020-02-12 17:38:19,391 epoch 10 - iter 14/28 - loss 1.51263666 - samples/sec: 23.43\n",
            "2020-02-12 17:38:28,512 epoch 10 - iter 16/28 - loss 1.41456002 - samples/sec: 20.23\n",
            "2020-02-12 17:38:37,686 epoch 10 - iter 18/28 - loss 1.42436393 - samples/sec: 17.61\n",
            "2020-02-12 17:38:44,573 epoch 10 - iter 20/28 - loss 1.46811123 - samples/sec: 30.26\n",
            "2020-02-12 17:38:51,340 epoch 10 - iter 22/28 - loss 1.42493336 - samples/sec: 22.19\n",
            "2020-02-12 17:38:58,310 epoch 10 - iter 24/28 - loss 1.43916965 - samples/sec: 31.17\n",
            "2020-02-12 17:39:06,270 epoch 10 - iter 26/28 - loss 1.45894297 - samples/sec: 31.87\n",
            "2020-02-12 17:39:11,502 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 17:39:11,504 EPOCH 10 done: loss 1.4594 - lr 0.0500\n",
            "2020-02-12 17:39:18,021 DEV : loss 1.0123785734176636 - score 0.6122\n",
            "2020-02-12 17:39:18,050 BAD EPOCHS (no improvement): 3\n",
            "2020-02-12 17:40:37,859 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 17:40:39,434 epoch 11 - iter 0/28 - loss 0.83113146 - samples/sec: 41.04\n",
            "2020-02-12 17:40:51,140 epoch 11 - iter 2/28 - loss 1.45333862 - samples/sec: 22.54\n",
            "2020-02-12 17:40:55,418 epoch 11 - iter 4/28 - loss 1.63624582 - samples/sec: 27.54\n",
            "2020-02-12 17:41:00,017 epoch 11 - iter 6/28 - loss 1.52301182 - samples/sec: 28.84\n",
            "2020-02-12 17:41:05,505 epoch 11 - iter 8/28 - loss 1.41525777 - samples/sec: 18.43\n",
            "2020-02-12 17:41:09,418 epoch 11 - iter 10/28 - loss 1.38417279 - samples/sec: 41.99\n",
            "2020-02-12 17:41:14,783 epoch 11 - iter 12/28 - loss 1.38282526 - samples/sec: 18.99\n",
            "2020-02-12 17:41:19,711 epoch 11 - iter 14/28 - loss 1.42568204 - samples/sec: 24.45\n",
            "2020-02-12 17:41:23,854 epoch 11 - iter 16/28 - loss 1.43896187 - samples/sec: 27.22\n",
            "2020-02-12 17:41:29,229 epoch 11 - iter 18/28 - loss 1.54610222 - samples/sec: 21.10\n",
            "2020-02-12 17:41:35,584 epoch 11 - iter 20/28 - loss 1.52532364 - samples/sec: 15.68\n",
            "2020-02-12 17:41:39,147 epoch 11 - iter 22/28 - loss 1.52589761 - samples/sec: 31.12\n",
            "2020-02-12 17:41:43,480 epoch 11 - iter 24/28 - loss 1.53338499 - samples/sec: 24.72\n",
            "2020-02-12 17:41:47,531 epoch 11 - iter 26/28 - loss 1.49624613 - samples/sec: 26.35\n",
            "2020-02-12 17:41:52,057 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 17:41:52,059 EPOCH 11 done: loss 1.4836 - lr 0.0500\n",
            "2020-02-12 17:41:58,626 DEV : loss 0.7996708154678345 - score 0.6809\n",
            "Epoch    11: reducing learning rate of group 0 to 2.5000e-02.\n",
            "2020-02-12 17:41:58,698 BAD EPOCHS (no improvement): 4\n",
            "2020-02-12 17:44:58,252 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 17:45:00,891 epoch 12 - iter 0/28 - loss 0.37580872 - samples/sec: 24.31\n",
            "2020-02-12 17:45:06,323 epoch 12 - iter 2/28 - loss 1.10490306 - samples/sec: 22.70\n",
            "2020-02-12 17:45:14,684 epoch 12 - iter 4/28 - loss 1.28230228 - samples/sec: 29.27\n",
            "2020-02-12 17:45:22,781 epoch 12 - iter 6/28 - loss 1.39185422 - samples/sec: 24.76\n",
            "2020-02-12 17:45:29,209 epoch 12 - iter 8/28 - loss 1.29254675 - samples/sec: 22.80\n",
            "2020-02-12 17:45:36,161 epoch 12 - iter 10/28 - loss 1.37036458 - samples/sec: 27.13\n",
            "2020-02-12 17:45:42,685 epoch 12 - iter 12/28 - loss 1.40236007 - samples/sec: 24.79\n",
            "2020-02-12 17:45:49,409 epoch 12 - iter 14/28 - loss 1.39451548 - samples/sec: 27.62\n",
            "2020-02-12 17:45:56,350 epoch 12 - iter 16/28 - loss 1.42760824 - samples/sec: 26.14\n",
            "2020-02-12 17:46:03,690 epoch 12 - iter 18/28 - loss 1.43219029 - samples/sec: 22.99\n",
            "2020-02-12 17:46:11,312 epoch 12 - iter 20/28 - loss 1.38319931 - samples/sec: 22.03\n",
            "2020-02-12 17:46:18,238 epoch 12 - iter 22/28 - loss 1.40335328 - samples/sec: 28.67\n",
            "2020-02-12 17:46:27,408 epoch 12 - iter 24/28 - loss 1.38137556 - samples/sec: 14.84\n",
            "2020-02-12 17:46:35,253 epoch 12 - iter 26/28 - loss 1.39257818 - samples/sec: 21.64\n",
            "2020-02-12 17:46:42,033 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 17:46:42,035 EPOCH 12 done: loss 1.3921 - lr 0.0250\n",
            "2020-02-12 17:46:48,666 DEV : loss 0.8127251863479614 - score 0.6667\n",
            "2020-02-12 17:46:48,709 BAD EPOCHS (no improvement): 1\n",
            "2020-02-12 17:48:09,810 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 17:48:10,927 epoch 13 - iter 0/28 - loss 1.00435877 - samples/sec: 57.49\n",
            "2020-02-12 17:48:19,173 epoch 13 - iter 2/28 - loss 1.08116992 - samples/sec: 12.10\n",
            "2020-02-12 17:48:23,417 epoch 13 - iter 4/28 - loss 1.42664633 - samples/sec: 31.15\n",
            "2020-02-12 17:48:27,820 epoch 13 - iter 6/28 - loss 1.34660966 - samples/sec: 28.38\n",
            "2020-02-12 17:48:33,517 epoch 13 - iter 8/28 - loss 1.24251355 - samples/sec: 20.33\n",
            "2020-02-12 17:48:37,897 epoch 13 - iter 10/28 - loss 1.25901690 - samples/sec: 26.35\n",
            "2020-02-12 17:48:42,600 epoch 13 - iter 12/28 - loss 1.26593968 - samples/sec: 23.38\n",
            "2020-02-12 17:48:47,666 epoch 13 - iter 14/28 - loss 1.27937396 - samples/sec: 23.74\n",
            "2020-02-12 17:48:52,825 epoch 13 - iter 16/28 - loss 1.36714582 - samples/sec: 24.00\n",
            "2020-02-12 17:48:59,004 epoch 13 - iter 18/28 - loss 1.38096393 - samples/sec: 20.39\n",
            "2020-02-12 17:49:03,181 epoch 13 - iter 20/28 - loss 1.35608042 - samples/sec: 30.23\n",
            "2020-02-12 17:49:08,597 epoch 13 - iter 22/28 - loss 1.39190730 - samples/sec: 22.51\n",
            "2020-02-12 17:49:13,212 epoch 13 - iter 24/28 - loss 1.40258045 - samples/sec: 25.11\n",
            "2020-02-12 17:49:18,047 epoch 13 - iter 26/28 - loss 1.39999275 - samples/sec: 23.03\n",
            "2020-02-12 17:49:21,225 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 17:49:21,226 EPOCH 13 done: loss 1.3943 - lr 0.0250\n",
            "2020-02-12 17:49:27,919 DEV : loss 0.8950028419494629 - score 0.6531\n",
            "2020-02-12 17:49:27,949 BAD EPOCHS (no improvement): 2\n",
            "2020-02-12 17:50:42,307 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 17:50:51,514 epoch 14 - iter 0/28 - loss 0.70068455 - samples/sec: 46.48\n",
            "2020-02-12 17:50:57,161 epoch 14 - iter 2/28 - loss 0.92607729 - samples/sec: 20.06\n",
            "2020-02-12 17:51:00,847 epoch 14 - iter 4/28 - loss 1.26408238 - samples/sec: 29.54\n",
            "2020-02-12 17:51:06,175 epoch 14 - iter 6/28 - loss 1.30273291 - samples/sec: 21.24\n",
            "2020-02-12 17:51:11,500 epoch 14 - iter 8/28 - loss 1.30051282 - samples/sec: 19.89\n",
            "2020-02-12 17:51:17,999 epoch 14 - iter 10/28 - loss 1.28702461 - samples/sec: 15.86\n",
            "2020-02-12 17:51:22,682 epoch 14 - iter 12/28 - loss 1.32508614 - samples/sec: 23.70\n",
            "2020-02-12 17:51:26,953 epoch 14 - iter 14/28 - loss 1.27309279 - samples/sec: 29.21\n",
            "2020-02-12 17:51:30,423 epoch 14 - iter 16/28 - loss 1.38819376 - samples/sec: 38.85\n",
            "2020-02-12 17:51:35,114 epoch 14 - iter 18/28 - loss 1.38157750 - samples/sec: 26.37\n",
            "2020-02-12 17:51:40,965 epoch 14 - iter 20/28 - loss 1.36831067 - samples/sec: 24.70\n",
            "2020-02-12 17:51:45,455 epoch 14 - iter 22/28 - loss 1.35295477 - samples/sec: 24.86\n",
            "2020-02-12 17:51:51,012 epoch 14 - iter 24/28 - loss 1.32586406 - samples/sec: 15.88\n",
            "2020-02-12 17:51:55,944 epoch 14 - iter 26/28 - loss 1.29164140 - samples/sec: 22.31\n",
            "2020-02-12 17:51:59,507 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 17:51:59,508 EPOCH 14 done: loss 1.3341 - lr 0.0250\n",
            "2020-02-12 17:52:05,628 DEV : loss 0.8523196578025818 - score 0.6531\n",
            "2020-02-12 17:52:05,658 BAD EPOCHS (no improvement): 3\n",
            "2020-02-12 17:53:20,561 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 17:53:22,132 epoch 15 - iter 0/28 - loss 1.70930290 - samples/sec: 40.81\n",
            "2020-02-12 17:53:30,316 epoch 15 - iter 2/28 - loss 1.69713116 - samples/sec: 27.74\n",
            "2020-02-12 17:53:34,664 epoch 15 - iter 4/28 - loss 1.58683519 - samples/sec: 15.63\n",
            "2020-02-12 17:53:39,581 epoch 15 - iter 6/28 - loss 1.44620861 - samples/sec: 23.14\n",
            "2020-02-12 17:53:44,597 epoch 15 - iter 8/28 - loss 1.57741605 - samples/sec: 27.95\n",
            "2020-02-12 17:53:49,182 epoch 15 - iter 10/28 - loss 1.47048148 - samples/sec: 24.95\n",
            "2020-02-12 17:53:54,425 epoch 15 - iter 12/28 - loss 1.39563073 - samples/sec: 20.49\n",
            "2020-02-12 17:53:59,456 epoch 15 - iter 14/28 - loss 1.37118196 - samples/sec: 23.37\n",
            "2020-02-12 17:54:04,595 epoch 15 - iter 16/28 - loss 1.33632823 - samples/sec: 22.10\n",
            "2020-02-12 17:54:09,121 epoch 15 - iter 18/28 - loss 1.28999670 - samples/sec: 25.49\n",
            "2020-02-12 17:54:13,552 epoch 15 - iter 20/28 - loss 1.26491912 - samples/sec: 26.20\n",
            "2020-02-12 17:54:18,420 epoch 15 - iter 22/28 - loss 1.23449925 - samples/sec: 22.71\n",
            "2020-02-12 17:54:22,481 epoch 15 - iter 24/28 - loss 1.28967484 - samples/sec: 24.86\n",
            "2020-02-12 17:54:28,486 epoch 15 - iter 26/28 - loss 1.27602574 - samples/sec: 16.51\n",
            "2020-02-12 17:54:31,581 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 17:54:31,584 EPOCH 15 done: loss 1.3045 - lr 0.0250\n",
            "2020-02-12 17:54:38,190 DEV : loss 0.886770486831665 - score 0.64\n",
            "Epoch    15: reducing learning rate of group 0 to 1.2500e-02.\n",
            "2020-02-12 17:54:38,305 BAD EPOCHS (no improvement): 4\n",
            "2020-02-12 17:55:56,697 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 17:55:58,246 epoch 16 - iter 0/28 - loss 1.83378696 - samples/sec: 41.69\n",
            "2020-02-12 17:56:00,809 epoch 16 - iter 2/28 - loss 1.45114406 - samples/sec: 29.92\n",
            "2020-02-12 17:56:03,296 epoch 16 - iter 4/28 - loss 1.36311207 - samples/sec: 29.06\n",
            "2020-02-12 17:56:05,781 epoch 16 - iter 6/28 - loss 1.54066317 - samples/sec: 28.72\n",
            "2020-02-12 17:56:11,111 epoch 16 - iter 8/28 - loss 1.43053818 - samples/sec: 24.15\n",
            "2020-02-12 17:56:18,044 epoch 16 - iter 10/28 - loss 1.39964013 - samples/sec: 16.09\n",
            "2020-02-12 17:56:22,905 epoch 16 - iter 12/28 - loss 1.36244491 - samples/sec: 23.42\n",
            "2020-02-12 17:56:27,573 epoch 16 - iter 14/28 - loss 1.35077437 - samples/sec: 25.53\n",
            "2020-02-12 17:56:32,205 epoch 16 - iter 16/28 - loss 1.39519861 - samples/sec: 25.30\n",
            "2020-02-12 17:56:37,531 epoch 16 - iter 18/28 - loss 1.31461850 - samples/sec: 24.02\n",
            "2020-02-12 17:56:42,490 epoch 16 - iter 20/28 - loss 1.31556333 - samples/sec: 22.63\n",
            "2020-02-12 17:56:48,041 epoch 16 - iter 22/28 - loss 1.31302455 - samples/sec: 22.34\n",
            "2020-02-12 17:56:53,493 epoch 16 - iter 24/28 - loss 1.30698281 - samples/sec: 17.64\n",
            "2020-02-12 17:56:58,635 epoch 16 - iter 26/28 - loss 1.29184413 - samples/sec: 24.94\n",
            "2020-02-12 17:57:02,398 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 17:57:02,399 EPOCH 16 done: loss 1.2546 - lr 0.0125\n",
            "2020-02-12 17:57:09,001 DEV : loss 0.9241332411766052 - score 0.64\n",
            "2020-02-12 17:57:09,033 BAD EPOCHS (no improvement): 1\n",
            "2020-02-12 17:58:28,180 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 17:58:29,503 epoch 17 - iter 0/28 - loss 2.05287266 - samples/sec: 48.50\n",
            "2020-02-12 17:58:32,399 epoch 17 - iter 2/28 - loss 1.43678045 - samples/sec: 25.66\n",
            "2020-02-12 17:58:35,661 epoch 17 - iter 4/28 - loss 1.43771820 - samples/sec: 26.36\n",
            "2020-02-12 17:58:39,431 epoch 17 - iter 6/28 - loss 1.23685156 - samples/sec: 18.61\n",
            "2020-02-12 17:58:44,257 epoch 17 - iter 8/28 - loss 1.30586359 - samples/sec: 24.21\n",
            "2020-02-12 17:58:50,575 epoch 17 - iter 10/28 - loss 1.28147238 - samples/sec: 23.98\n",
            "2020-02-12 17:58:55,899 epoch 17 - iter 12/28 - loss 1.28626134 - samples/sec: 20.77\n",
            "2020-02-12 17:59:00,596 epoch 17 - iter 14/28 - loss 1.22821496 - samples/sec: 26.80\n",
            "2020-02-12 17:59:05,460 epoch 17 - iter 16/28 - loss 1.34134879 - samples/sec: 22.41\n",
            "2020-02-12 17:59:10,627 epoch 17 - iter 18/28 - loss 1.38207353 - samples/sec: 24.53\n",
            "2020-02-12 17:59:14,993 epoch 17 - iter 20/28 - loss 1.35433165 - samples/sec: 28.03\n",
            "2020-02-12 17:59:20,974 epoch 17 - iter 22/28 - loss 1.35910706 - samples/sec: 15.40\n",
            "2020-02-12 17:59:26,596 epoch 17 - iter 24/28 - loss 1.32686522 - samples/sec: 18.36\n",
            "2020-02-12 17:59:31,623 epoch 17 - iter 26/28 - loss 1.30097847 - samples/sec: 24.48\n",
            "2020-02-12 17:59:35,382 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 17:59:35,383 EPOCH 17 done: loss 1.2917 - lr 0.0125\n",
            "2020-02-12 17:59:41,876 DEV : loss 0.9142895936965942 - score 0.64\n",
            "2020-02-12 17:59:41,907 BAD EPOCHS (no improvement): 2\n",
            "2020-02-12 18:00:55,384 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 18:00:56,523 epoch 18 - iter 0/28 - loss 1.35434818 - samples/sec: 56.32\n",
            "2020-02-12 18:01:09,108 epoch 18 - iter 2/28 - loss 1.18734233 - samples/sec: 14.50\n",
            "2020-02-12 18:01:16,186 epoch 18 - iter 4/28 - loss 1.37727985 - samples/sec: 17.74\n",
            "2020-02-12 18:01:20,304 epoch 18 - iter 6/28 - loss 1.28347846 - samples/sec: 26.44\n",
            "2020-02-12 18:01:24,544 epoch 18 - iter 8/28 - loss 1.14347691 - samples/sec: 29.52\n",
            "2020-02-12 18:01:28,969 epoch 18 - iter 10/28 - loss 1.36702407 - samples/sec: 37.86\n",
            "2020-02-12 18:01:33,278 epoch 18 - iter 12/28 - loss 1.35880324 - samples/sec: 26.62\n",
            "2020-02-12 18:01:37,516 epoch 18 - iter 14/28 - loss 1.34513009 - samples/sec: 27.34\n",
            "2020-02-12 18:01:41,930 epoch 18 - iter 16/28 - loss 1.35794698 - samples/sec: 31.23\n",
            "2020-02-12 18:01:46,562 epoch 18 - iter 18/28 - loss 1.39012189 - samples/sec: 22.98\n",
            "2020-02-12 18:01:51,087 epoch 18 - iter 20/28 - loss 1.34851002 - samples/sec: 24.53\n",
            "2020-02-12 18:01:57,104 epoch 18 - iter 22/28 - loss 1.32825006 - samples/sec: 24.36\n",
            "2020-02-12 18:02:01,513 epoch 18 - iter 24/28 - loss 1.29180428 - samples/sec: 21.11\n",
            "2020-02-12 18:02:05,601 epoch 18 - iter 26/28 - loss 1.24761627 - samples/sec: 30.21\n",
            "2020-02-12 18:02:07,737 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 18:02:07,738 EPOCH 18 done: loss 1.2640 - lr 0.0125\n",
            "2020-02-12 18:02:14,154 DEV : loss 0.8315276503562927 - score 0.64\n",
            "2020-02-12 18:02:14,186 BAD EPOCHS (no improvement): 3\n",
            "2020-02-12 18:03:30,266 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 18:03:31,563 epoch 19 - iter 0/28 - loss 1.73059130 - samples/sec: 50.22\n",
            "2020-02-12 18:03:39,838 epoch 19 - iter 2/28 - loss 1.40953191 - samples/sec: 23.60\n",
            "2020-02-12 18:03:45,007 epoch 19 - iter 4/28 - loss 1.42617760 - samples/sec: 21.57\n",
            "2020-02-12 18:03:48,950 epoch 19 - iter 6/28 - loss 1.31001670 - samples/sec: 31.51\n",
            "2020-02-12 18:03:53,755 epoch 19 - iter 8/28 - loss 1.46713463 - samples/sec: 21.14\n",
            "2020-02-12 18:03:58,905 epoch 19 - iter 10/28 - loss 1.41656442 - samples/sec: 23.07\n",
            "2020-02-12 18:04:03,392 epoch 19 - iter 12/28 - loss 1.40848692 - samples/sec: 26.97\n",
            "2020-02-12 18:04:08,058 epoch 19 - iter 14/28 - loss 1.41180681 - samples/sec: 26.23\n",
            "2020-02-12 18:04:13,619 epoch 19 - iter 16/28 - loss 1.37570493 - samples/sec: 16.90\n",
            "2020-02-12 18:04:19,922 epoch 19 - iter 18/28 - loss 1.33288617 - samples/sec: 24.61\n",
            "2020-02-12 18:04:24,511 epoch 19 - iter 20/28 - loss 1.29615248 - samples/sec: 24.83\n",
            "2020-02-12 18:04:30,401 epoch 19 - iter 22/28 - loss 1.27676970 - samples/sec: 21.61\n",
            "2020-02-12 18:04:37,834 epoch 19 - iter 24/28 - loss 1.26603811 - samples/sec: 15.93\n",
            "2020-02-12 18:04:42,888 epoch 19 - iter 26/28 - loss 1.27247632 - samples/sec: 26.00\n",
            "2020-02-12 18:04:46,055 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 18:04:46,057 EPOCH 19 done: loss 1.2749 - lr 0.0125\n",
            "2020-02-12 18:04:52,325 DEV : loss 0.9216298460960388 - score 0.64\n",
            "Epoch    19: reducing learning rate of group 0 to 6.2500e-03.\n",
            "2020-02-12 18:04:52,426 BAD EPOCHS (no improvement): 4\n",
            "2020-02-12 18:06:08,042 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 18:06:09,040 epoch 20 - iter 0/28 - loss 0.99837303 - samples/sec: 64.32\n",
            "2020-02-12 18:06:11,495 epoch 20 - iter 2/28 - loss 1.21144279 - samples/sec: 31.67\n",
            "2020-02-12 18:06:18,215 epoch 20 - iter 4/28 - loss 1.23962517 - samples/sec: 17.26\n",
            "2020-02-12 18:06:23,761 epoch 20 - iter 6/28 - loss 1.19423485 - samples/sec: 22.08\n",
            "2020-02-12 18:06:29,654 epoch 20 - iter 8/28 - loss 1.22638135 - samples/sec: 16.79\n",
            "2020-02-12 18:06:35,211 epoch 20 - iter 10/28 - loss 1.26887005 - samples/sec: 25.81\n",
            "2020-02-12 18:06:38,977 epoch 20 - iter 12/28 - loss 1.30783862 - samples/sec: 28.48\n",
            "2020-02-12 18:06:44,754 epoch 20 - iter 14/28 - loss 1.27847789 - samples/sec: 22.77\n",
            "2020-02-12 18:06:49,478 epoch 20 - iter 16/28 - loss 1.25522594 - samples/sec: 25.08\n",
            "2020-02-12 18:06:54,348 epoch 20 - iter 18/28 - loss 1.25362226 - samples/sec: 26.41\n",
            "2020-02-12 18:06:59,542 epoch 20 - iter 20/28 - loss 1.28355769 - samples/sec: 27.84\n",
            "2020-02-12 18:07:05,758 epoch 20 - iter 22/28 - loss 1.24713000 - samples/sec: 19.22\n",
            "2020-02-12 18:07:10,774 epoch 20 - iter 24/28 - loss 1.26491264 - samples/sec: 21.78\n",
            "2020-02-12 18:07:15,462 epoch 20 - iter 26/28 - loss 1.23447213 - samples/sec: 24.31\n",
            "2020-02-12 18:07:20,416 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 18:07:20,418 EPOCH 20 done: loss 1.2146 - lr 0.0063\n",
            "2020-02-12 18:07:27,165 DEV : loss 0.902758002281189 - score 0.64\n",
            "2020-02-12 18:07:27,194 BAD EPOCHS (no improvement): 1\n",
            "2020-02-12 18:08:42,056 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 18:08:48,179 epoch 21 - iter 0/28 - loss 2.06975365 - samples/sec: 50.23\n",
            "2020-02-12 18:08:52,509 epoch 21 - iter 2/28 - loss 1.43812450 - samples/sec: 27.41\n",
            "2020-02-12 18:08:56,704 epoch 21 - iter 4/28 - loss 1.64234867 - samples/sec: 29.86\n",
            "2020-02-12 18:09:03,129 epoch 21 - iter 6/28 - loss 1.51596996 - samples/sec: 14.46\n",
            "2020-02-12 18:09:09,526 epoch 21 - iter 8/28 - loss 1.39637280 - samples/sec: 21.79\n",
            "2020-02-12 18:09:13,300 epoch 21 - iter 10/28 - loss 1.23994836 - samples/sec: 33.59\n",
            "2020-02-12 18:09:17,993 epoch 21 - iter 12/28 - loss 1.29903852 - samples/sec: 27.69\n",
            "2020-02-12 18:09:24,142 epoch 21 - iter 14/28 - loss 1.31168601 - samples/sec: 15.78\n",
            "2020-02-12 18:09:28,668 epoch 21 - iter 16/28 - loss 1.34878476 - samples/sec: 28.26\n",
            "2020-02-12 18:09:33,443 epoch 21 - iter 18/28 - loss 1.32916328 - samples/sec: 24.15\n",
            "2020-02-12 18:09:38,205 epoch 21 - iter 20/28 - loss 1.27889413 - samples/sec: 22.77\n",
            "2020-02-12 18:09:43,863 epoch 21 - iter 22/28 - loss 1.20597468 - samples/sec: 19.02\n",
            "2020-02-12 18:09:48,802 epoch 21 - iter 24/28 - loss 1.24763508 - samples/sec: 23.66\n",
            "2020-02-12 18:09:52,210 epoch 21 - iter 26/28 - loss 1.24413473 - samples/sec: 26.40\n",
            "2020-02-12 18:09:53,922 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 18:09:53,923 EPOCH 21 done: loss 1.2102 - lr 0.0063\n",
            "2020-02-12 18:10:00,817 DEV : loss 0.8597415685653687 - score 0.64\n",
            "2020-02-12 18:10:00,852 BAD EPOCHS (no improvement): 2\n",
            "2020-02-12 18:11:22,109 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 18:11:23,774 epoch 22 - iter 0/28 - loss 1.35674047 - samples/sec: 38.49\n",
            "2020-02-12 18:11:26,450 epoch 22 - iter 2/28 - loss 1.57574717 - samples/sec: 27.67\n",
            "2020-02-12 18:11:28,946 epoch 22 - iter 4/28 - loss 1.37011547 - samples/sec: 29.20\n",
            "2020-02-12 18:11:32,130 epoch 22 - iter 6/28 - loss 1.31421062 - samples/sec: 21.93\n",
            "2020-02-12 18:11:36,358 epoch 22 - iter 8/28 - loss 1.31228320 - samples/sec: 25.67\n",
            "2020-02-12 18:11:41,653 epoch 22 - iter 10/28 - loss 1.26756486 - samples/sec: 20.74\n",
            "2020-02-12 18:11:46,335 epoch 22 - iter 12/28 - loss 1.29138224 - samples/sec: 24.08\n",
            "2020-02-12 18:11:51,129 epoch 22 - iter 14/28 - loss 1.40707064 - samples/sec: 21.70\n",
            "2020-02-12 18:11:57,235 epoch 22 - iter 16/28 - loss 1.40852866 - samples/sec: 14.99\n",
            "2020-02-12 18:12:02,522 epoch 22 - iter 18/28 - loss 1.39783019 - samples/sec: 19.16\n",
            "2020-02-12 18:12:06,642 epoch 22 - iter 20/28 - loss 1.37288414 - samples/sec: 34.38\n",
            "2020-02-12 18:12:11,816 epoch 22 - iter 22/28 - loss 1.31423117 - samples/sec: 20.99\n",
            "2020-02-12 18:12:17,283 epoch 22 - iter 24/28 - loss 1.29477201 - samples/sec: 16.41\n",
            "2020-02-12 18:12:21,558 epoch 22 - iter 26/28 - loss 1.28242058 - samples/sec: 29.34\n",
            "2020-02-12 18:12:25,167 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 18:12:25,169 EPOCH 22 done: loss 1.2835 - lr 0.0063\n",
            "2020-02-12 18:12:31,705 DEV : loss 0.8873783349990845 - score 0.64\n",
            "2020-02-12 18:12:31,735 BAD EPOCHS (no improvement): 3\n",
            "2020-02-12 18:13:46,994 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 18:13:48,052 epoch 23 - iter 0/28 - loss 1.14074039 - samples/sec: 60.63\n",
            "2020-02-12 18:13:57,465 epoch 23 - iter 2/28 - loss 1.19356839 - samples/sec: 18.26\n",
            "2020-02-12 18:14:04,252 epoch 23 - iter 4/28 - loss 1.17301559 - samples/sec: 15.36\n",
            "2020-02-12 18:14:08,945 epoch 23 - iter 6/28 - loss 1.22864778 - samples/sec: 24.04\n",
            "2020-02-12 18:14:14,032 epoch 23 - iter 8/28 - loss 1.10634412 - samples/sec: 20.34\n",
            "2020-02-12 18:14:19,266 epoch 23 - iter 10/28 - loss 1.17580873 - samples/sec: 21.43\n",
            "2020-02-12 18:14:23,312 epoch 23 - iter 12/28 - loss 1.16745021 - samples/sec: 34.87\n",
            "2020-02-12 18:14:28,746 epoch 23 - iter 14/28 - loss 1.13940674 - samples/sec: 24.96\n",
            "2020-02-12 18:14:33,710 epoch 23 - iter 16/28 - loss 1.18675305 - samples/sec: 23.56\n",
            "2020-02-12 18:14:39,755 epoch 23 - iter 18/28 - loss 1.18311302 - samples/sec: 16.57\n",
            "2020-02-12 18:14:44,182 epoch 23 - iter 20/28 - loss 1.24070104 - samples/sec: 27.92\n",
            "2020-02-12 18:14:48,541 epoch 23 - iter 22/28 - loss 1.37503010 - samples/sec: 24.91\n",
            "2020-02-12 18:14:53,545 epoch 23 - iter 24/28 - loss 1.35522905 - samples/sec: 21.65\n",
            "2020-02-12 18:14:58,672 epoch 23 - iter 26/28 - loss 1.30452716 - samples/sec: 25.78\n",
            "2020-02-12 18:15:01,808 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 18:15:01,810 EPOCH 23 done: loss 1.3111 - lr 0.0063\n",
            "2020-02-12 18:15:09,233 DEV : loss 0.8648545742034912 - score 0.64\n",
            "Epoch    23: reducing learning rate of group 0 to 3.1250e-03.\n",
            "2020-02-12 18:15:09,282 BAD EPOCHS (no improvement): 4\n",
            "2020-02-12 18:16:31,228 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 18:16:32,171 epoch 24 - iter 0/28 - loss 0.78837490 - samples/sec: 68.79\n",
            "2020-02-12 18:16:36,460 epoch 24 - iter 2/28 - loss 0.93733184 - samples/sec: 25.89\n",
            "2020-02-12 18:16:40,898 epoch 24 - iter 4/28 - loss 1.16551905 - samples/sec: 22.65\n",
            "2020-02-12 18:16:45,619 epoch 24 - iter 6/28 - loss 1.16954238 - samples/sec: 24.26\n",
            "2020-02-12 18:16:50,764 epoch 24 - iter 8/28 - loss 1.33001391 - samples/sec: 22.28\n",
            "2020-02-12 18:16:54,574 epoch 24 - iter 10/28 - loss 1.29992585 - samples/sec: 30.47\n",
            "2020-02-12 18:16:58,753 epoch 24 - iter 12/28 - loss 1.25870375 - samples/sec: 26.20\n",
            "2020-02-12 18:17:03,205 epoch 24 - iter 14/28 - loss 1.22780422 - samples/sec: 27.63\n",
            "2020-02-12 18:17:10,279 epoch 24 - iter 16/28 - loss 1.20751886 - samples/sec: 14.24\n",
            "2020-02-12 18:17:15,145 epoch 24 - iter 18/28 - loss 1.27331746 - samples/sec: 14.23\n",
            "2020-02-12 18:17:17,887 epoch 24 - iter 20/28 - loss 1.25948166 - samples/sec: 25.93\n",
            "2020-02-12 18:17:20,782 epoch 24 - iter 22/28 - loss 1.21357802 - samples/sec: 24.82\n",
            "2020-02-12 18:17:23,594 epoch 24 - iter 24/28 - loss 1.23129578 - samples/sec: 25.24\n",
            "2020-02-12 18:17:26,674 epoch 24 - iter 26/28 - loss 1.26434985 - samples/sec: 23.10\n",
            "2020-02-12 18:17:27,997 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 18:17:27,999 EPOCH 24 done: loss 1.2346 - lr 0.0031\n",
            "2020-02-12 18:17:34,339 DEV : loss 0.8801844120025635 - score 0.64\n",
            "2020-02-12 18:17:34,371 BAD EPOCHS (no improvement): 1\n",
            "2020-02-12 18:18:52,747 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 18:18:55,299 epoch 25 - iter 0/28 - loss 1.85072279 - samples/sec: 25.10\n",
            "2020-02-12 18:18:59,614 epoch 25 - iter 2/28 - loss 1.36063067 - samples/sec: 27.44\n",
            "2020-02-12 18:19:02,317 epoch 25 - iter 4/28 - loss 1.50740337 - samples/sec: 26.19\n",
            "2020-02-12 18:19:06,770 epoch 25 - iter 6/28 - loss 1.43341766 - samples/sec: 26.00\n",
            "2020-02-12 18:19:12,304 epoch 25 - iter 8/28 - loss 1.31481801 - samples/sec: 23.81\n",
            "2020-02-12 18:19:17,444 epoch 25 - iter 10/28 - loss 1.26624229 - samples/sec: 21.90\n",
            "2020-02-12 18:19:22,025 epoch 25 - iter 12/28 - loss 1.24538106 - samples/sec: 21.96\n",
            "2020-02-12 18:19:26,542 epoch 25 - iter 14/28 - loss 1.21083422 - samples/sec: 25.20\n",
            "2020-02-12 18:19:32,052 epoch 25 - iter 16/28 - loss 1.18652571 - samples/sec: 20.34\n",
            "2020-02-12 18:19:37,126 epoch 25 - iter 18/28 - loss 1.26336926 - samples/sec: 25.46\n",
            "2020-02-12 18:19:42,859 epoch 25 - iter 20/28 - loss 1.28494270 - samples/sec: 17.07\n",
            "2020-02-12 18:19:46,028 epoch 25 - iter 22/28 - loss 1.26889094 - samples/sec: 22.40\n",
            "2020-02-12 18:19:49,214 epoch 25 - iter 24/28 - loss 1.25359596 - samples/sec: 22.16\n",
            "2020-02-12 18:19:51,866 epoch 25 - iter 26/28 - loss 1.25931554 - samples/sec: 27.63\n",
            "2020-02-12 18:19:52,882 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 18:19:52,885 EPOCH 25 done: loss 1.2234 - lr 0.0031\n",
            "2020-02-12 18:19:59,038 DEV : loss 0.8673393130302429 - score 0.64\n",
            "2020-02-12 18:19:59,073 BAD EPOCHS (no improvement): 2\n",
            "2020-02-12 18:21:20,612 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 18:21:21,889 epoch 26 - iter 0/28 - loss 1.38782883 - samples/sec: 50.20\n",
            "2020-02-12 18:21:24,729 epoch 26 - iter 2/28 - loss 1.06533988 - samples/sec: 26.22\n",
            "2020-02-12 18:21:27,533 epoch 26 - iter 4/28 - loss 1.13399038 - samples/sec: 25.88\n",
            "2020-02-12 18:21:30,641 epoch 26 - iter 6/28 - loss 1.14286259 - samples/sec: 22.81\n",
            "2020-02-12 18:21:35,151 epoch 26 - iter 8/28 - loss 1.07920678 - samples/sec: 25.54\n",
            "2020-02-12 18:21:39,825 epoch 26 - iter 10/28 - loss 1.13417409 - samples/sec: 28.24\n",
            "2020-02-12 18:21:43,782 epoch 26 - iter 12/28 - loss 1.25600730 - samples/sec: 27.44\n",
            "2020-02-12 18:21:49,468 epoch 26 - iter 14/28 - loss 1.17249428 - samples/sec: 19.89\n",
            "2020-02-12 18:21:55,064 epoch 26 - iter 16/28 - loss 1.21098081 - samples/sec: 22.76\n",
            "2020-02-12 18:22:00,324 epoch 26 - iter 18/28 - loss 1.20739653 - samples/sec: 21.58\n",
            "2020-02-12 18:22:04,568 epoch 26 - iter 20/28 - loss 1.23077545 - samples/sec: 27.65\n",
            "2020-02-12 18:22:10,276 epoch 26 - iter 22/28 - loss 1.24226257 - samples/sec: 21.15\n",
            "2020-02-12 18:22:16,256 epoch 26 - iter 24/28 - loss 1.23237013 - samples/sec: 16.02\n",
            "2020-02-12 18:22:22,242 epoch 26 - iter 26/28 - loss 1.20057373 - samples/sec: 15.66\n",
            "2020-02-12 18:22:25,678 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 18:22:25,680 EPOCH 26 done: loss 1.1962 - lr 0.0031\n",
            "2020-02-12 18:22:32,249 DEV : loss 0.881919801235199 - score 0.64\n",
            "2020-02-12 18:22:32,283 BAD EPOCHS (no improvement): 3\n",
            "2020-02-12 18:23:49,920 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 18:23:52,437 epoch 27 - iter 0/28 - loss 1.63004971 - samples/sec: 25.45\n",
            "2020-02-12 18:23:55,467 epoch 27 - iter 2/28 - loss 1.30387052 - samples/sec: 24.28\n",
            "2020-02-12 18:23:58,326 epoch 27 - iter 4/28 - loss 1.19720564 - samples/sec: 24.93\n",
            "2020-02-12 18:24:01,090 epoch 27 - iter 6/28 - loss 1.21185453 - samples/sec: 25.90\n",
            "2020-02-12 18:24:06,316 epoch 27 - iter 8/28 - loss 1.38087024 - samples/sec: 24.24\n",
            "2020-02-12 18:24:10,965 epoch 27 - iter 10/28 - loss 1.41596768 - samples/sec: 23.88\n",
            "2020-02-12 18:24:15,696 epoch 27 - iter 12/28 - loss 1.37259043 - samples/sec: 24.66\n",
            "2020-02-12 18:24:21,074 epoch 27 - iter 14/28 - loss 1.32922169 - samples/sec: 21.44\n",
            "2020-02-12 18:24:27,495 epoch 27 - iter 16/28 - loss 1.32303316 - samples/sec: 14.52\n",
            "2020-02-12 18:24:31,966 epoch 27 - iter 18/28 - loss 1.34193546 - samples/sec: 24.65\n",
            "2020-02-12 18:24:36,796 epoch 27 - iter 20/28 - loss 1.36498776 - samples/sec: 21.25\n",
            "2020-02-12 18:24:43,218 epoch 27 - iter 22/28 - loss 1.30368676 - samples/sec: 23.39\n",
            "2020-02-12 18:24:46,504 epoch 27 - iter 24/28 - loss 1.28816372 - samples/sec: 27.02\n",
            "2020-02-12 18:24:50,685 epoch 27 - iter 26/28 - loss 1.24262956 - samples/sec: 32.38\n",
            "2020-02-12 18:24:53,705 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 18:24:53,706 EPOCH 27 done: loss 1.2424 - lr 0.0031\n",
            "2020-02-12 18:24:59,978 DEV : loss 0.8737722635269165 - score 0.64\n",
            "Epoch    27: reducing learning rate of group 0 to 1.5625e-03.\n",
            "2020-02-12 18:25:00,010 BAD EPOCHS (no improvement): 4\n",
            "2020-02-12 18:26:14,348 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 18:26:15,558 epoch 28 - iter 0/28 - loss 0.53074074 - samples/sec: 52.98\n",
            "2020-02-12 18:26:18,098 epoch 28 - iter 2/28 - loss 1.08616622 - samples/sec: 29.38\n",
            "2020-02-12 18:26:20,905 epoch 28 - iter 4/28 - loss 0.98146520 - samples/sec: 25.33\n",
            "2020-02-12 18:26:22,936 epoch 28 - iter 6/28 - loss 1.05332364 - samples/sec: 36.35\n",
            "2020-02-12 18:26:27,736 epoch 28 - iter 8/28 - loss 1.03607557 - samples/sec: 24.32\n",
            "2020-02-12 18:26:33,142 epoch 28 - iter 10/28 - loss 1.16462532 - samples/sec: 22.51\n",
            "2020-02-12 18:26:38,905 epoch 28 - iter 12/28 - loss 1.15006584 - samples/sec: 16.01\n",
            "2020-02-12 18:26:43,867 epoch 28 - iter 14/28 - loss 1.19072668 - samples/sec: 25.03\n",
            "2020-02-12 18:26:50,268 epoch 28 - iter 16/28 - loss 1.14530899 - samples/sec: 15.35\n",
            "2020-02-12 18:26:54,840 epoch 28 - iter 18/28 - loss 1.10899266 - samples/sec: 26.45\n",
            "2020-02-12 18:27:01,657 epoch 28 - iter 20/28 - loss 1.13009583 - samples/sec: 19.12\n",
            "2020-02-12 18:27:07,305 epoch 28 - iter 22/28 - loss 1.18308224 - samples/sec: 22.11\n",
            "2020-02-12 18:27:12,002 epoch 28 - iter 24/28 - loss 1.24407519 - samples/sec: 23.70\n",
            "2020-02-12 18:27:16,714 epoch 28 - iter 26/28 - loss 1.25022486 - samples/sec: 24.56\n",
            "2020-02-12 18:27:19,962 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 18:27:19,963 EPOCH 28 done: loss 1.2362 - lr 0.0016\n",
            "2020-02-12 18:27:26,075 DEV : loss 0.8682941198348999 - score 0.64\n",
            "2020-02-12 18:27:26,106 BAD EPOCHS (no improvement): 1\n",
            "2020-02-12 18:28:39,057 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 18:28:40,200 epoch 29 - iter 0/28 - loss 1.41758680 - samples/sec: 56.25\n",
            "2020-02-12 18:28:42,526 epoch 29 - iter 2/28 - loss 1.13837910 - samples/sec: 33.16\n",
            "2020-02-12 18:28:50,972 epoch 29 - iter 4/28 - loss 1.30615044 - samples/sec: 25.23\n",
            "2020-02-12 18:28:57,150 epoch 29 - iter 6/28 - loss 1.17566504 - samples/sec: 14.77\n",
            "2020-02-12 18:29:02,392 epoch 29 - iter 8/28 - loss 1.14724758 - samples/sec: 25.79\n",
            "2020-02-12 18:29:07,865 epoch 29 - iter 10/28 - loss 1.11818764 - samples/sec: 20.23\n",
            "2020-02-12 18:29:12,990 epoch 29 - iter 12/28 - loss 1.15142984 - samples/sec: 20.80\n",
            "2020-02-12 18:29:17,496 epoch 29 - iter 14/28 - loss 1.13352232 - samples/sec: 24.64\n",
            "2020-02-12 18:29:22,026 epoch 29 - iter 16/28 - loss 1.17367697 - samples/sec: 26.52\n",
            "2020-02-12 18:29:27,367 epoch 29 - iter 18/28 - loss 1.12659520 - samples/sec: 28.28\n",
            "2020-02-12 18:29:31,520 epoch 29 - iter 20/28 - loss 1.13642588 - samples/sec: 24.48\n",
            "2020-02-12 18:29:37,447 epoch 29 - iter 22/28 - loss 1.14105104 - samples/sec: 16.22\n",
            "2020-02-12 18:29:42,693 epoch 29 - iter 24/28 - loss 1.21519262 - samples/sec: 26.98\n",
            "2020-02-12 18:29:48,241 epoch 29 - iter 26/28 - loss 1.17925134 - samples/sec: 21.82\n",
            "2020-02-12 18:29:51,761 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 18:29:51,763 EPOCH 29 done: loss 1.2062 - lr 0.0016\n",
            "2020-02-12 18:29:58,263 DEV : loss 0.8741247653961182 - score 0.64\n",
            "2020-02-12 18:29:58,292 BAD EPOCHS (no improvement): 2\n",
            "2020-02-12 18:31:17,164 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 18:31:19,034 epoch 30 - iter 0/28 - loss 0.99690962 - samples/sec: 55.30\n",
            "2020-02-12 18:31:21,430 epoch 30 - iter 2/28 - loss 1.02662595 - samples/sec: 32.71\n",
            "2020-02-12 18:31:24,171 epoch 30 - iter 4/28 - loss 0.97367792 - samples/sec: 26.03\n",
            "2020-02-12 18:31:28,537 epoch 30 - iter 6/28 - loss 1.06532158 - samples/sec: 31.40\n",
            "2020-02-12 18:31:34,083 epoch 30 - iter 8/28 - loss 1.05326419 - samples/sec: 22.38\n",
            "2020-02-12 18:31:38,882 epoch 30 - iter 10/28 - loss 1.09720846 - samples/sec: 27.08\n",
            "2020-02-12 18:31:43,315 epoch 30 - iter 12/28 - loss 1.10813596 - samples/sec: 26.72\n",
            "2020-02-12 18:31:47,392 epoch 30 - iter 14/28 - loss 1.14576257 - samples/sec: 28.11\n",
            "2020-02-12 18:31:51,690 epoch 30 - iter 16/28 - loss 1.12228929 - samples/sec: 28.17\n",
            "2020-02-12 18:31:57,192 epoch 30 - iter 18/28 - loss 1.13811116 - samples/sec: 28.00\n",
            "2020-02-12 18:32:03,673 epoch 30 - iter 20/28 - loss 1.11347133 - samples/sec: 16.18\n",
            "2020-02-12 18:32:09,625 epoch 30 - iter 22/28 - loss 1.13719258 - samples/sec: 18.80\n",
            "2020-02-12 18:32:14,288 epoch 30 - iter 24/28 - loss 1.10461210 - samples/sec: 23.12\n",
            "2020-02-12 18:32:20,598 epoch 30 - iter 26/28 - loss 1.11859828 - samples/sec: 15.30\n",
            "2020-02-12 18:32:24,381 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 18:32:24,383 EPOCH 30 done: loss 1.1735 - lr 0.0016\n",
            "2020-02-12 18:32:31,628 DEV : loss 0.8756513595581055 - score 0.64\n",
            "2020-02-12 18:32:31,665 BAD EPOCHS (no improvement): 3\n",
            "2020-02-12 18:33:50,258 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 18:33:53,659 epoch 31 - iter 0/28 - loss 0.79006672 - samples/sec: 76.40\n",
            "2020-02-12 18:33:56,234 epoch 31 - iter 2/28 - loss 1.26541217 - samples/sec: 28.74\n",
            "2020-02-12 18:33:58,969 epoch 31 - iter 4/28 - loss 1.14587002 - samples/sec: 26.19\n",
            "2020-02-12 18:34:03,392 epoch 31 - iter 6/28 - loss 1.46577883 - samples/sec: 34.65\n",
            "2020-02-12 18:34:08,621 epoch 31 - iter 8/28 - loss 1.29263894 - samples/sec: 24.85\n",
            "2020-02-12 18:34:14,303 epoch 31 - iter 10/28 - loss 1.23719671 - samples/sec: 15.75\n",
            "2020-02-12 18:34:18,559 epoch 31 - iter 12/28 - loss 1.24655404 - samples/sec: 26.54\n",
            "2020-02-12 18:34:23,657 epoch 31 - iter 14/28 - loss 1.28045867 - samples/sec: 21.30\n",
            "2020-02-12 18:34:29,200 epoch 31 - iter 16/28 - loss 1.22741803 - samples/sec: 23.15\n",
            "2020-02-12 18:34:33,791 epoch 31 - iter 18/28 - loss 1.21276597 - samples/sec: 25.17\n",
            "2020-02-12 18:34:38,615 epoch 31 - iter 20/28 - loss 1.22583516 - samples/sec: 26.99\n",
            "2020-02-12 18:34:42,563 epoch 31 - iter 22/28 - loss 1.23543078 - samples/sec: 17.83\n",
            "2020-02-12 18:34:45,478 epoch 31 - iter 24/28 - loss 1.26037333 - samples/sec: 24.79\n",
            "2020-02-12 18:34:48,702 epoch 31 - iter 26/28 - loss 1.26371820 - samples/sec: 23.17\n",
            "2020-02-12 18:34:50,630 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 18:34:50,632 EPOCH 31 done: loss 1.2610 - lr 0.0016\n",
            "2020-02-12 18:34:56,831 DEV : loss 0.8751553297042847 - score 0.64\n",
            "Epoch    31: reducing learning rate of group 0 to 7.8125e-04.\n",
            "2020-02-12 18:34:56,869 BAD EPOCHS (no improvement): 4\n",
            "2020-02-12 18:36:18,911 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 18:36:20,118 epoch 32 - iter 0/28 - loss 1.47593117 - samples/sec: 53.16\n",
            "2020-02-12 18:36:22,237 epoch 32 - iter 2/28 - loss 1.22954909 - samples/sec: 35.13\n",
            "2020-02-12 18:36:24,431 epoch 32 - iter 4/28 - loss 1.31176977 - samples/sec: 33.90\n",
            "2020-02-12 18:36:27,730 epoch 32 - iter 6/28 - loss 1.28860385 - samples/sec: 21.12\n",
            "2020-02-12 18:36:32,302 epoch 32 - iter 8/28 - loss 1.18888717 - samples/sec: 23.19\n",
            "2020-02-12 18:36:37,778 epoch 32 - iter 10/28 - loss 1.22193449 - samples/sec: 21.92\n",
            "2020-02-12 18:36:44,144 epoch 32 - iter 12/28 - loss 1.16425281 - samples/sec: 15.27\n",
            "2020-02-12 18:36:48,357 epoch 32 - iter 14/28 - loss 1.10581384 - samples/sec: 26.50\n",
            "2020-02-12 18:36:54,608 epoch 32 - iter 16/28 - loss 1.19541046 - samples/sec: 16.57\n",
            "2020-02-12 18:36:58,768 epoch 32 - iter 18/28 - loss 1.21253381 - samples/sec: 25.43\n",
            "2020-02-12 18:37:03,271 epoch 32 - iter 20/28 - loss 1.18036224 - samples/sec: 27.59\n",
            "2020-02-12 18:37:07,530 epoch 32 - iter 22/28 - loss 1.18073699 - samples/sec: 28.14\n",
            "2020-02-12 18:37:11,266 epoch 32 - iter 24/28 - loss 1.17640712 - samples/sec: 22.59\n",
            "2020-02-12 18:37:13,593 epoch 32 - iter 26/28 - loss 1.21775805 - samples/sec: 31.13\n",
            "2020-02-12 18:37:15,321 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 18:37:15,323 EPOCH 32 done: loss 1.2082 - lr 0.0008\n",
            "2020-02-12 18:37:21,725 DEV : loss 0.8754314184188843 - score 0.64\n",
            "2020-02-12 18:37:21,755 BAD EPOCHS (no improvement): 1\n",
            "2020-02-12 18:38:36,265 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 18:38:37,174 epoch 33 - iter 0/28 - loss 0.92646742 - samples/sec: 70.57\n",
            "2020-02-12 18:38:39,690 epoch 33 - iter 2/28 - loss 1.10088348 - samples/sec: 30.01\n",
            "2020-02-12 18:38:42,422 epoch 33 - iter 4/28 - loss 1.09687958 - samples/sec: 26.18\n",
            "2020-02-12 18:38:44,843 epoch 33 - iter 6/28 - loss 1.01071753 - samples/sec: 29.84\n",
            "2020-02-12 18:38:51,677 epoch 33 - iter 8/28 - loss 1.09019476 - samples/sec: 21.16\n",
            "2020-02-12 18:38:56,613 epoch 33 - iter 10/28 - loss 1.03915058 - samples/sec: 31.04\n",
            "2020-02-12 18:39:03,178 epoch 33 - iter 12/28 - loss 1.03986648 - samples/sec: 21.17\n",
            "2020-02-12 18:39:07,232 epoch 33 - iter 14/28 - loss 1.12755680 - samples/sec: 28.30\n",
            "2020-02-12 18:39:12,991 epoch 33 - iter 16/28 - loss 1.09133524 - samples/sec: 19.77\n",
            "2020-02-12 18:39:19,182 epoch 33 - iter 18/28 - loss 1.13243828 - samples/sec: 15.57\n",
            "2020-02-12 18:39:23,742 epoch 33 - iter 20/28 - loss 1.10262971 - samples/sec: 24.84\n",
            "2020-02-12 18:39:28,063 epoch 33 - iter 22/28 - loss 1.18496236 - samples/sec: 31.86\n",
            "2020-02-12 18:39:34,290 epoch 33 - iter 24/28 - loss 1.16159758 - samples/sec: 17.65\n",
            "2020-02-12 18:39:38,978 epoch 33 - iter 26/28 - loss 1.23678559 - samples/sec: 24.39\n",
            "2020-02-12 18:39:42,589 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 18:39:42,591 EPOCH 33 done: loss 1.2355 - lr 0.0008\n",
            "2020-02-12 18:39:48,927 DEV : loss 0.8787496089935303 - score 0.64\n",
            "2020-02-12 18:39:48,973 BAD EPOCHS (no improvement): 2\n",
            "2020-02-12 18:41:07,263 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 18:41:08,349 epoch 34 - iter 0/28 - loss 1.03503609 - samples/sec: 59.20\n",
            "2020-02-12 18:41:11,054 epoch 34 - iter 2/28 - loss 1.23279651 - samples/sec: 28.32\n",
            "2020-02-12 18:41:13,253 epoch 34 - iter 4/28 - loss 1.11530685 - samples/sec: 32.86\n",
            "2020-02-12 18:41:16,013 epoch 34 - iter 6/28 - loss 0.99991226 - samples/sec: 26.16\n",
            "2020-02-12 18:41:21,238 epoch 34 - iter 8/28 - loss 1.04639276 - samples/sec: 20.41\n",
            "2020-02-12 18:41:27,454 epoch 34 - iter 10/28 - loss 1.04949903 - samples/sec: 15.77\n",
            "2020-02-12 18:41:31,965 epoch 34 - iter 12/28 - loss 1.08758791 - samples/sec: 23.96\n",
            "2020-02-12 18:41:38,305 epoch 34 - iter 14/28 - loss 1.20901518 - samples/sec: 14.54\n",
            "2020-02-12 18:41:43,670 epoch 34 - iter 16/28 - loss 1.20489785 - samples/sec: 29.47\n",
            "2020-02-12 18:41:47,762 epoch 34 - iter 18/28 - loss 1.21727083 - samples/sec: 29.63\n",
            "2020-02-12 18:41:52,803 epoch 34 - iter 20/28 - loss 1.23016385 - samples/sec: 27.61\n",
            "2020-02-12 18:41:58,920 epoch 34 - iter 22/28 - loss 1.21116995 - samples/sec: 21.11\n",
            "2020-02-12 18:42:03,354 epoch 34 - iter 24/28 - loss 1.21405056 - samples/sec: 28.36\n",
            "2020-02-12 18:42:08,379 epoch 34 - iter 26/28 - loss 1.19872529 - samples/sec: 19.49\n",
            "2020-02-12 18:42:11,924 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 18:42:11,926 EPOCH 34 done: loss 1.2112 - lr 0.0008\n",
            "2020-02-12 18:42:18,524 DEV : loss 0.8881824016571045 - score 0.64\n",
            "2020-02-12 18:42:18,555 BAD EPOCHS (no improvement): 3\n",
            "2020-02-12 18:43:38,329 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 18:43:39,396 epoch 35 - iter 0/28 - loss 0.66021490 - samples/sec: 70.30\n",
            "2020-02-12 18:43:41,724 epoch 35 - iter 2/28 - loss 0.93486277 - samples/sec: 32.32\n",
            "2020-02-12 18:43:43,807 epoch 35 - iter 4/28 - loss 1.10204048 - samples/sec: 34.88\n",
            "2020-02-12 18:43:48,749 epoch 35 - iter 6/28 - loss 0.96035869 - samples/sec: 21.49\n",
            "2020-02-12 18:43:53,899 epoch 35 - iter 8/28 - loss 0.98017004 - samples/sec: 24.24\n",
            "2020-02-12 18:43:58,446 epoch 35 - iter 10/28 - loss 0.95422095 - samples/sec: 26.91\n",
            "2020-02-12 18:44:04,277 epoch 35 - iter 12/28 - loss 1.03669566 - samples/sec: 24.57\n",
            "2020-02-12 18:44:08,658 epoch 35 - iter 14/28 - loss 1.05280145 - samples/sec: 25.69\n",
            "2020-02-12 18:44:13,653 epoch 35 - iter 16/28 - loss 1.10378479 - samples/sec: 26.72\n",
            "2020-02-12 18:44:17,748 epoch 35 - iter 18/28 - loss 1.13376246 - samples/sec: 30.60\n",
            "2020-02-12 18:44:23,425 epoch 35 - iter 20/28 - loss 1.15821346 - samples/sec: 15.37\n",
            "2020-02-12 18:44:29,285 epoch 35 - iter 22/28 - loss 1.11428246 - samples/sec: 14.81\n",
            "2020-02-12 18:44:32,321 epoch 35 - iter 24/28 - loss 1.11530851 - samples/sec: 23.81\n",
            "2020-02-12 18:44:35,226 epoch 35 - iter 26/28 - loss 1.15691136 - samples/sec: 24.75\n",
            "2020-02-12 18:44:36,686 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 18:44:36,688 EPOCH 35 done: loss 1.1952 - lr 0.0008\n",
            "2020-02-12 18:44:43,246 DEV : loss 0.8897943496704102 - score 0.64\n",
            "Epoch    35: reducing learning rate of group 0 to 3.9063e-04.\n",
            "2020-02-12 18:44:43,287 BAD EPOCHS (no improvement): 4\n",
            "2020-02-12 18:46:02,790 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 18:46:04,107 epoch 36 - iter 0/28 - loss 1.35661125 - samples/sec: 48.70\n",
            "2020-02-12 18:46:06,958 epoch 36 - iter 2/28 - loss 1.21735128 - samples/sec: 25.66\n",
            "2020-02-12 18:46:10,794 epoch 36 - iter 4/28 - loss 1.06551437 - samples/sec: 17.85\n",
            "2020-02-12 18:46:13,724 epoch 36 - iter 6/28 - loss 1.18191310 - samples/sec: 24.00\n",
            "2020-02-12 18:46:19,328 epoch 36 - iter 8/28 - loss 1.20782381 - samples/sec: 16.91\n",
            "2020-02-12 18:46:23,648 epoch 36 - iter 10/28 - loss 1.15744435 - samples/sec: 26.63\n",
            "2020-02-12 18:46:28,459 epoch 36 - iter 12/28 - loss 1.20748098 - samples/sec: 24.57\n",
            "2020-02-12 18:46:32,244 epoch 36 - iter 14/28 - loss 1.30871951 - samples/sec: 33.69\n",
            "2020-02-12 18:46:37,755 epoch 36 - iter 16/28 - loss 1.33804108 - samples/sec: 21.15\n",
            "2020-02-12 18:46:42,166 epoch 36 - iter 18/28 - loss 1.31197204 - samples/sec: 27.39\n",
            "2020-02-12 18:46:47,509 epoch 36 - iter 20/28 - loss 1.31585598 - samples/sec: 25.93\n",
            "2020-02-12 18:46:52,154 epoch 36 - iter 22/28 - loss 1.28327791 - samples/sec: 26.40\n",
            "2020-02-12 18:46:56,553 epoch 36 - iter 24/28 - loss 1.26378397 - samples/sec: 28.98\n",
            "2020-02-12 18:47:01,339 epoch 36 - iter 26/28 - loss 1.26150396 - samples/sec: 24.58\n",
            "2020-02-12 18:47:05,346 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 18:47:05,351 EPOCH 36 done: loss 1.2347 - lr 0.0004\n",
            "2020-02-12 18:47:11,911 DEV : loss 0.8915261030197144 - score 0.64\n",
            "2020-02-12 18:47:11,943 BAD EPOCHS (no improvement): 1\n",
            "2020-02-12 18:48:30,211 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 18:48:31,664 epoch 37 - iter 0/28 - loss 0.96290302 - samples/sec: 44.12\n",
            "2020-02-12 18:48:37,077 epoch 37 - iter 2/28 - loss 1.39510234 - samples/sec: 23.54\n",
            "2020-02-12 18:48:39,848 epoch 37 - iter 4/28 - loss 1.21701345 - samples/sec: 26.11\n",
            "2020-02-12 18:48:43,894 epoch 37 - iter 6/28 - loss 1.04730531 - samples/sec: 30.85\n",
            "2020-02-12 18:48:48,827 epoch 37 - iter 8/28 - loss 0.99677308 - samples/sec: 23.63\n",
            "2020-02-12 18:48:54,183 epoch 37 - iter 10/28 - loss 1.06457602 - samples/sec: 23.14\n",
            "2020-02-12 18:48:59,924 epoch 37 - iter 12/28 - loss 1.16340575 - samples/sec: 28.84\n",
            "2020-02-12 18:49:05,732 epoch 37 - iter 14/28 - loss 1.24247980 - samples/sec: 16.36\n",
            "2020-02-12 18:49:10,660 epoch 37 - iter 16/28 - loss 1.24071194 - samples/sec: 23.17\n",
            "2020-02-12 18:49:15,650 epoch 37 - iter 18/28 - loss 1.29268709 - samples/sec: 23.27\n",
            "2020-02-12 18:49:19,994 epoch 37 - iter 20/28 - loss 1.28476157 - samples/sec: 15.79\n",
            "2020-02-12 18:49:22,370 epoch 37 - iter 22/28 - loss 1.27319209 - samples/sec: 31.15\n",
            "2020-02-12 18:49:25,829 epoch 37 - iter 24/28 - loss 1.22993271 - samples/sec: 20.42\n",
            "2020-02-12 18:49:28,687 epoch 37 - iter 26/28 - loss 1.19463181 - samples/sec: 24.96\n",
            "2020-02-12 18:49:30,258 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 18:49:30,261 EPOCH 37 done: loss 1.2123 - lr 0.0004\n",
            "2020-02-12 18:49:36,546 DEV : loss 0.8900036215782166 - score 0.64\n",
            "2020-02-12 18:49:36,576 BAD EPOCHS (no improvement): 2\n",
            "2020-02-12 18:50:55,831 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 18:50:57,052 epoch 38 - iter 0/28 - loss 0.97845793 - samples/sec: 52.52\n",
            "2020-02-12 18:51:01,237 epoch 38 - iter 2/28 - loss 1.32612340 - samples/sec: 16.79\n",
            "2020-02-12 18:51:04,298 epoch 38 - iter 4/28 - loss 1.15509939 - samples/sec: 22.85\n",
            "2020-02-12 18:51:07,239 epoch 38 - iter 6/28 - loss 1.12788221 - samples/sec: 23.84\n",
            "2020-02-12 18:51:11,774 epoch 38 - iter 8/28 - loss 1.10855463 - samples/sec: 28.62\n",
            "2020-02-12 18:51:16,557 epoch 38 - iter 10/28 - loss 1.18522250 - samples/sec: 23.67\n",
            "2020-02-12 18:51:21,132 epoch 38 - iter 12/28 - loss 1.12767414 - samples/sec: 24.87\n",
            "2020-02-12 18:51:25,730 epoch 38 - iter 14/28 - loss 1.13239940 - samples/sec: 23.03\n",
            "2020-02-12 18:51:30,170 epoch 38 - iter 16/28 - loss 1.15043968 - samples/sec: 26.35\n",
            "2020-02-12 18:51:35,295 epoch 38 - iter 18/28 - loss 1.15705706 - samples/sec: 22.43\n",
            "2020-02-12 18:51:41,081 epoch 38 - iter 20/28 - loss 1.12547173 - samples/sec: 16.70\n",
            "2020-02-12 18:51:46,502 epoch 38 - iter 22/28 - loss 1.13098437 - samples/sec: 26.12\n",
            "2020-02-12 18:51:51,951 epoch 38 - iter 24/28 - loss 1.12640720 - samples/sec: 25.62\n",
            "2020-02-12 18:51:57,466 epoch 38 - iter 26/28 - loss 1.14875112 - samples/sec: 27.52\n",
            "2020-02-12 18:52:00,968 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 18:52:00,971 EPOCH 38 done: loss 1.1786 - lr 0.0004\n",
            "2020-02-12 18:52:07,179 DEV : loss 0.8902065753936768 - score 0.64\n",
            "2020-02-12 18:52:07,211 BAD EPOCHS (no improvement): 3\n",
            "2020-02-12 18:53:22,341 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 18:53:23,289 epoch 39 - iter 0/28 - loss 0.41284180 - samples/sec: 68.53\n",
            "2020-02-12 18:53:26,578 epoch 39 - iter 2/28 - loss 0.71106513 - samples/sec: 22.16\n",
            "2020-02-12 18:53:31,709 epoch 39 - iter 4/28 - loss 0.84043589 - samples/sec: 29.27\n",
            "2020-02-12 18:53:36,637 epoch 39 - iter 6/28 - loss 1.02792215 - samples/sec: 22.79\n",
            "2020-02-12 18:53:41,352 epoch 39 - iter 8/28 - loss 0.92726453 - samples/sec: 26.41\n",
            "2020-02-12 18:53:45,759 epoch 39 - iter 10/28 - loss 1.10620438 - samples/sec: 29.94\n",
            "2020-02-12 18:53:51,016 epoch 39 - iter 12/28 - loss 1.10030039 - samples/sec: 22.81\n",
            "2020-02-12 18:53:55,534 epoch 39 - iter 14/28 - loss 1.16521489 - samples/sec: 24.52\n",
            "2020-02-12 18:54:01,981 epoch 39 - iter 16/28 - loss 1.12026234 - samples/sec: 15.75\n",
            "2020-02-12 18:54:06,874 epoch 39 - iter 18/28 - loss 1.15386240 - samples/sec: 26.06\n",
            "2020-02-12 18:54:11,210 epoch 39 - iter 20/28 - loss 1.19856959 - samples/sec: 26.70\n",
            "2020-02-12 18:54:17,482 epoch 39 - iter 22/28 - loss 1.18301560 - samples/sec: 15.03\n",
            "2020-02-12 18:54:23,045 epoch 39 - iter 24/28 - loss 1.18749039 - samples/sec: 25.63\n",
            "2020-02-12 18:54:28,176 epoch 39 - iter 26/28 - loss 1.16378426 - samples/sec: 20.24\n",
            "2020-02-12 18:54:31,448 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 18:54:31,449 EPOCH 39 done: loss 1.1829 - lr 0.0004\n",
            "2020-02-12 18:54:37,767 DEV : loss 0.8895131349563599 - score 0.64\n",
            "Epoch    39: reducing learning rate of group 0 to 1.9531e-04.\n",
            "2020-02-12 18:54:37,799 BAD EPOCHS (no improvement): 4\n",
            "2020-02-12 18:55:59,742 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 18:56:00,952 epoch 40 - iter 0/28 - loss 1.28904581 - samples/sec: 52.99\n",
            "2020-02-12 18:56:04,048 epoch 40 - iter 2/28 - loss 1.29068406 - samples/sec: 23.82\n",
            "2020-02-12 18:56:08,412 epoch 40 - iter 4/28 - loss 1.41293964 - samples/sec: 15.74\n",
            "2020-02-12 18:56:11,180 epoch 40 - iter 6/28 - loss 1.36928517 - samples/sec: 25.40\n",
            "2020-02-12 18:56:15,506 epoch 40 - iter 8/28 - loss 1.35894749 - samples/sec: 27.69\n",
            "2020-02-12 18:56:19,616 epoch 40 - iter 10/28 - loss 1.29324241 - samples/sec: 28.87\n",
            "2020-02-12 18:56:24,081 epoch 40 - iter 12/28 - loss 1.28469034 - samples/sec: 24.71\n",
            "2020-02-12 18:56:28,619 epoch 40 - iter 14/28 - loss 1.22383483 - samples/sec: 30.27\n",
            "2020-02-12 18:56:33,145 epoch 40 - iter 16/28 - loss 1.15901047 - samples/sec: 32.87\n",
            "2020-02-12 18:56:38,298 epoch 40 - iter 18/28 - loss 1.18576627 - samples/sec: 23.80\n",
            "2020-02-12 18:56:43,047 epoch 40 - iter 20/28 - loss 1.15559001 - samples/sec: 25.11\n",
            "2020-02-12 18:56:48,166 epoch 40 - iter 22/28 - loss 1.16927678 - samples/sec: 23.98\n",
            "2020-02-12 18:56:54,676 epoch 40 - iter 24/28 - loss 1.19604321 - samples/sec: 14.28\n",
            "2020-02-12 18:56:59,410 epoch 40 - iter 26/28 - loss 1.19887354 - samples/sec: 24.54\n",
            "2020-02-12 18:57:02,535 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 18:57:02,536 EPOCH 40 done: loss 1.1908 - lr 0.0002\n",
            "2020-02-12 18:57:08,832 DEV : loss 0.889061450958252 - score 0.64\n",
            "2020-02-12 18:57:08,860 BAD EPOCHS (no improvement): 1\n",
            "2020-02-12 18:58:22,246 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 18:58:23,248 epoch 41 - iter 0/28 - loss 1.29796410 - samples/sec: 64.03\n",
            "2020-02-12 18:58:26,321 epoch 41 - iter 2/28 - loss 1.29600763 - samples/sec: 23.38\n",
            "2020-02-12 18:58:29,410 epoch 41 - iter 4/28 - loss 1.19970560 - samples/sec: 22.67\n",
            "2020-02-12 18:58:32,516 epoch 41 - iter 6/28 - loss 1.07621152 - samples/sec: 22.64\n",
            "2020-02-12 18:58:38,732 epoch 41 - iter 8/28 - loss 1.21487464 - samples/sec: 17.06\n",
            "2020-02-12 18:58:43,389 epoch 41 - iter 10/28 - loss 1.18059999 - samples/sec: 27.77\n",
            "2020-02-12 18:58:49,814 epoch 41 - iter 12/28 - loss 1.19301759 - samples/sec: 17.09\n",
            "2020-02-12 18:58:55,040 epoch 41 - iter 14/28 - loss 1.17956985 - samples/sec: 22.26\n",
            "2020-02-12 18:58:59,586 epoch 41 - iter 16/28 - loss 1.18104438 - samples/sec: 27.68\n",
            "2020-02-12 18:59:04,309 epoch 41 - iter 18/28 - loss 1.19294924 - samples/sec: 26.29\n",
            "2020-02-12 18:59:08,987 epoch 41 - iter 20/28 - loss 1.14554675 - samples/sec: 26.48\n",
            "2020-02-12 18:59:14,020 epoch 41 - iter 22/28 - loss 1.18828554 - samples/sec: 25.20\n",
            "2020-02-12 18:59:18,811 epoch 41 - iter 24/28 - loss 1.20466838 - samples/sec: 27.35\n",
            "2020-02-12 18:59:23,632 epoch 41 - iter 26/28 - loss 1.20283698 - samples/sec: 30.91\n",
            "2020-02-12 18:59:26,483 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 18:59:26,484 EPOCH 41 done: loss 1.2043 - lr 0.0002\n",
            "2020-02-12 18:59:33,177 DEV : loss 0.8890502452850342 - score 0.64\n",
            "2020-02-12 18:59:33,207 BAD EPOCHS (no improvement): 2\n",
            "2020-02-12 19:00:49,456 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 19:00:53,391 epoch 42 - iter 0/28 - loss 0.91436481 - samples/sec: 68.75\n",
            "2020-02-12 19:00:56,578 epoch 42 - iter 2/28 - loss 1.49425205 - samples/sec: 23.78\n",
            "2020-02-12 19:00:59,532 epoch 42 - iter 4/28 - loss 1.28744116 - samples/sec: 24.21\n",
            "2020-02-12 19:01:04,070 epoch 42 - iter 6/28 - loss 1.32623870 - samples/sec: 25.42\n",
            "2020-02-12 19:01:08,758 epoch 42 - iter 8/28 - loss 1.34125275 - samples/sec: 27.64\n",
            "2020-02-12 19:01:13,571 epoch 42 - iter 10/28 - loss 1.25557873 - samples/sec: 26.35\n",
            "2020-02-12 19:01:19,826 epoch 42 - iter 12/28 - loss 1.25244086 - samples/sec: 16.48\n",
            "2020-02-12 19:01:25,031 epoch 42 - iter 14/28 - loss 1.22352819 - samples/sec: 23.07\n",
            "2020-02-12 19:01:30,751 epoch 42 - iter 16/28 - loss 1.27941651 - samples/sec: 17.34\n",
            "2020-02-12 19:01:35,432 epoch 42 - iter 18/28 - loss 1.22442381 - samples/sec: 26.88\n",
            "2020-02-12 19:01:40,737 epoch 42 - iter 20/28 - loss 1.22212399 - samples/sec: 27.94\n",
            "2020-02-12 19:01:44,689 epoch 42 - iter 22/28 - loss 1.25522524 - samples/sec: 39.33\n",
            "2020-02-12 19:01:49,330 epoch 42 - iter 24/28 - loss 1.21147368 - samples/sec: 26.84\n",
            "2020-02-12 19:01:53,959 epoch 42 - iter 26/28 - loss 1.20910162 - samples/sec: 22.71\n",
            "2020-02-12 19:01:57,319 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 19:01:57,321 EPOCH 42 done: loss 1.2139 - lr 0.0002\n",
            "2020-02-12 19:02:03,596 DEV : loss 0.8903070688247681 - score 0.64\n",
            "2020-02-12 19:02:03,626 BAD EPOCHS (no improvement): 3\n",
            "2020-02-12 19:03:17,407 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 19:03:18,423 epoch 43 - iter 0/28 - loss 1.53201246 - samples/sec: 63.16\n",
            "2020-02-12 19:03:31,212 epoch 43 - iter 2/28 - loss 1.42731412 - samples/sec: 16.99\n",
            "2020-02-12 19:03:36,189 epoch 43 - iter 4/28 - loss 1.36753340 - samples/sec: 23.17\n",
            "2020-02-12 19:03:42,313 epoch 43 - iter 6/28 - loss 1.28144237 - samples/sec: 15.67\n",
            "2020-02-12 19:03:46,890 epoch 43 - iter 8/28 - loss 1.20996703 - samples/sec: 30.99\n",
            "2020-02-12 19:03:52,254 epoch 43 - iter 10/28 - loss 1.23248373 - samples/sec: 20.52\n",
            "2020-02-12 19:03:57,393 epoch 43 - iter 12/28 - loss 1.25811280 - samples/sec: 23.22\n",
            "2020-02-12 19:04:02,226 epoch 43 - iter 14/28 - loss 1.20317084 - samples/sec: 21.43\n",
            "2020-02-12 19:04:07,324 epoch 43 - iter 16/28 - loss 1.16770068 - samples/sec: 23.75\n",
            "2020-02-12 19:04:12,844 epoch 43 - iter 18/28 - loss 1.18679860 - samples/sec: 27.72\n",
            "2020-02-12 19:04:16,950 epoch 43 - iter 20/28 - loss 1.24326315 - samples/sec: 33.57\n",
            "2020-02-12 19:04:22,191 epoch 43 - iter 22/28 - loss 1.19592580 - samples/sec: 24.08\n",
            "2020-02-12 19:04:26,168 epoch 43 - iter 24/28 - loss 1.16252541 - samples/sec: 34.97\n",
            "2020-02-12 19:04:31,337 epoch 43 - iter 26/28 - loss 1.13723635 - samples/sec: 20.66\n",
            "2020-02-12 19:04:33,044 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 19:04:33,046 EPOCH 43 done: loss 1.1839 - lr 0.0002\n",
            "2020-02-12 19:04:39,196 DEV : loss 0.8895096182823181 - score 0.64\n",
            "Epoch    43: reducing learning rate of group 0 to 9.7656e-05.\n",
            "2020-02-12 19:04:39,240 BAD EPOCHS (no improvement): 4\n",
            "2020-02-12 19:05:53,087 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 19:05:53,089 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 19:05:53,094 learning rate too small - quitting training!\n",
            "2020-02-12 19:05:53,096 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 19:07:39,415 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-12 19:07:39,417 Testing using best model ...\n",
            "2020-02-12 19:07:39,442 loading file /content/drive/My Drive/Colab Notebooks/Fall-Recognition/Data/FOLDER_3/TRN-FD3/best-model.pt\n",
            "2020-02-12 19:12:52,084 0.669\t0.5419\t0.5988\n",
            "2020-02-12 19:12:52,091 \n",
            "MICRO_AVG: acc 0.4273 - f1-score 0.5988\n",
            "MACRO_AVG: acc 0.4273 - f1-score 0.5988\n",
            "QUEDA      tp: 97 - fp: 48 - fn: 82 - tn: 97 - precision: 0.6690 - recall: 0.5419 - accuracy: 0.4273 - f1-score: 0.5988\n",
            "2020-02-12 19:12:52,092 ----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'test_score': 0.5988,\n",
              " 'dev_score_history': [0.4783,\n",
              "  0.6383,\n",
              "  0.6809,\n",
              "  0.6522,\n",
              "  0.579,\n",
              "  0.4444,\n",
              "  0.6809,\n",
              "  0.6667,\n",
              "  0.6809,\n",
              "  0.6122,\n",
              "  0.6809,\n",
              "  0.6667,\n",
              "  0.6531,\n",
              "  0.6531,\n",
              "  0.64,\n",
              "  0.64,\n",
              "  0.64,\n",
              "  0.64,\n",
              "  0.64,\n",
              "  0.64,\n",
              "  0.64,\n",
              "  0.64,\n",
              "  0.64,\n",
              "  0.64,\n",
              "  0.64,\n",
              "  0.64,\n",
              "  0.64,\n",
              "  0.64,\n",
              "  0.64,\n",
              "  0.64,\n",
              "  0.64,\n",
              "  0.64,\n",
              "  0.64,\n",
              "  0.64,\n",
              "  0.64,\n",
              "  0.64,\n",
              "  0.64,\n",
              "  0.64,\n",
              "  0.64,\n",
              "  0.64,\n",
              "  0.64,\n",
              "  0.64,\n",
              "  0.64],\n",
              " 'train_loss_history': [24.54027901376997,\n",
              "  3.385047197341919,\n",
              "  2.6585456005164554,\n",
              "  2.3565533586910794,\n",
              "  2.138084718159267,\n",
              "  1.8553393823759896,\n",
              "  1.7396685906818934,\n",
              "  1.6574717632361822,\n",
              "  1.5599483847618103,\n",
              "  1.4593707195350103,\n",
              "  1.4836481426443373,\n",
              "  1.3921161677156175,\n",
              "  1.3943055995873042,\n",
              "  1.3340523838996887,\n",
              "  1.304547735622951,\n",
              "  1.2546399299587523,\n",
              "  1.2916852704116277,\n",
              "  1.2640106465135301,\n",
              "  1.2748524631772722,\n",
              "  1.2146339203630174,\n",
              "  1.2102458934698785,\n",
              "  1.283508654151644,\n",
              "  1.3110862629754203,\n",
              "  1.234634348324367,\n",
              "  1.2234178334474564,\n",
              "  1.196191476924079,\n",
              "  1.2423964313098363,\n",
              "  1.2362496831587382,\n",
              "  1.2062174337250846,\n",
              "  1.1734704630715507,\n",
              "  1.2609740964003973,\n",
              "  1.208151055233819,\n",
              "  1.2355089485645294,\n",
              "  1.2111677953175135,\n",
              "  1.1952038322176253,\n",
              "  1.2346729678767068,\n",
              "  1.2123012287276131,\n",
              "  1.1786159702709742,\n",
              "  1.1829253349985396,\n",
              "  1.190819508263043,\n",
              "  1.2042900664465768,\n",
              "  1.2139239736965723,\n",
              "  1.1838521787098475],\n",
              " 'dev_loss_history': [tensor(1.7596, device='cuda:0'),\n",
              "  tensor(1.4598, device='cuda:0'),\n",
              "  tensor(1.2848, device='cuda:0'),\n",
              "  tensor(1.3526, device='cuda:0'),\n",
              "  tensor(1.0050, device='cuda:0'),\n",
              "  tensor(1.3780, device='cuda:0'),\n",
              "  tensor(0.9452, device='cuda:0'),\n",
              "  tensor(0.8610, device='cuda:0'),\n",
              "  tensor(0.8990, device='cuda:0'),\n",
              "  tensor(1.0124, device='cuda:0'),\n",
              "  tensor(0.7997, device='cuda:0'),\n",
              "  tensor(0.8127, device='cuda:0'),\n",
              "  tensor(0.8950, device='cuda:0'),\n",
              "  tensor(0.8523, device='cuda:0'),\n",
              "  tensor(0.8868, device='cuda:0'),\n",
              "  tensor(0.9241, device='cuda:0'),\n",
              "  tensor(0.9143, device='cuda:0'),\n",
              "  tensor(0.8315, device='cuda:0'),\n",
              "  tensor(0.9216, device='cuda:0'),\n",
              "  tensor(0.9028, device='cuda:0'),\n",
              "  tensor(0.8597, device='cuda:0'),\n",
              "  tensor(0.8874, device='cuda:0'),\n",
              "  tensor(0.8649, device='cuda:0'),\n",
              "  tensor(0.8802, device='cuda:0'),\n",
              "  tensor(0.8673, device='cuda:0'),\n",
              "  tensor(0.8819, device='cuda:0'),\n",
              "  tensor(0.8738, device='cuda:0'),\n",
              "  tensor(0.8683, device='cuda:0'),\n",
              "  tensor(0.8741, device='cuda:0'),\n",
              "  tensor(0.8757, device='cuda:0'),\n",
              "  tensor(0.8752, device='cuda:0'),\n",
              "  tensor(0.8754, device='cuda:0'),\n",
              "  tensor(0.8787, device='cuda:0'),\n",
              "  tensor(0.8882, device='cuda:0'),\n",
              "  tensor(0.8898, device='cuda:0'),\n",
              "  tensor(0.8915, device='cuda:0'),\n",
              "  tensor(0.8900, device='cuda:0'),\n",
              "  tensor(0.8902, device='cuda:0'),\n",
              "  tensor(0.8895, device='cuda:0'),\n",
              "  tensor(0.8891, device='cuda:0'),\n",
              "  tensor(0.8891, device='cuda:0'),\n",
              "  tensor(0.8903, device='cuda:0'),\n",
              "  tensor(0.8895, device='cuda:0')]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VBlbBW1Sjig",
        "colab_type": "text"
      },
      "source": [
        "## Evaluating"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSVl-5-CSh-s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "369c2697-4781-437e-edfd-dc9f1356aea7"
      },
      "source": [
        "!python3 EvaluatesModels.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[94m--------------- (NER) EVAL CROSS-VALIDATION FOLDER: 1 ---------------\u001b[0m\n",
            " \n",
            "--------------------------START VALIDATION TOKEN------------------------------\n",
            " \n",
            "2020-02-14 10:56:09,670 loading file /content/drive/My Drive/Colab Notebooks/Fall-Recognition/Experiments/CROSS-NER/FOLDER_1/TRN-FD1/best-model.pt\n",
            " \n",
            " --- VALID --- \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       0.95      0.96      0.96      1913\n",
            "     class 1       0.85      0.79      0.82       477\n",
            "\n",
            "    accuracy                           0.93      2390\n",
            "   macro avg       0.90      0.88      0.89      2390\n",
            "weighted avg       0.93      0.93      0.93      2390\n",
            "\n",
            "\tF1 Score\n",
            "\n",
            "Class 0\t 0.9562062710546774\n",
            "Class 1\t 0.8165038002171552\n",
            " \n",
            "\u001b[94m--------------- (NER) EVAL CROSS-VALIDATION FOLDER: 2 ---------------\u001b[0m\n",
            " \n",
            "--------------------------START VALIDATION TOKEN------------------------------\n",
            " \n",
            "2020-02-14 10:59:55,680 loading file /content/drive/My Drive/Colab Notebooks/Fall-Recognition/Experiments/CROSS-NER/FOLDER_2/TRN-FD2/best-model.pt\n",
            " \n",
            " --- VALID --- \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       0.93      0.97      0.95      1913\n",
            "     class 1       0.83      0.70      0.76       477\n",
            "\n",
            "    accuracy                           0.91      2390\n",
            "   macro avg       0.88      0.83      0.85      2390\n",
            "weighted avg       0.91      0.91      0.91      2390\n",
            "\n",
            "\tF1 Score\n",
            "\n",
            "Class 0\t 0.9459667093469911\n",
            "Class 1\t 0.7588571428571428\n",
            " \n",
            "\u001b[94m--------------- (NER) EVAL CROSS-VALIDATION FOLDER: 3 ---------------\u001b[0m\n",
            " \n",
            "--------------------------START VALIDATION TOKEN------------------------------\n",
            " \n",
            "2020-02-14 11:03:53,660 loading file /content/drive/My Drive/Colab Notebooks/Fall-Recognition/Experiments/CROSS-NER/FOLDER_3/TRN-FD3/best-model.pt\n",
            " \n",
            " --- VALID --- \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       0.94      0.97      0.96      1913\n",
            "     class 1       0.87      0.76      0.81       477\n",
            "\n",
            "    accuracy                           0.93      2390\n",
            "   macro avg       0.91      0.87      0.89      2390\n",
            "weighted avg       0.93      0.93      0.93      2390\n",
            "\n",
            "\tF1 Score\n",
            "\n",
            "Class 0\t 0.9573045267489713\n",
            "Class 1\t 0.8139013452914797\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}